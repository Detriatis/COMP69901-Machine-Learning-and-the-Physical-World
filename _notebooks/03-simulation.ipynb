{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation\n",
    "==========\n",
    "\n",
    "### [Neil D. Lawrence](http://inverseprobability.com)\n",
    "\n",
    "### 2020-10-22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**: This lecture will introduce the notion of simulation and\n",
    "review the different types of simulation we might use to represent the\n",
    "physical world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\tk}[1]{}\n",
    "%\\newcommand{\\tk}[1]{\\textbf{TK}: #1}\n",
    "\\newcommand{\\Amatrix}{\\mathbf{A}}\n",
    "\\newcommand{\\KL}[2]{\\text{KL}\\left( #1\\,\\|\\,#2 \\right)}\n",
    "\\newcommand{\\Kaast}{\\kernelMatrix_{\\mathbf{ \\ast}\\mathbf{ \\ast}}}\n",
    "\\newcommand{\\Kastu}{\\kernelMatrix_{\\mathbf{ \\ast} \\inducingVector}}\n",
    "\\newcommand{\\Kff}{\\kernelMatrix_{\\mappingFunctionVector \\mappingFunctionVector}}\n",
    "\\newcommand{\\Kfu}{\\kernelMatrix_{\\mappingFunctionVector \\inducingVector}}\n",
    "\\newcommand{\\Kuast}{\\kernelMatrix_{\\inducingVector \\bf\\ast}}\n",
    "\\newcommand{\\Kuf}{\\kernelMatrix_{\\inducingVector \\mappingFunctionVector}}\n",
    "\\newcommand{\\Kuu}{\\kernelMatrix_{\\inducingVector \\inducingVector}}\n",
    "\\newcommand{\\Kuui}{\\Kuu^{-1}}\n",
    "\\newcommand{\\Qaast}{\\mathbf{Q}_{\\bf \\ast \\ast}}\n",
    "\\newcommand{\\Qastf}{\\mathbf{Q}_{\\ast \\mappingFunction}}\n",
    "\\newcommand{\\Qfast}{\\mathbf{Q}_{\\mappingFunctionVector \\bf \\ast}}\n",
    "\\newcommand{\\Qff}{\\mathbf{Q}_{\\mappingFunctionVector \\mappingFunctionVector}}\n",
    "\\newcommand{\\aMatrix}{\\mathbf{A}}\n",
    "\\newcommand{\\aScalar}{a}\n",
    "\\newcommand{\\aVector}{\\mathbf{a}}\n",
    "\\newcommand{\\acceleration}{a}\n",
    "\\newcommand{\\bMatrix}{\\mathbf{B}}\n",
    "\\newcommand{\\bScalar}{b}\n",
    "\\newcommand{\\bVector}{\\mathbf{b}}\n",
    "\\newcommand{\\basisFunc}{\\phi}\n",
    "\\newcommand{\\basisFuncVector}{\\boldsymbol{ \\basisFunc}}\n",
    "\\newcommand{\\basisFunction}{\\phi}\n",
    "\\newcommand{\\basisLocation}{\\mu}\n",
    "\\newcommand{\\basisMatrix}{\\boldsymbol{ \\Phi}}\n",
    "\\newcommand{\\basisScalar}{\\basisFunction}\n",
    "\\newcommand{\\basisVector}{\\boldsymbol{ \\basisFunction}}\n",
    "\\newcommand{\\activationFunction}{\\phi}\n",
    "\\newcommand{\\activationMatrix}{\\boldsymbol{ \\Phi}}\n",
    "\\newcommand{\\activationScalar}{\\basisFunction}\n",
    "\\newcommand{\\activationVector}{\\boldsymbol{ \\basisFunction}}\n",
    "\\newcommand{\\bigO}{\\mathcal{O}}\n",
    "\\newcommand{\\binomProb}{\\pi}\n",
    "\\newcommand{\\cMatrix}{\\mathbf{C}}\n",
    "\\newcommand{\\cbasisMatrix}{\\hat{\\boldsymbol{ \\Phi}}}\n",
    "\\newcommand{\\cdataMatrix}{\\hat{\\dataMatrix}}\n",
    "\\newcommand{\\cdataScalar}{\\hat{\\dataScalar}}\n",
    "\\newcommand{\\cdataVector}{\\hat{\\dataVector}}\n",
    "\\newcommand{\\centeredKernelMatrix}{\\mathbf{ \\MakeUppercase{\\centeredKernelScalar}}}\n",
    "\\newcommand{\\centeredKernelScalar}{b}\n",
    "\\newcommand{\\centeredKernelVector}{\\centeredKernelScalar}\n",
    "\\newcommand{\\centeringMatrix}{\\mathbf{H}}\n",
    "\\newcommand{\\chiSquaredDist}[2]{\\chi_{#1}^{2}\\left(#2\\right)}\n",
    "\\newcommand{\\chiSquaredSamp}[1]{\\chi_{#1}^{2}}\n",
    "\\newcommand{\\conditionalCovariance}{\\boldsymbol{ \\Sigma}}\n",
    "\\newcommand{\\coregionalizationMatrix}{\\mathbf{B}}\n",
    "\\newcommand{\\coregionalizationScalar}{b}\n",
    "\\newcommand{\\coregionalizationVector}{\\mathbf{ \\coregionalizationScalar}}\n",
    "\\newcommand{\\covDist}[2]{\\text{cov}_{#2}\\left(#1\\right)}\n",
    "\\newcommand{\\covSamp}[1]{\\text{cov}\\left(#1\\right)}\n",
    "\\newcommand{\\covarianceScalar}{c}\n",
    "\\newcommand{\\covarianceVector}{\\mathbf{ \\covarianceScalar}}\n",
    "\\newcommand{\\covarianceMatrix}{\\mathbf{C}}\n",
    "\\newcommand{\\covarianceMatrixTwo}{\\boldsymbol{ \\Sigma}}\n",
    "\\newcommand{\\croupierScalar}{s}\n",
    "\\newcommand{\\croupierVector}{\\mathbf{ \\croupierScalar}}\n",
    "\\newcommand{\\croupierMatrix}{\\mathbf{ \\MakeUppercase{\\croupierScalar}}}\n",
    "\\newcommand{\\dataDim}{p}\n",
    "\\newcommand{\\dataIndex}{i}\n",
    "\\newcommand{\\dataIndexTwo}{j}\n",
    "\\newcommand{\\dataMatrix}{\\mathbf{Y}}\n",
    "\\newcommand{\\dataScalar}{y}\n",
    "\\newcommand{\\dataSet}{\\mathcal{D}}\n",
    "\\newcommand{\\dataStd}{\\sigma}\n",
    "\\newcommand{\\dataVector}{\\mathbf{ \\dataScalar}}\n",
    "\\newcommand{\\decayRate}{d}\n",
    "\\newcommand{\\degreeMatrix}{\\mathbf{ \\MakeUppercase{\\degreeScalar}}}\n",
    "\\newcommand{\\degreeScalar}{d}\n",
    "\\newcommand{\\degreeVector}{\\mathbf{ \\degreeScalar}}\n",
    "% Already defined by latex\n",
    "%\\newcommand{\\det}[1]{\\left|#1\\right|}\n",
    "\\newcommand{\\diag}[1]{\\text{diag}\\left(#1\\right)}\n",
    "\\newcommand{\\diagonalMatrix}{\\mathbf{D}}\n",
    "\\newcommand{\\diff}[2]{\\frac{\\text{d}#1}{\\text{d}#2}}\n",
    "\\newcommand{\\diffTwo}[2]{\\frac{\\text{d}^2#1}{\\text{d}#2^2}}\n",
    "\\newcommand{\\displacement}{x}\n",
    "\\newcommand{\\displacementVector}{\\textbf{\\displacement}}\n",
    "\\newcommand{\\distanceMatrix}{\\mathbf{ \\MakeUppercase{\\distanceScalar}}}\n",
    "\\newcommand{\\distanceScalar}{d}\n",
    "\\newcommand{\\distanceVector}{\\mathbf{ \\distanceScalar}}\n",
    "\\newcommand{\\eigenvaltwo}{\\ell}\n",
    "\\newcommand{\\eigenvaltwoMatrix}{\\mathbf{L}}\n",
    "\\newcommand{\\eigenvaltwoVector}{\\mathbf{l}}\n",
    "\\newcommand{\\eigenvalue}{\\lambda}\n",
    "\\newcommand{\\eigenvalueMatrix}{\\boldsymbol{ \\Lambda}}\n",
    "\\newcommand{\\eigenvalueVector}{\\boldsymbol{ \\lambda}}\n",
    "\\newcommand{\\eigenvector}{\\mathbf{ \\eigenvectorScalar}}\n",
    "\\newcommand{\\eigenvectorMatrix}{\\mathbf{U}}\n",
    "\\newcommand{\\eigenvectorScalar}{u}\n",
    "\\newcommand{\\eigenvectwo}{\\mathbf{v}}\n",
    "\\newcommand{\\eigenvectwoMatrix}{\\mathbf{V}}\n",
    "\\newcommand{\\eigenvectwoScalar}{v}\n",
    "\\newcommand{\\entropy}[1]{\\mathcal{H}\\left(#1\\right)}\n",
    "\\newcommand{\\errorFunction}{E}\n",
    "\\newcommand{\\expDist}[2]{\\left<#1\\right>_{#2}}\n",
    "\\newcommand{\\expSamp}[1]{\\left<#1\\right>}\n",
    "\\newcommand{\\expectation}[1]{\\left\\langle #1 \\right\\rangle }\n",
    "\\newcommand{\\expectationDist}[2]{\\left\\langle #1 \\right\\rangle _{#2}}\n",
    "\\newcommand{\\expectedDistanceMatrix}{\\mathcal{D}}\n",
    "\\newcommand{\\eye}{\\mathbf{I}}\n",
    "\\newcommand{\\fantasyDim}{r}\n",
    "\\newcommand{\\fantasyMatrix}{\\mathbf{ \\MakeUppercase{\\fantasyScalar}}}\n",
    "\\newcommand{\\fantasyScalar}{z}\n",
    "\\newcommand{\\fantasyVector}{\\mathbf{ \\fantasyScalar}}\n",
    "\\newcommand{\\featureStd}{\\varsigma}\n",
    "\\newcommand{\\gammaCdf}[3]{\\mathcal{GAMMA CDF}\\left(#1|#2,#3\\right)}\n",
    "\\newcommand{\\gammaDist}[3]{\\mathcal{G}\\left(#1|#2,#3\\right)}\n",
    "\\newcommand{\\gammaSamp}[2]{\\mathcal{G}\\left(#1,#2\\right)}\n",
    "\\newcommand{\\gaussianDist}[3]{\\mathcal{N}\\left(#1|#2,#3\\right)}\n",
    "\\newcommand{\\gaussianSamp}[2]{\\mathcal{N}\\left(#1,#2\\right)}\n",
    "\\newcommand{\\given}{|}\n",
    "\\newcommand{\\half}{\\frac{1}{2}}\n",
    "\\newcommand{\\heaviside}{H}\n",
    "\\newcommand{\\hiddenMatrix}{\\mathbf{ \\MakeUppercase{\\hiddenScalar}}}\n",
    "\\newcommand{\\hiddenScalar}{h}\n",
    "\\newcommand{\\hiddenVector}{\\mathbf{ \\hiddenScalar}}\n",
    "\\newcommand{\\identityMatrix}{\\eye}\n",
    "\\newcommand{\\inducingInputScalar}{z}\n",
    "\\newcommand{\\inducingInputVector}{\\mathbf{ \\inducingInputScalar}}\n",
    "\\newcommand{\\inducingInputMatrix}{\\mathbf{Z}}\n",
    "\\newcommand{\\inducingScalar}{u}\n",
    "\\newcommand{\\inducingVector}{\\mathbf{ \\inducingScalar}}\n",
    "\\newcommand{\\inducingMatrix}{\\mathbf{U}}\n",
    "\\newcommand{\\inlineDiff}[2]{\\text{d}#1/\\text{d}#2}\n",
    "\\newcommand{\\inputDim}{q}\n",
    "\\newcommand{\\inputMatrix}{\\mathbf{X}}\n",
    "\\newcommand{\\inputScalar}{x}\n",
    "\\newcommand{\\inputSpace}{\\mathcal{X}}\n",
    "\\newcommand{\\inputVals}{\\inputVector}\n",
    "\\newcommand{\\inputVector}{\\mathbf{ \\inputScalar}}\n",
    "\\newcommand{\\iterNum}{k}\n",
    "\\newcommand{\\kernel}{\\kernelScalar}\n",
    "\\newcommand{\\kernelMatrix}{\\mathbf{K}}\n",
    "\\newcommand{\\kernelScalar}{k}\n",
    "\\newcommand{\\kernelVector}{\\mathbf{ \\kernelScalar}}\n",
    "\\newcommand{\\kff}{\\kernelScalar_{\\mappingFunction \\mappingFunction}}\n",
    "\\newcommand{\\kfu}{\\kernelVector_{\\mappingFunction \\inducingScalar}}\n",
    "\\newcommand{\\kuf}{\\kernelVector_{\\inducingScalar \\mappingFunction}}\n",
    "\\newcommand{\\kuu}{\\kernelVector_{\\inducingScalar \\inducingScalar}}\n",
    "\\newcommand{\\lagrangeMultiplier}{\\lambda}\n",
    "\\newcommand{\\lagrangeMultiplierMatrix}{\\boldsymbol{ \\Lambda}}\n",
    "\\newcommand{\\lagrangian}{L}\n",
    "\\newcommand{\\laplacianFactor}{\\mathbf{ \\MakeUppercase{\\laplacianFactorScalar}}}\n",
    "\\newcommand{\\laplacianFactorScalar}{m}\n",
    "\\newcommand{\\laplacianFactorVector}{\\mathbf{ \\laplacianFactorScalar}}\n",
    "\\newcommand{\\laplacianMatrix}{\\mathbf{L}}\n",
    "\\newcommand{\\laplacianScalar}{\\ell}\n",
    "\\newcommand{\\laplacianVector}{\\mathbf{ \\ell}}\n",
    "\\newcommand{\\latentDim}{q}\n",
    "\\newcommand{\\latentDistanceMatrix}{\\boldsymbol{ \\Delta}}\n",
    "\\newcommand{\\latentDistanceScalar}{\\delta}\n",
    "\\newcommand{\\latentDistanceVector}{\\boldsymbol{ \\delta}}\n",
    "\\newcommand{\\latentForce}{f}\n",
    "\\newcommand{\\latentFunction}{u}\n",
    "\\newcommand{\\latentFunctionVector}{\\mathbf{ \\latentFunction}}\n",
    "\\newcommand{\\latentFunctionMatrix}{\\mathbf{ \\MakeUppercase{\\latentFunction}}}\n",
    "\\newcommand{\\latentIndex}{j}\n",
    "\\newcommand{\\latentScalar}{z}\n",
    "\\newcommand{\\latentVector}{\\mathbf{ \\latentScalar}}\n",
    "\\newcommand{\\latentMatrix}{\\mathbf{Z}}\n",
    "\\newcommand{\\learnRate}{\\eta}\n",
    "\\newcommand{\\lengthScale}{\\ell}\n",
    "\\newcommand{\\rbfWidth}{\\ell}\n",
    "\\newcommand{\\likelihoodBound}{\\mathcal{L}}\n",
    "\\newcommand{\\likelihoodFunction}{L}\n",
    "\\newcommand{\\locationScalar}{\\mu}\n",
    "\\newcommand{\\locationVector}{\\boldsymbol{ \\locationScalar}}\n",
    "\\newcommand{\\locationMatrix}{\\mathbf{M}}\n",
    "\\newcommand{\\variance}[1]{\\text{var}\\left( #1 \\right)}\n",
    "\\newcommand{\\mappingFunction}{f}\n",
    "\\newcommand{\\mappingFunctionMatrix}{\\mathbf{F}}\n",
    "\\newcommand{\\mappingFunctionTwo}{g}\n",
    "\\newcommand{\\mappingFunctionTwoMatrix}{\\mathbf{G}}\n",
    "\\newcommand{\\mappingFunctionTwoVector}{\\mathbf{ \\mappingFunctionTwo}}\n",
    "\\newcommand{\\mappingFunctionVector}{\\mathbf{ \\mappingFunction}}\n",
    "\\newcommand{\\scaleScalar}{s}\n",
    "\\newcommand{\\mappingScalar}{w}\n",
    "\\newcommand{\\mappingVector}{\\mathbf{ \\mappingScalar}}\n",
    "\\newcommand{\\mappingMatrix}{\\mathbf{W}}\n",
    "\\newcommand{\\mappingScalarTwo}{v}\n",
    "\\newcommand{\\mappingVectorTwo}{\\mathbf{ \\mappingScalarTwo}}\n",
    "\\newcommand{\\mappingMatrixTwo}{\\mathbf{V}}\n",
    "\\newcommand{\\maxIters}{K}\n",
    "\\newcommand{\\meanMatrix}{\\mathbf{M}}\n",
    "\\newcommand{\\meanScalar}{\\mu}\n",
    "\\newcommand{\\meanTwoMatrix}{\\mathbf{M}}\n",
    "\\newcommand{\\meanTwoScalar}{m}\n",
    "\\newcommand{\\meanTwoVector}{\\mathbf{ \\meanTwoScalar}}\n",
    "\\newcommand{\\meanVector}{\\boldsymbol{ \\meanScalar}}\n",
    "\\newcommand{\\mrnaConcentration}{m}\n",
    "\\newcommand{\\naturalFrequency}{\\omega}\n",
    "\\newcommand{\\neighborhood}[1]{\\mathcal{N}\\left( #1 \\right)}\n",
    "\\newcommand{\\neilurl}{http://inverseprobability.com/}\n",
    "\\newcommand{\\noiseMatrix}{\\boldsymbol{ E}}\n",
    "\\newcommand{\\noiseScalar}{\\epsilon}\n",
    "\\newcommand{\\noiseVector}{\\boldsymbol{ \\epsilon}}\n",
    "\\newcommand{\\norm}[1]{\\left\\Vert #1 \\right\\Vert}\n",
    "\\newcommand{\\normalizedLaplacianMatrix}{\\hat{\\mathbf{L}}}\n",
    "\\newcommand{\\normalizedLaplacianScalar}{\\hat{\\ell}}\n",
    "\\newcommand{\\normalizedLaplacianVector}{\\hat{\\mathbf{ \\ell}}}\n",
    "\\newcommand{\\numActive}{m}\n",
    "\\newcommand{\\numBasisFunc}{m}\n",
    "\\newcommand{\\numComponents}{m}\n",
    "\\newcommand{\\numComps}{K}\n",
    "\\newcommand{\\numData}{n}\n",
    "\\newcommand{\\numFeatures}{K}\n",
    "\\newcommand{\\numHidden}{h}\n",
    "\\newcommand{\\numInducing}{m}\n",
    "\\newcommand{\\numLayers}{\\ell}\n",
    "\\newcommand{\\numNeighbors}{K}\n",
    "\\newcommand{\\numSequences}{s}\n",
    "\\newcommand{\\numSuccess}{s}\n",
    "\\newcommand{\\numTasks}{m}\n",
    "\\newcommand{\\numTime}{T}\n",
    "\\newcommand{\\numTrials}{S}\n",
    "\\newcommand{\\outputIndex}{j}\n",
    "\\newcommand{\\paramVector}{\\boldsymbol{ \\theta}}\n",
    "\\newcommand{\\parameterMatrix}{\\boldsymbol{ \\Theta}}\n",
    "\\newcommand{\\parameterScalar}{\\theta}\n",
    "\\newcommand{\\parameterVector}{\\boldsymbol{ \\parameterScalar}}\n",
    "\\newcommand{\\partDiff}[2]{\\frac{\\partial#1}{\\partial#2}}\n",
    "\\newcommand{\\precisionScalar}{j}\n",
    "\\newcommand{\\precisionVector}{\\mathbf{ \\precisionScalar}}\n",
    "\\newcommand{\\precisionMatrix}{\\mathbf{J}}\n",
    "\\newcommand{\\pseudotargetScalar}{\\widetilde{y}}\n",
    "\\newcommand{\\pseudotargetVector}{\\mathbf{ \\pseudotargetScalar}}\n",
    "\\newcommand{\\pseudotargetMatrix}{\\mathbf{ \\widetilde{Y}}}\n",
    "\\newcommand{\\rank}[1]{\\text{rank}\\left(#1\\right)}\n",
    "\\newcommand{\\rayleighDist}[2]{\\mathcal{R}\\left(#1|#2\\right)}\n",
    "\\newcommand{\\rayleighSamp}[1]{\\mathcal{R}\\left(#1\\right)}\n",
    "\\newcommand{\\responsibility}{r}\n",
    "\\newcommand{\\rotationScalar}{r}\n",
    "\\newcommand{\\rotationVector}{\\mathbf{ \\rotationScalar}}\n",
    "\\newcommand{\\rotationMatrix}{\\mathbf{R}}\n",
    "\\newcommand{\\sampleCovScalar}{s}\n",
    "\\newcommand{\\sampleCovVector}{\\mathbf{ \\sampleCovScalar}}\n",
    "\\newcommand{\\sampleCovMatrix}{\\mathbf{s}}\n",
    "\\newcommand{\\scalarProduct}[2]{\\left\\langle{#1},{#2}\\right\\rangle}\n",
    "\\newcommand{\\sign}[1]{\\text{sign}\\left(#1\\right)}\n",
    "\\newcommand{\\sigmoid}[1]{\\sigma\\left(#1\\right)}\n",
    "\\newcommand{\\singularvalue}{\\ell}\n",
    "\\newcommand{\\singularvalueMatrix}{\\mathbf{L}}\n",
    "\\newcommand{\\singularvalueVector}{\\mathbf{l}}\n",
    "\\newcommand{\\sorth}{\\mathbf{u}}\n",
    "\\newcommand{\\spar}{\\lambda}\n",
    "\\newcommand{\\trace}[1]{\\text{tr}\\left(#1\\right)}\n",
    "\\newcommand{\\BasalRate}{B}\n",
    "\\newcommand{\\DampingCoefficient}{C}\n",
    "\\newcommand{\\DecayRate}{D}\n",
    "\\newcommand{\\Displacement}{X}\n",
    "\\newcommand{\\LatentForce}{F}\n",
    "\\newcommand{\\Mass}{M}\n",
    "\\newcommand{\\Sensitivity}{S}\n",
    "\\newcommand{\\basalRate}{b}\n",
    "\\newcommand{\\dampingCoefficient}{c}\n",
    "\\newcommand{\\mass}{m}\n",
    "\\newcommand{\\sensitivity}{s}\n",
    "\\newcommand{\\springScalar}{\\kappa}\n",
    "\\newcommand{\\springVector}{\\boldsymbol{ \\kappa}}\n",
    "\\newcommand{\\springMatrix}{\\boldsymbol{ \\mathcal{K}}}\n",
    "\\newcommand{\\tfConcentration}{p}\n",
    "\\newcommand{\\tfDecayRate}{\\delta}\n",
    "\\newcommand{\\tfMrnaConcentration}{f}\n",
    "\\newcommand{\\tfVector}{\\mathbf{ \\tfConcentration}}\n",
    "\\newcommand{\\velocity}{v}\n",
    "\\newcommand{\\sufficientStatsScalar}{g}\n",
    "\\newcommand{\\sufficientStatsVector}{\\mathbf{ \\sufficientStatsScalar}}\n",
    "\\newcommand{\\sufficientStatsMatrix}{\\mathbf{G}}\n",
    "\\newcommand{\\switchScalar}{s}\n",
    "\\newcommand{\\switchVector}{\\mathbf{ \\switchScalar}}\n",
    "\\newcommand{\\switchMatrix}{\\mathbf{S}}\n",
    "\\newcommand{\\tr}[1]{\\text{tr}\\left(#1\\right)}\n",
    "\\newcommand{\\loneNorm}[1]{\\left\\Vert #1 \\right\\Vert_1}\n",
    "\\newcommand{\\ltwoNorm}[1]{\\left\\Vert #1 \\right\\Vert_2}\n",
    "\\newcommand{\\onenorm}[1]{\\left\\vert#1\\right\\vert_1}\n",
    "\\newcommand{\\twonorm}[1]{\\left\\Vert #1 \\right\\Vert}\n",
    "\\newcommand{\\vScalar}{v}\n",
    "\\newcommand{\\vVector}{\\mathbf{v}}\n",
    "\\newcommand{\\vMatrix}{\\mathbf{V}}\n",
    "\\newcommand{\\varianceDist}[2]{\\text{var}_{#2}\\left( #1 \\right)}\n",
    "% Already defined by latex\n",
    "%\\newcommand{\\vec}{#1:}\n",
    "\\newcommand{\\vecb}[1]{\\left(#1\\right):}\n",
    "\\newcommand{\\weightScalar}{w}\n",
    "\\newcommand{\\weightVector}{\\mathbf{ \\weightScalar}}\n",
    "\\newcommand{\\weightMatrix}{\\mathbf{W}}\n",
    "\\newcommand{\\weightedAdjacencyMatrix}{\\mathbf{A}}\n",
    "\\newcommand{\\weightedAdjacencyScalar}{a}\n",
    "\\newcommand{\\weightedAdjacencyVector}{\\mathbf{ \\weightedAdjacencyScalar}}\n",
    "\\newcommand{\\onesVector}{\\mathbf{1}}\n",
    "\\newcommand{\\zerosVector}{\\mathbf{0}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%\n",
    "\n",
    "% Already defined by latex %\n",
    "\n",
    "% Already defined by latex %\n",
    "\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->\n",
    "\n",
    "Last lecture Carl Henrik introduced you to some of the challenges of\n",
    "approximate inference. Including the problem of mathematical\n",
    "tractability. Before that he introduced you to a particular form of\n",
    "model, the Gaussian process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Inference by Rejection Sampling\n",
    "----------------------------------------\n",
    "\n",
    "One view of Bayesian inference is to assume we are given a mechanism for\n",
    "generating samples, where we assume that mechanism is representing on\n",
    "accurate view on the way we believe the world works.\n",
    "\n",
    "This mechanism is known as our *prior* belief.\n",
    "\n",
    "We combine our prior belief with our observations of the real world by\n",
    "discarding all those samples that are inconsistent with our prior. The\n",
    "*likelihood* defines mathematically what we mean by inconsistent with\n",
    "the prior. The higher the noise level in the likelihood, the looser the\n",
    "notion of consistent.\n",
    "\n",
    "The samples that remain are considered to be samples from the\n",
    "*posterior*.\n",
    "\n",
    "This approach to Bayesian inference is closely related to two sampling\n",
    "techniques known as *rejection sampling* and *importance sampling*. It\n",
    "is realized in practice in an approach known as *approximate Bayesian\n",
    "computation* (ABC) or likelihood-free inference.\n",
    "\n",
    "In practice, the algorithm is often too slow to be practical, because\n",
    "most samples will be inconsistent with the data and as a result the\n",
    "mechanism has to be operated many times to obtain a few posterior\n",
    "samples.\n",
    "\n",
    "However, in the Gaussian process case, when the likelihood also assumes\n",
    "Gaussian noise, we can operate this mechanism mathematically, and obtain\n",
    "the posterior density *analytically*. This is the benefit of Gaussian\n",
    "processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pods\n",
    "from ipywidgets import IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pods.notebook.display_plots('gp_rejection_sample{sample:0>3}.png', \n",
    "                            directory='./gp', \n",
    "                            sample=IntSlider(1,1,5,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/gp/gp_rejection_sample003.png\" style=\"width:100%\">\n",
    "<img class=\"\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/gp/gp_rejection_sample004.png\" style=\"width:100%\">\n",
    "<img class=\"\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/gp/gp_rejection_sample005.png\" style=\"width:100%\">\n",
    "\n",
    "Figure: <i>One view of Bayesian inference is we have a machine for\n",
    "generating samples (the *prior*), and we discard all samples\n",
    "inconsistent with our data, leaving the samples of interest (the\n",
    "*posterior*). The Gaussian process allows us to do this\n",
    "analytically.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universe isn’t as Gaussian as it Was\n",
    "------------------------------------\n",
    "\n",
    "The [Planck space\n",
    "craft](https://en.wikipedia.org/wiki/Planck_(spacecraft)) was a European\n",
    "Space Agency space telescope that mapped the cosmic microwave background\n",
    "(CMB) from 2009 to 2013. The [Cosmic Microwave\n",
    "Background](https://en.wikipedia.org/wiki/Cosmic_microwave_background)\n",
    "is the first observable echo we have of the big bang. It dates to\n",
    "approximately 400,000 years after the big bang, at the time the universe\n",
    "was approximately $10^8$ times smaller and the temperature of the\n",
    "Univers was high, around $3 \\times 10^8$ degrees Kelvin. The Universe\n",
    "was in the form of a hydrogen plasma. The echo we observe is the moment\n",
    "when the Universe was cool enough for Protons and electrons to combine\n",
    "to form hydrogen atoms. At this moment, the Universe became transparent\n",
    "for the first time, and photons could travel through space.\n",
    "\n",
    "<img class=\"\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/physics/Front_view_of_the_European_Space_Agency_Planck_satellite.jpg\" style=\"width:60%\">\n",
    "\n",
    "Figure: <i>Artists impression of the Planck spacecraft which measured\n",
    "the Cosmic Microwave Background between 2009 and 2013.</i>\n",
    "\n",
    "The objective of the Planck space craft was to measure the anisotropy\n",
    "and statistics of the Cosmic Microwave Background. This was important,\n",
    "because if the standard model of the Universe is correct the variations\n",
    "around the very high temperature of the Universe of the CMB should be\n",
    "distributed according to a Gaussian process.[1] Currently our best\n",
    "estimates show this to be the case (Jaffe et al., 1998, pp.\n",
    "@Pontzen–cmb10, @Elsner–unbiased15, Elsner–unbiased16).\n",
    "\n",
    "To the high degree of precision that we could measure with the Planck\n",
    "space telescope, the CMB appears to be a Gaussian process. The\n",
    "parameters of its covariance function are given by the fundamental\n",
    "parameters of the universe, for example the amount of dark matter and\n",
    "matter in the universe\n",
    "\n",
    "<img class=\"vertical-align:middle\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/Planck_CMB.png\" style=\"width:50%\">\n",
    "\n",
    "Figure: <i>The cosmic microwave background is, to a very high degree of\n",
    "precision, a Gaussian process. The parameters of its covariance function\n",
    "are given by fundamental parameters of the universe, such as the amount\n",
    "of dark matter and mass.</i>\n",
    "\n",
    "[1] Most of my understanding of this is taken from conversations with\n",
    "Kyle Cranmer, a physicist who makes extensive use of machine learning\n",
    "methods in his work. See e.g. Mishra-Sharma and Cranmer (2020) from Kyle\n",
    "and Siddharth Mishra-Sharma. Of course, any errors in the above text are\n",
    "mine and do not stem from Kyle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating a CMB Map\n",
    "--------------------\n",
    "\n",
    "You can find a Jupyter notebook that allows you to sample from the\n",
    "covariance function to make different Cosmic Microwave Backgrounds [in\n",
    "this Jupyter\n",
    "notebook](https://github.com/lawrennd/Prob-tools/blob/master/notebooks/The%20CMB%20as%20a%20Gaussian%20Process.ipynb).\n",
    "\n",
    "Here we use that code to simulate our own universe and sample from what\n",
    "it looks like.\n",
    "\n",
    "First we install some specialist software as well as `matplotlib`,\n",
    "`scipy`, `numpy` we require\n",
    "\n",
    "-   `camb`:\n",
    "    <a href=\"http://camb.readthedocs.io/en/latest/\" class=\"uri\">http://camb.readthedocs.io/en/latest/</a>\n",
    "-   `healpy`:\n",
    "    <a href=\"https://healpy.readthedocs.io/en/latest/\" class=\"uri\">https://healpy.readthedocs.io/en/latest/</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install camb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install healpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = 'retina'\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from cycler import cycler\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rc(\"font\", family=\"serif\", size=14)\n",
    "rc(\"text\", usetex=False)\n",
    "matplotlib.rcParams['lines.linewidth'] = 2\n",
    "matplotlib.rcParams['patch.linewidth'] = 2\n",
    "matplotlib.rcParams['axes.prop_cycle'] =\\\n",
    "    cycler(\"color\", ['k', 'c', 'm', 'y'])\n",
    "matplotlib.rcParams['axes.labelsize'] = 16\n",
    "\n",
    "import healpy as hp\n",
    "\n",
    "import camb\n",
    "from camb import model, initialpower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the theoretical power spectrum to design the covariance\n",
    "function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 512  # Healpix parameter, giving 12*nside**2 equal-area pixels on the sphere.\n",
    "lmax = 3*nside # band-limit. Should be 2*nside < lmax < 4*nside to get information content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we design our Universe. It is parameterised according to the\n",
    "[$\\Lambda$CDM model](https://en.wikipedia.org/wiki/Lambda-CDM_model).\n",
    "The variables are as follows. `H0` is the Hubble parameter (in\n",
    "Km/s/Mpc). The `ombh2` is Physical Baryon density parameter. The `omch2`\n",
    "is the physical dark matter density parameter. `mnu` is the sum of the\n",
    "neutrino masses (in electron Volts). `omk` is the $\\Omega_k$ is the\n",
    "curvature parameter, which is here set to 0, tiving the minimal six\n",
    "parameter Lambda-CDM model. `tau` is the reionization optical depth.\n",
    "\n",
    "Then we set `ns`, the “scalar spectral index”. This was estimated by\n",
    "Planck to be 0.96. Then there’s `r`, the ratio of the tensor power\n",
    "spectrum to scalar power spectrum. This has been estimated by Planck to\n",
    "be under 0.11. Here we set it to zero. These parameters are associated\n",
    "[with inflation](https://en.wikipedia.org/wiki/Primordial_fluctuations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly following http://camb.readthedocs.io/en/latest/CAMBdemo.html with parameters from https://en.wikipedia.org/wiki/Lambda-CDM_model\n",
    "\n",
    "pars = camb.CAMBparams()\n",
    "pars.set_cosmology(H0=67.74, ombh2=0.0223, omch2=0.1188, mnu=0.06, omk=0, tau=0.066)\n",
    "pars.InitPower.set_params(ns=0.96, r=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having set the parameters, we now use the python software “Code for\n",
    "Anisotropies in the Microwave Background” to get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.set_for_lmax(lmax, lens_potential_accuracy=0);\n",
    "results = camb.get_results(pars)\n",
    "powers = results.get_cmb_power_spectra(pars)\n",
    "totCL = powers['total']\n",
    "unlensedCL = powers['unlensed_scalar']\n",
    "\n",
    "ells = np.arange(totCL.shape[0])\n",
    "Dells = totCL[:, 0]\n",
    "Cells = Dells * 2*np.pi / ells / (ells + 1)  # change of convention to get C_ell\n",
    "Cells[0:2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmbmap = hp.synfast(Cells, nside, \n",
    "                 lmax=lmax, mmax=None, alm=False, pol=False, \n",
    "                 pixwin=False, fwhm=0.0, sigma=None, new=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"vertical-align:middle\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/physics/mollweide-sample-cmb.png\" style=\"width:50%\">\n",
    "\n",
    "Figure: <i>A simulation of the Cosmic Microwave Background obtained\n",
    "through sampling from the relevant Gaussian process covariance (in polar\n",
    "co-ordinates).</i>\n",
    "\n",
    "The simulation was created by [Boris\n",
    "Leistedt](https://ixkael.github.io/), see the [original Jupter notebook\n",
    "here](https://github.com/ixkael/Prob-tools/blob/master/notebooks/The%20CMB%20as%20a%20Gaussian%20Process.ipynb).\n",
    "\n",
    "The world we see today, of course, is not a Gaussian process. There are\n",
    "many dicontinuities, for example, in the density of matter, and\n",
    "therefore in the temperature of the Universe.\n",
    "\n",
    "<img src=\"../slides/diagrams/earth_PNG37.png\" width=\"20%\" style=\"display:inline-block;background:none;vertical-align:middle;border:none;box-shadow:none;\">$=f\\Bigg($<img src=\"../slides/diagrams/Planck_CMB.png\"  width=\"50%\" style=\"display:inline-block;background:none;vertical-align:middle;border:none;box-shadow:none;\">$\\Bigg)$\n",
    "\n",
    "Figure: <i>What we observe today is some non-linear function of the\n",
    "cosmic microwave background.</i>\n",
    "\n",
    "We can think of todays observed Universe, though, as a being a\n",
    "consequence of those temperature fluctuations in the CMB. Those\n",
    "fluctuations are only order $10^-6$ of the scale of the overal\n",
    "temperature of the Universe. But minor fluctations in that density is\n",
    "what triggered the pattern of formation of the Galaxies and how stars\n",
    "formed and created the elements that are the building blocks of our\n",
    "Earth (Vogelsberger et al., 2020).\n",
    "\n",
    "Plank meme\n",
    "\n",
    "Those Cosmological simulations are based on a relatively simple set of\n",
    "‘rules’ that stem from our understanding of natural laws. These ‘rules’\n",
    "are mathematical abstractions of the physical world. Representations of\n",
    "behaviour in mathematical form that capture the interaction forces\n",
    "between particles. The grand aim of physics has been to unify these\n",
    "rules into a single unifying theory. Popular understanding of this quest\n",
    "developed as a result of Stephen Hawking’s book, “[A Brief History of\n",
    "Time](https://en.wikipedia.org/wiki/A_Brief_History_of_Time)”. The idea\n",
    "of these laws as ‘ultimate causes’ has given them a pseudo religious\n",
    "feel, see for example Paul Davies’s book “[The Mind of\n",
    "God](https://en.wikipedia.org/wiki/The_Mind_of_God)” which comes from a\n",
    "quotation form Stephen Hawking.\n",
    "\n",
    "> If we do discover a theory of everything … it would be the ultimate\n",
    "> triump of human reason-for then we would truly know the mind of God\n",
    ">\n",
    "> Stephen Hawking in *A Brief History of Time* 1988\n",
    "\n",
    "The quote captures the mind, and likely works well for selling books (A\n",
    "Brief History of Time sold over 10 million copies), but as Laplace has\n",
    "already pointed out to us, the Universe doesn’t work quite so simply as\n",
    "that. Commonly, God is thought to be omniscient, but having a grand\n",
    "unifying theory alone doesn’t give us omniscience.\n",
    "\n",
    "Laplace’s demon still applies. Even if we had a grand unifying theory,\n",
    "which encoded “all the forces that set nature in motion” we have an\n",
    "amount of work left to do in any quest for ‘omniscience’.\n",
    "\n",
    "> We may regard the present state of the universe as the effect of its\n",
    "> past and the cause of its future. An intellect which at a certain\n",
    "> moment would know all forces that set nature in motion, and all\n",
    "> positions of all items of which nature is composed, if this intellect\n",
    "> were also vast enough to submit these data to analysis, it would\n",
    "> embrace in a single formula the movements of the greatest bodies of\n",
    "> the universe and those of the tiniest atom; for such an intellect\n",
    "> nothing would be uncertain and the future just like the past would be\n",
    "> present before its eyes.\n",
    ">\n",
    "> — Pierre Simon Laplace (Laplace, 1814)\n",
    "\n",
    "We summarized this notion as $$\n",
    "\\text{data} + \\text{model} \\stackrel{\\text{compute}}{\\rightarrow} \\text{prediction}\n",
    "$$ As we pointed out, there is an irony in Laplace’s demon forming the\n",
    "cornerstone of a movement known as ‘determinism’, because Laplace wrote\n",
    "about this idea in an essay on probabilities. The more important quote\n",
    "in the essay was\n",
    "\n",
    "> The curve described by a simple molecule of air or vapor is regulated\n",
    "> in a manner just as certain as the planetary orbits; the only\n",
    "> difference between them is that which comes from our ignorance.\n",
    ">\n",
    "> Probability is relative, in part to this ignorance, in part to our\n",
    "> knowledge. We know that of three or greater number of events a single\n",
    "> one ought to occur; but nothing induces us to believe that one of them\n",
    "> will occur rather than the others. In this state of indecision it is\n",
    "> impossible for us to announce their occurrence with certainty. It is,\n",
    "> however, probable that one of these events, chosen at will, will not\n",
    "> occur because we see several cases equally possible which exclude its\n",
    "> occurrence, while only a single one favors it.\n",
    ">\n",
    "> — Pierre-Simon Laplace (Laplace, 1814)\n",
    "\n",
    "The representation of ignorance through probability is the true message\n",
    "of Laplace, I refer to this message as “Laplace’s gremlin”, because it\n",
    "is the gremlin of uncertainty that interferes with the demon of\n",
    "determinism to mean that our predictions are not deterministic.\n",
    "\n",
    "Our separation of the uncertainty into the data, the model and the\n",
    "computation gives us three domains in which our doubts can creep into\n",
    "our ability to predict. Over the last three lectures we’ve introduced\n",
    "some of the basic tools we can use to unpick this uncertainty. In\n",
    "particular, you’ve been introduced to, or have had reviewed *Bayes’\n",
    "rule*. This rule, which is a simple consequence of the product rule of\n",
    "probability, is the foundation of how we update our beliefs in the\n",
    "presence of new information.\n",
    "\n",
    "Carl Henrik described how a prior probability $p(\\boldsymbol{ \\theta})$\n",
    "represents our hypothesis about the way the world might behave. This can\n",
    "be combined with a *likelihood* through the process of multiplication.\n",
    "Correctly normalized, this gives an updated hypothesis that represents\n",
    "our *posterior* belief about the model in the light of the data.\n",
    "\n",
    "There is a nice symmetry between this approach and how Karl Popper\n",
    "describes the process of scientific discovery. In conjectures and\n",
    "refutations, Popper describes the process of scientific discovery as\n",
    "involving hypothesis and experiment. In our description hypothesis maps\n",
    "onto the *model*. The model is an abstraction of the hypothesis,\n",
    "represented for example as a set of mathematical equations, a\n",
    "computational description or an analogous system (physical system). The\n",
    "data is the product of previous experiments, our readings, our\n",
    "observation of the world around us. We can combine these to make a\n",
    "prediction about what we might expect the future to hold. Popper’s view\n",
    "on the philosophy of science was that the prediction should be\n",
    "falsifiable.\n",
    "\n",
    "We can see this process as a spiral driving forward, importantly Popper\n",
    "relates the relationship between hypothesis (model) and experiment\n",
    "(predictions) as akin to the relationship between the chicken and the\n",
    "egg. Which comes first? The answer is that they co-evolve together.\n",
    "\n",
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/physics/different-models.svg\" class=\"\" width=\"90%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The sets of different models. There are all the models in the\n",
    "Universe we might like to work with. Then there are those models that\n",
    "are computable e.g. by a Turing machine. Then there are those which are\n",
    "analytical tractable. I.e. where the solution might be found\n",
    "analytically. Finally, there are Gaussian processes, where the joint\n",
    "distribution of the states in the model is Gaussian.</i>\n",
    "\n",
    "The approach we’ve taken to the model so far has been severely limiting.\n",
    "By constraining ourselves to models for which the mathematics of\n",
    "probability is tractable, we severely limit what we can say about the\n",
    "universe.\n",
    "\n",
    "Although Bayes’ rule only implies multiplication of probabilities, to\n",
    "acquire theposterior we also need to normalize. Very often it is this\n",
    "normalization step that gets in the way. The normalization step involves\n",
    "integration over the updated hypothesis space, to ensure the updated\n",
    "posterior prediction is correct.\n",
    "\n",
    "We can map the process of Bayesian inference onto the the\n",
    "$\\text{model} + \\text{data}$ perspective in the following way. We can\n",
    "see the model as the prior, the data as the likelihood and the\n",
    "prediction as the posterior[1].\n",
    "\n",
    "So, if we think of our model as incorporating what we know about the\n",
    "physical problem of interest (from Newton, or Bernoulli or Laplace or\n",
    "Einstein or whoever) and the data as being the observations (e.g. from\n",
    "Piazzi’s telescope or a particle accelerator) then we can make\n",
    "predictions about what we might expect to happen in the future by\n",
    "combining the two. It is *those* predictions that Popper sees as\n",
    "important in verifying the scientific theory (which is incorporated in\n",
    "the model).\n",
    "\n",
    "But while Gaussian processes are highly flexible non-parametric function\n",
    "models, they are *not* going to be sufficient to capture the type of\n",
    "physical processes we might expect to encounter in the real world. To\n",
    "give a sense, let’s consider a few examples of the phenomena we might\n",
    "want to capture, either in the scientific world, or in real world\n",
    "decision making.\n",
    "\n",
    "[1] We should be careful about such mappings, this is the one I prefer\n",
    "to think about because I try to think of my modelling assumptions as\n",
    "being stored in a probabilistic model, which I see as the prior\n",
    "distribution over what I expect the data to look like. In many domains\n",
    "of parametric modelling, however, the prior will be specified over the\n",
    "parameters of a model. In the Gaussian process formalism we’re using,\n",
    "this mapping is clearer though. The ‘prior’ is the Gaussian process\n",
    "prior over functions, the data is the relationship between those\n",
    "functions and observations we make. This mental model will also suit\n",
    "what follows in terms of our consideration of simulation. But it would\n",
    "likely confuse someone who had only come to Bayesian inference through\n",
    "parametric models such a neural networks. Note that even in such models,\n",
    "there will be a way of writing down the decomposition of the model that\n",
    "is akin to the above, but it might involve writing down intractable\n",
    "densities so it’s often avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precise Physical Laws\n",
    "=====================\n",
    "\n",
    "We’ve already reviewed the importance of Newton’s laws in forging our\n",
    "view of science: we mentioned the influence [Christiaan\n",
    "Huygens’](https://en.wikipedia.org/wiki/Christiaan_Huygens) work on\n",
    "collisions had on Daniel Bernoulli in forming the kinetic theory of\n",
    "gases. These ideas inform many of the physical models we have today\n",
    "around a number of natural phenomena. The MET Office super computer in\n",
    "Exeter spends its mornings computing the weather across the world, and\n",
    "in its afternoons it’s used for climate modelling. It uses the same set\n",
    "of principles that Newton and Bernoulli explored for gases. They are\n",
    "encoded in the Navier-Stokes equations. The rules that govern the flow\n",
    "of compressible and incompressible fluids. As well as predicting our\n",
    "weather, these equations are used in fluid dynamics models to understand\n",
    "the flight of aircraft, the driving characteristics of racing cars and\n",
    "the efficiency of gas turbine engines.\n",
    "\n",
    "This broad class of physical models, or ‘natural laws’ is probably the\n",
    "closest to what Laplace was referring to in the Demon. The search for\n",
    "unifying physical laws that dictate everything we observe around us has\n",
    "gone on. Alongside Newton we must mention James Clerk Maxwell, who\n",
    "unified electricity and magnetism in one set of equations that were\n",
    "inspired by the work and ideas of Michael Faraday. And still today we\n",
    "look for unifying equations that bring together in a single mathematical\n",
    "model the ‘natural laws’ we observe. One equation that for Laplace would\n",
    "be “all forces that set nature in motion”. We can think of this as our\n",
    "first time of physical model, a ‘precise model’ of the known laws of our\n",
    "Universe, a model where we expect that the mapping from the mathematical\n",
    "abstraction to the physical reality is ‘exact.’[1]\n",
    "\n",
    "<img src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/physics/simulation-scales.svg\" class=\"\" width=\"90%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>A scale of different simulations we might be interested in\n",
    "when modelling the physical world. The scale is $\\log_10$ meters</i>\n",
    "\n",
    "[1] Unfortunately, I have to use the term ‘exact’ loosely here! For\n",
    "example, most of these laws treat space/time as a continuum. But in\n",
    "reality, it is quantised. The smallest length we can define is Planck\n",
    "length ($1.61 \\times 10^{-35}$), and the the smallest time is Planck\n",
    "time. So even in this exact world of Maxwell and Newton there is an\n",
    "abstraction or a discretisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abstraction and Emergent Properties\n",
    "-----------------------------------\n",
    "\n",
    "Unfortunately, even if such an equation were to exist, we would be\n",
    "unlikely to know “all positions of all items of which nature is\n",
    "composed”. A good example here is computational systems biology. In that\n",
    "domain we are interested in understanding the undelying function of the\n",
    "cell. These systems sit somewhere between the two extremes that Laplace\n",
    "described: “the movements of the greatest bodies of the universe and\n",
    "those of the smallest atom”.\n",
    "\n",
    "When the smallest atom is considered, we need to introduce uncertainty.\n",
    "We again turn to a different work of Maxwell, building on Bernoulli’s\n",
    "kinetic theory of gases we end up with probabilities for representing\n",
    "the location of the ‘molecules of air’. Instead of a deterministic\n",
    "location for these particles we represent our belief about their\n",
    "location in a distribution.\n",
    "\n",
    "Computational systems biology is a world of micro-machines, built of\n",
    "three dimensional foldings of strings of proteins. There are spindles\n",
    "(stators) and rotors (e.g. [ATP\n",
    "Synthase](https://en.wikipedia.org/wiki/ATP_synthase)), there are small\n",
    "copying machines (e.g. [RNA\n",
    "Polymerase](https://en.wikipedia.org/wiki/RNA_polymerase)) there are\n",
    "sequence to sequence translators\n",
    "([Ribosomes](https://en.wikipedia.org/wiki/Ribosome)). The cells store\n",
    "information in DNA, but have an ecosystem of structures and messages\n",
    "being sent and built in proteins and RNA. Unpikcing these structures has\n",
    "been a major preoccupation of biology. That is knowing where the atoms\n",
    "of these molecules are in the structure, and how the parts of the\n",
    "structure move when these small micro-machines are carrying out their\n",
    "roles.\n",
    "\n",
    "We understand most (if not all) of the physical laws that drive the\n",
    "movements of these molecules, but we don’t understand all the actions of\n",
    "the cell, nor can we intervene reliably to improve things. So even in\n",
    "the case where we have a good understanding of the physical laws,\n",
    "Laplace’s gremlin emerges in our knowledge of “the positions of all\n",
    "items of which nature is composed”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Molecular Dynamics Simulations\n",
    "------------------------------\n",
    "\n",
    "By understanding and simulating the physics, we can recreate operations\n",
    "that are happening at the level of proteins in the human cell.\n",
    "[V-ATPase](https://en.wikipedia.org/wiki/V-ATPase) is an enzyme that\n",
    "pumps protons. But at the microscopic level it’s a small machine.\n",
    "produces ATP in response to a proton gradient. A recent paper in Science\n",
    "Advanes simulates the functioning of these proteins that operate across\n",
    "from The response to this is to use a mathematical model which\n",
    "(somewhat) abstracts the processes. You can also check this [blog\n",
    "post](https://www6.slac.stanford.edu/news/2020-10-07-first-detailed-look-how-molecular-ferris-wheel-delivers-protons-cellular-factories),\n",
    "although I don’t think the analogies are very helpful, perhaps the blog\n",
    "post serves more as an indicator of how much a scientific result can be\n",
    "corrupted when rewritten for PR purposes.\n",
    "\n",
    "<img class=\"\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/sysbio/rotary_proton_sv_pump_anim_final.gif\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>The V-ATPase enzyme pumps proteins across membranes. This\n",
    "molecular dynamics simulation was recently published in Science Advances\n",
    "(Roh et al., 2020). The scale is roughly $10^{-8} m$.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum Mechanics\n",
    "-----------------\n",
    "\n",
    "Alternative we can drop down a few scales and consider simulation of the\n",
    "Schrodinger equation. A recent paper uses deep neural networks to speed\n",
    "up the solution of the many-electron Schrödinger equation enabling\n",
    "simulation of chemical bonds (Pfau et al., 2020). The [PR-blog post is\n",
    "also available](https://deepmind.com/blog/article/FermiNet) and is\n",
    "rather better written than the V-ATPase version. The paper uses a neural\n",
    "network to model the quantum state of a number of elctrons.\n",
    "\n",
    "<img class=\"\" src=\"http://inverseprobability.com/talks/slides/../slides/diagrams/physics/many-electron-schroedinger.gif\" style=\"width:40%\">\n",
    "\n",
    "Figure: <i>The many-electron Schroedinger equation is important in\n",
    "understanding how Chemical bonds are formed.</i>\n",
    "\n",
    "Each of these simulations have the same property of being based on a set\n",
    "of (physical) rules about how particles interact. But one of the\n",
    "interesting characteristics of such systems is how the properties of the\n",
    "system are emergent as the dynamics are allowed to continue.\n",
    "\n",
    "These properties cannot be predicted without running the physics, or the\n",
    "equivalently the equation. Computation is required. And often the amount\n",
    "of computation that is required is prohibitive.\n",
    "\n",
    "{Closer to home, Bingqing Cheng, one of the Department’s new DECAF\n",
    "Fellows in the Accelerate Program has used neural network accelerated\n",
    "molecular dynamics simulations to understand a new form of metallic\n",
    "hydrogen, likely to occur at the heart of stars (Cheng et al., 2020).\n",
    "The University’s [press release is\n",
    "here](https://www.cam.ac.uk/research/news/ai-shows-how-hydrogen-becomes-a-metal-inside-giant-planets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surrogate Models and Emulators\n",
    "------------------------------\n",
    "\n",
    "In these papers neural networks are being used to speed up computations.\n",
    "In this course we’ve introduced Gaussian processes that will be used to\n",
    "speed up these computations. In both cases the ideas are similar. Rather\n",
    "than rerunning the simulation, we use data from the simulation to *fit*\n",
    "the neural network or the Gaussian process to the data.\n",
    "\n",
    "We’ll see an example of how this is done in a moment, taken from a\n",
    "simple ride hailing simulator, but before we look at that, we’ll first\n",
    "consider why this might be a useful approach.\n",
    "\n",
    "Inspired by\n",
    "<a href=\"https://gist.github.com/jiffyclub/3778422#file-game_of_life-ipynb\" class=\"uri\">https://gist.github.com/jiffyclub/3778422#file-game_of_life-ipynb</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used for counting the number of living neighbors each cell has\n",
    "FILTER = np.array([[1, 1, 1],\n",
    "                   [1, 100, 1],\n",
    "                   [1, 1, 1]], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve(length, generations):\n",
    "    \"\"\"\n",
    "    Run the Game of Life. Starting state is random.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    length : int\n",
    "        Universe will be `length` units per side.\n",
    "    generations : int\n",
    "        Number of generations to run simulation.\n",
    "\n",
    "    \"\"\"\n",
    "    current = np.random.randint(2, size=(length, length))\n",
    "    next = np.empty_like(current)\n",
    "    current[length//2, 1:(length-1)] = 1\n",
    "    show_board(current)\n",
    "    for _ in range(generations):\n",
    "        advance(current, next)\n",
    "        current, next = next, current\n",
    "        show_board(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advance(current, next):\n",
    "    \"\"\"\n",
    "    Calculate the next iteration of the Game of Life.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    current : 2D array\n",
    "        Current state of universe.\n",
    "    next : 2D array\n",
    "        This array will be modified in place so that it contains the\n",
    "        next step. Must be the same size as `current`.\n",
    "\n",
    "    \"\"\"\n",
    "    assert current.shape[0] == current.shape[1], \\\n",
    "           'Expected square universe'\n",
    "    next[:] = 0\n",
    "    count = convolve(current, FILTER, mode='same')\n",
    "    next[(count == 3) | (count == 102) | (count == 103)] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling in Practice\n",
    "=====================\n",
    "\n",
    "Simulations\n",
    "\n",
    "[Simpy](https://simpy.readthedocs.io/en/latest/examples/gas_station_refuel.html)\n",
    "\n",
    "News Vendor Problem Trolley & Pendulum Mountain Car Hodgkin Huxley\n",
    "Formula One Race Plane/F1 Car/Drone Climate model Weather model [Fluid\n",
    "Dynamics](https://github.com/barbagroup/CFDPython) Discretisation of\n",
    "PDEs [Stress in a connecting\n",
    "rod](https://solidspy.readthedocs.io/en/latest/readme.html)\n",
    "Discretisation of PDEs [Network\n",
    "simulation](https://github.com/mkalewski/sim2net) Discrete Event\n",
    "\n",
    "Reaction Rates: https://en.wikipedia.org/wiki/Gillespie\\_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# Input parameters ####################\n",
    "\n",
    "# int; total population\n",
    "N = 350\n",
    "\n",
    "# float; maximum elapsed time\n",
    "T = 100.0\n",
    "\n",
    "# float; start time\n",
    "t = 0.0\n",
    "\n",
    "# float; spatial parameter\n",
    "V = 100.0\n",
    "\n",
    "# float; rate of infection after contact\n",
    "_alpha = 10.0\n",
    "\n",
    "# float; rate of cure\n",
    "_beta = 10.0\n",
    "\n",
    "# int; initial infected population\n",
    "n_I = 1\n",
    "\n",
    "#########################################\n",
    "\n",
    "# Compute susceptible population, set recovered to zero\n",
    "n_S = N - n_I\n",
    "n_R = 0\n",
    "\n",
    "# Initialize results list\n",
    "SIR_data = []\n",
    "SIR_data.append((t, n_S, n_I, n_R))\n",
    "\n",
    "# Main loop\n",
    "while t < T:\n",
    "    if n_I == 0:\n",
    "        break\n",
    "\n",
    "    w1 = _alpha * n_S * n_I / V\n",
    "    w2 = _beta * n_I\n",
    "    W = w1 + w2\n",
    "\n",
    "    # generate exponentially distributed random variable dt\n",
    "    # using inverse transform sampling\n",
    "    dt = -math.log(1 - random.uniform(0.0, 1.0)) / W\n",
    "    t = t + dt\n",
    "\n",
    "    if random.uniform(0.0, 1.0) < w1 / W:\n",
    "        n_S = n_S - 1\n",
    "        n_I = n_I + 1\n",
    "    else:\n",
    "        n_I = n_I - 1\n",
    "        n_R = n_R + 1\n",
    "\n",
    "    SIR_data.append((t, n_S, n_I, n_R))\n",
    "\n",
    "with open(\"SIR_data.txt\", \"w+\") as fp:\n",
    "    fp.write(\"\\n\".join(\"%f %i %i %i\" % x for x in SIR_data))\n",
    "\n",
    "\n",
    "from scipy.integrate import odeint\n",
    "import numpy as np\n",
    "\n",
    "# Numerical solution using an ordinary differential equation solver\n",
    "ts = np.linspace(0, 2, num=200)\n",
    "initial_S_I_R = (N - 1, 1, 0)\n",
    "\n",
    "\n",
    "def differential_SIR(initial_S_I_R, t, _alpha, _beta, V):\n",
    "    n_S, n_I, n_R = initial_S_I_R\n",
    "    dS_dt = -_alpha * n_S / V * n_I\n",
    "    dI_dt = (_alpha * n_S / V - _beta) * n_I\n",
    "    dR_dt = _beta * n_I\n",
    "    return dS_dt, dI_dt, dR_dt\n",
    "\n",
    "\n",
    "solution = odeint(differential_SIR, initial_S_I_R, ts, args=(_alpha, _beta, V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game of Life Conway https://twitter.com/i/status/1316725519518371840\n",
    "Nice intro from [Alan\n",
    "Zucconi](https://www.youtube.com/watch?v=Kk2MH9O4pXY)\n",
    "\n",
    "Probabilistic Programming\n",
    "\n",
    "ABC\n",
    "\n",
    "Boids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cheng, B., Mazzola, G., Pickard, C.J., Ceriotti, M., 2020. Evidence for\n",
    "supercritical behaviour of high-pressure liquid hydrogen. Nature 585,\n",
    "217–220. <https://doi.org/10.1038/s41586-020-2677-y>\n",
    "\n",
    "Elsner, F., Leistedt, B., Peiris, H.V., 2015. Unbiased methods for\n",
    "removing systematics from galaxy clustering measurements. Monthly\n",
    "Notices of the Royal Astronomical Society 456, 2095–2104.\n",
    "<https://doi.org/10.1093/mnras/stv2777>\n",
    "\n",
    "Jaffe, A.H., Bond, J.R., Ferreira, P.G., Knox, L.E., 1998. CMB\n",
    "likelihood functions for beginners and experts, in:.\n",
    "\n",
    "Laplace, P.S., 1814. Essai philosophique sur les probabilités, 2nd ed.\n",
    "Courcier, Paris.\n",
    "\n",
    "Mishra-Sharma, S., Cranmer, K., 2020. Semi-parametric $\\gamma$-ray\n",
    "modeling with Gaussian processes and variational inference.\n",
    "\n",
    "Pfau, D., Spencer, J.S., Matthews, A.G.D.G., Foulkes, W.M.C., 2020. Ab\n",
    "initio solution of the many-electron schrödinger equation with deep\n",
    "neural networks. Phys. Rev. Research 2, 033429.\n",
    "<https://doi.org/10.1103/PhysRevResearch.2.033429>\n",
    "\n",
    "Pontzen, A., Peiris, H.V., 2010. The cut-sky cosmic microwave background\n",
    "is not anomalous. Phys. Rev. D 81, 103008.\n",
    "<https://doi.org/10.1103/PhysRevD.81.103008>\n",
    "\n",
    "Roh, S.-H., Shekhar, M., Pintilie, G., Chipot, C., Wilkens, S.,\n",
    "Singharoy, A., Chiu, W., 2020. Cryo-EM and MD infer water-mediated\n",
    "proton transport and autoinhibition mechanisms of Vo complex. Science\n",
    "Advances 6. <https://doi.org/10.1126/sciadv.abb9605>\n",
    "\n",
    "Vogelsberger, M., Marinacci, F., Torrey, P., Puchwei, E., 2020.\n",
    "Cosmological simulations of galaxy formation. Nature Reviews Physics\n",
    "42–66. <https://doi.org/10.1038/s42254-019-0127-2>"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
