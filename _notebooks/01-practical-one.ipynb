{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 1\n",
    "\n",
    "### [Carl Henrik Ek](http://carlhenrik.com), University of Cambridge\n",
    "\n",
    "### 2022-10-27"
   ],
   "id": "261f57b7-5923-48b5-b7cc-bd9c5356fea6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [],
   "id": "a1177fdd-0f2f-4310-a6f0-400170505af2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "$$"
   ],
   "id": "37aa75a1-0c6d-4366-bc94-cc13ec7bb34b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.cell .markdown}\n",
    "\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->"
   ],
   "id": "533adfc2-c6d9-4ba9-b61a-a7113eb82dc1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Decision Making\n",
    "\n",
    "This notebook will form part of your individual submission for the\n",
    "course. The notebook will roughly mimick the parts that are in the PDF\n",
    "worksheet. Your task is to complete the code that is missing in the\n",
    "parts below and answer the questions that we ask. The aim is not for you\n",
    "to solve the worksheet but rather for you to show your understanding of\n",
    "the material in the course, instead of re-running and aiming to get\n",
    "“perfect” results run things, make sure it is correct and then try to\n",
    "explain your results with a few sentences.\n",
    "\n",
    "First we need to implement the surrogate model, we will use a Gaussian\n",
    "process surrogate."
   ],
   "id": "d6af444f-8c7b-4578-850a-f64b1ec93094"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.spatial.distance import cdist"
   ],
   "id": "ca166765-2671-4f51-9970-6e1e7263fde1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X, noise=0.0):\n",
    "    return -(-np.sin(3*X) - X**2 + 0.7*X + noise*np.random.randn(*X.shape))\n",
    "\n",
    "def squared_exponential_computer(x1,x2,theta):\n",
    "    # compute the squared exponential covariance function\n",
    "    return K\n",
    "\n",
    "def gpposterior(x_star,X,Y,lengthScale,sigma):\n",
    "    # return the posterior estimate of the GP\n",
    "    return mu, varSigma\n",
    "\n",
    "theta = np.zeros((2, ))\n",
    "theta[0] = 0.3  # lengthscale\n",
    "theta[1] = 1.0; # variance"
   ],
   "id": "5ac7b550-e745-40b5-b13c-83591eb7d7ad"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have the surrogate model up and running we need to implement the\n",
    "acquisition function."
   ],
   "id": "60673106-7d77-4251-b5e4-5d80dd808bcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_improvement(f_star, mu, varSigma):\n",
    "    # return the value of the acquisition function at each\n",
    "    \n",
    "    return alpha"
   ],
   "id": "0927f3cf-6268-43ce-8174-2bcb80eb682c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the above code up and running you should be able to\n",
    "reproduce the results that are in Figure 1 in the worksheet. Now lets\n",
    "try to run some additional experiments. First lets evaluate the effect\n",
    "of the initial start locations. Create a plot where on the x-axis have\n",
    "the number of times you have evaluated the true function and on the\n",
    "y-axis have the current minima, run the optimisation loop several times\n",
    "and plot the mean and two standard deviations for the minimal value at\n",
    "each iteration."
   ],
   "id": "4001aeed-340d-4e31-935a-be14dc0580a2"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "implement a loop that tries a set of random-restarts"
   ],
   "id": "e2889cd4-3f1e-467a-adfc-f159366ac7d8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer to Exercise 1 here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "9f7daeb6-ec49-4ab0-ba7c-9dc59b7b0fe1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "for j in range(0, n_starts):\n",
    "    for k in range(0, n_evals):\n",
    "        # Your code here"
   ],
   "id": "b033eeee-6fac-4d04-9043-30b7437453cd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{Explain why the plots looks this way? Does it make a difference how\n",
    "many initial points you start with?}\n",
    "\n",
    "While the function have a local minima so it presents some challenges\n",
    "for optimisation it is still quite easy to find the minima. Let us try\n",
    "make the function a bit more challenging by adding a bit of noise to the\n",
    "function."
   ],
   "id": "c02943de-bf8b-416c-9192-4719df9adb6d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Implement an additional loop around the previous two loops which alters\n",
    "the amount of noise added."
   ],
   "id": "a8ffe85f-6576-4677-bf71-13104a0c1465"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer to Exercise 2 here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "82826154-c31d-4689-9ca8-c37e92e1d36a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a loop that tries different noise-levels\n",
    "np.random.seed(42)\n",
    "for i in range(0, 10):\n",
    "    y = f(x, noise[i])\n",
    "    for j in range(0, n_starts):\n",
    "        for k in range(0, n_evals):\n",
    "            # Your code here"
   ],
   "id": "306287b2-8862-4943-bb27-1ea7308b4f6b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Explain the results by contrasting to the previous none-noisy\n",
    "evaluation. How does the “best” run compare to the “best” run in the\n",
    "previous example?"
   ],
   "id": "af31da31-3fa3-4470-9eba-8636802ca3ab"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 Answer\n",
    "\n",
    "Write your answer to Exercise 3 here\n",
    "\n",
    "As you have probably noticed the kernel-hyperparmeters have a huge\n",
    "effect on the results. This is a desirable effect as this is where we\n",
    "encode our knowledge of the function. We will now do one experiment\n",
    "where we will alter the lengthscale value and see how it effects the\n",
    "results."
   ],
   "id": "9e22cfc9-0473-4d0c-9271-05c6e1f71802"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "\n",
    "For a final extra experiment try to fit the kernel parameters inside the\n",
    "inner-loop. The way to do this is to maximise the marginal likelihood of\n",
    "the surrogate model using gradient descent. You can alter the numpy code\n",
    "that we have implemented to jax instead and which will allow you to use\n",
    "auto-differetiation to compute gradients. Now you can implement a simple\n",
    "gradient descent"
   ],
   "id": "167b91e7-636e-4297-acd5-ab39b659c612"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import grad\n",
    "import jax.numpy as jnp"
   ],
   "id": "d4c0ba0b-f0aa-46a3-ada2-f90577acc1f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_exponential(x1, x2, theta):\n",
    "    # theta[0] - variance\n",
    "    # theta[1] - lengthscale\n",
    "    if x2 == None:\n",
    "        return theta[0]*jnp.exp(-cdist(x1, x1, metric='sqeuclidean')/theta[1]**2)\n",
    "    else:\n",
    "        return theta[0]*jnp.exp(-cdist(x1, x2, metric='sqeuclidean')/theta[1]**2)\n",
    "\n",
    "def logmarginal_likelihood(x, y, theta):\n",
    "    # implement the log-marginal likelihood of a GP\n",
    "    \n",
    "dLdtheta = grad(logmarginal_likelihood, argnums=2)\n",
    "for i in range(1000):\n",
    "    \n",
    "    theta -= dLdtheta(w) * 0.01"
   ],
   "id": "ce458031-74de-4631-88ec-9991372ec836"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [],
   "id": "c78da346-3b90-448b-91d6-c817401d37cf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "You can submit the notebook on Moodle. Name your notebook using your\n",
    "CRSid as `crsid_practical-one.ipynb` before submitting to Moodle.\n",
    "\n",
    "The deadline for the submission is Friday the 4th of November at 23:59."
   ],
   "id": "d0037455-602a-4e6d-88ea-56d611ac9600"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
