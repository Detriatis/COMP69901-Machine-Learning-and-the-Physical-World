---
title: "Sensitivity Analysis"
abstract: "<p>This week we introduce sensitivity analysis through Emukit, showing how Emukit can deliver Sobol indices for understanding how the output of the system is affected by different inputs.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orcid: 
edit_url: https://github.com/lawrennd/talks/edit/gh-pages/_mlphysical/sensitivity-analysis.md
date: 2022-11-03
published: 2022-11-03
time: "12:00"
week: 5
session: 1
featured_image: slides/diagrams/uq/non-zero-sobol-ishigami.svg
reveal: 05-01-sensitivity-analysis.slides.html
transition: None
ipynb: 05-01-sensitivity-analysis.ipynb
youtube: "PtE_EFyUkkE"
layout: lecture
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<h2 id="setup">Setup</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_notebooks/includes/notebook-setup.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_notebooks/includes/notebook-setup.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<!--setupplotcode{import seaborn as sns
sns.set_style('darkgrid')
sns.set_context('paper')
sns.set_palette('colorblind')}-->
<h2 id="notutils">notutils</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/notutils-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/notutils-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>This small package is a helper package for various notebook utilities used</p>
<p>The software can be installed using</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install notutils</span></code></pre></div>
<p>from the command prompt where you can access your python installation.</p>
<p>The code is also available on GitHub: <a href="https://github.com/lawrennd/notutils" class="uri">https://github.com/lawrennd/notutils</a></p>
<p>Once <code>notutils</code> is installed, it can be imported in the usual manner.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> notutils</span></code></pre></div>
<h2 id="pods">pods</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/pods-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/pods-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>In Sheffield we created a suite of software tools for ‘Open Data Science.’ Open data science is an approach to sharing code, models and data that should make it easier for companies, health professionals and scientists to gain access to data science techniques.</p>
<p>You can also check this blog post on <a href="http://inverseprobability.com/2014/07/01/open-data-science">Open Data Science</a>.</p>
<p>The software can be installed using</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pods</span></code></pre></div>
<p>from the command prompt where you can access your python installation.</p>
<p>The code is also available on GitHub: <a href="https://github.com/lawrennd/ods" class="uri">https://github.com/lawrennd/ods</a></p>
<p>Once <code>pods</code> is installed, it can be imported in the usual manner.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pods</span></code></pre></div>
<h2 id="mlai">mlai</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/mlai-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/mlai-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The <code>mlai</code> software is a suite of helper functions for teaching and demonstrating machine learning algorithms. It was first used in the Machine Learning and Adaptive Intelligence course in Sheffield in 2013.</p>
<p>The software can be installed using</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install mlai</span></code></pre></div>
<p>from the command prompt where you can access your python installation.</p>
<p>The code is also available on GitHub: <a href="https://github.com/lawrennd/mlai" class="uri">https://github.com/lawrennd/mlai</a></p>
<p>Once <code>mlai</code> is installed, it can be imported in the usual manner.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install gpy</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pyDOE</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install emukit</span></code></pre></div>
<h2 id="emukit-sensitivity-analysis">Emukit Sensitivity Analysis</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-sensitivity-analysis.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-sensitivity-analysis.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>This introduction is based on <a href="https://github.com/EmuKit/emukit/blob/master/notebooks/Emukit-tutorial-sensitivity-montecarlo.ipynb">Introduction to Global Sensitivity Analysis with Emukit</a> written by Mark Pullin, Javier Gonzalez, Juan Emmanuel Johnson and Andrei Paleyes. Some references include <span class="citation" data-cites="Kennedy-predicting00 Sobol-sensitivity90 Sobol-global01 Saltelli-sensitivity04 Saltelli-global08 Saltelli-variance10">(Kennedy and O’Hagan, 2000; Saltelli et al., 2010, 2008, 2004; Sobol, 2001, 1990)</span></p>
<blockquote>
<p>A possible definition of sensitivity analysis is the following: The study of how uncertainty in the output of a model (numerical or otherwise) can be apportioned to different sources of uncertainty in the model input <span class="citation" data-cites="Saltelli-sensitivity04">(Saltelli et al., 2004)</span>. A related practice is ‘uncertainty analysis,’ which focuses rather on quantifying uncertainty in model output. Ideally, uncertainty and sensitivity analyses should be run in tandem, with uncertainty analysis preceding in current practice.</p>
<p>In Chapter 1 of <span class="citation" data-cites="Saltelli-global08">Saltelli et al. (2008)</span></p>
</blockquote>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> colors <span class="im">as</span> mcolors</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> cm</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pyDOE</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai.plot <span class="im">as</span> plot</span></code></pre></div>
<p>Sensitivity analysis is a statistical technique widely used to test the reliability of real systems. Imagine a simulator of taxis picking up customers in a city like the one showed in the <a href="https://github.com/amzn/emukit-playground">Emukit playground</a>. The profit of the taxi company depends on factors like the number of taxis on the road and the price per trip. In this example, a global sensitivity analysis of the simulator could be useful to decompose the variance of the profit in a way that can be assigned to the input variables of the simulator.</p>
<p>There are different ways of doing a sensitivity analysis of the variables of a simulator. In this notebook we will start with an approach based on Monte Carlo sampling that is useful when evaluating the simulator is cheap. If evaluating the simulator is expensive, emulators can then be used to speed up computations. We will show this in the last part of the notebook. Next, we start with a few formal definitions and literature review so we can understand the basics of Sensitivity Analysis and how it can be performed with Emukit.</p>
<h2 id="local-sensitivity">Local Sensitivity</h2>
<p>Given any function, <span class="math inline">\(g(\cdot)\)</span>, we might be interested in how sensitive that function is to variations in its input space. One route to determining this is to compute the partial derivatives of that function with respect to its inputs, <span class="math display">\[
\frac{\partial}{\partial x_i} g(\mathbf{ x}).
\]</span> The matrix of all these partial derivatives is known as the Jacobian.</p>
<p>These types of local sensitivity analysis can be used for determining the effect of changing an input variable around an operating point. But they don’t give us an understanding of the response of the target function to variations in the input across the domain of inputs. For this, we need to look to <em>global sensitivity analysis</em>.</p>
<h2 id="global-sensitivity-analysis">Global Sensitivity Analysis</h2>
<p>In global sensitivity analysis, rather than looking around a single operating point, we’re interested in the overall sensitivity of a function to its inputs, or combinations of inputs, across its entire domain. The key tool in determining this sensitivity is known as the ANOVA decomposition, or the <em>Hoeffding-Sobol decomposition</em>.</p>
<p>For global sensitivity analysis, we need to make an assumption about how inputs are going to vary to create different values of the function. The fundamental object we’re interested in is the total variance of the function, <span class="math display">\[
\text{var}\left(g(\mathbf{ x})\right) = \left\langle g(\mathbf{ x})^2 \right\rangle _{p(\mathbf{ x})} - \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x})}^2,
\]</span> where <span class="math display">\[
\left\langle h(\mathbf{ x}) \right\rangle _{p(\mathbf{ x})} = \int_\mathbf{ x}h(\mathbf{ x}) p(\mathbf{ x}) \text{d}\mathbf{ x}
\]</span> is the expectation of the function <span class="math inline">\(h(\mathbf{ x})\)</span> under the density <span class="math inline">\(p(\mathbf{ x})\)</span>, which represents the probability distribution of inputs we’re interested in.</p>
<p>The total variance of the function gives us the overall variation of the function across the domain of inputs, as represented by the probability density, <span class="math inline">\(p(\mathbf{ x})\)</span>. Normally, we perform analysis by assuming that, <span class="math display">\[
p(\mathbf{ x}) = \prod_{i=1}^pp(x_i)
\]</span> and that each <span class="math inline">\(p(x_i)\)</span> is <em>uniformly distributed</em> across its input domain. Assuming we scale the input domain down to the interval <span class="math inline">\([0, 1]\)</span>, that gives us <span class="math display">\[
x_i \sim \mathcal{U}\left(0,1\right).
\]</span></p>
<h2 id="hoeffding-sobol-decomposition">Hoeffding-Sobol Decomposition</h2>
<p>The Hoeffding-Sobol, or ANOVA, decomposition of a function allows us to write it as, <span class="math display">\[
\begin{align*}
g(\mathbf{ x}) = &amp; g_0 + \sum_{i=1}^pg_i(x_i) + \sum_{i&lt;j}^{p} g_{ij}(x_i,x_j) + \cdots \\
&amp; + g_{1,2,\dots,p}(x_1,x_2,\dots,x_p),
\end{align*}
\]</span> where <span class="math display">\[
g_0 = \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x})}
\]</span> and <span class="math display">\[
g_i(x_i) = \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x}_{\sim i})} - g_0,
\]</span> where we’re using the notation <span class="math inline">\(p(\mathbf{ x}_{\sim i})\)</span> to represent the input distribution with the <span class="math inline">\(i\)</span>th variable marginalised, <span class="math display">\[
p(\mathbf{ x}_{\sim i}) = \int p(\mathbf{ x}) \text{d}x_i
\]</span> Higher order terms in the decomposition represent interactions between inputs, <span class="math display">\[
g_{i,j}(x_i, x_j) = \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x}_{\sim i,j})} - g_i(x_i) - g_j(x_j) - g_0
\]</span> and similar expressions can be written for higher order terms up to <span class="math inline">\(g_{1,2,\dots,p}(\mathbf{ x})\)</span>.</p>
<p>Note that to compute each of these individual terms, you need to first compute the low order terms, and then compute the high order terms. This can be problematic when <span class="math inline">\(p\)</span> is large.</p>
<p>We’re interested in the variance of the function <span class="math inline">\(g\)</span>, so implicitly we’re assuming that the square of this function is integrable across its domain, i.e., we’re assuming that <span class="math inline">\(\left\langle g(\mathbf{ x})^2 \right\rangle _{p(\mathbf{ x})}\)</span> exists and is finite.</p>
<p>The Sobol decomposition has some important properties, in particular, its components are orthogonal, so this means that when we substitute it in to the variance, we have, <span class="math display">\[
\begin{align*}
\text{var}(g) = &amp; \left\langle g(\mathbf{ x})^2  \right\rangle _{p(\mathbf{ x})} - \left\langle g(\mathbf{ x}) \right\rangle _{p(\mathbf{ x})}^2 \\
 = &amp; \left\langle g(\mathbf{ x})^2  \right\rangle _{p(\mathbf{ x})} - g_0^2\\
 = &amp; \sum_{i=1}^p\text{var}\left(g_i(x_i)\right) + \sum_{i&lt;j}^{p} \text{var}\left(g_{ij}(x_i,x_j)\right)  + \cdots \\ &amp; + \text{var}\left(g_{1,2,\dots,p}(x_1,x_2,\dots,x_p)\right).
\end{align*}
\]</span> So, this decomposition gives us a decomposition of the function in terms of variances. It’s for this reason that it’s sometimes known as an ANOVA decomposition. ANOVA stands a for <em>analysis of variance</em>. The ANOVA decomposition decomposes the function into additive variance parts that are each stemming from interactions between different inputs.</p>
<p>As is common in various analyses of variance, we can rescale the components with the <em>total variance</em> of the function. These rescaled components are known as <em>Sobol indicies</em>. <span class="math display">\[
S_\ell = \frac{\text{var}\left(g(\mathbf{ x}_\ell)\right)}{\text{var}\left(g(\mathbf{ x})\right)},
\]</span> where the <span class="math inline">\(\ell\)</span> represents the relevent set of indices for the different combinations of inputs.</p>
<p>In practice, for an elegant approach that exploits a particular covariance function structure to perform global sensitivity analysis see <span class="citation" data-cites="Durrande-anova13">Durrande et al. (2013)</span>.</p>
<h1 id="example-the-ishigami-function">Example: the Ishigami function</h1>
<p>We illustrate the exact calculation of the Sobol indices with the three-dimensional Ishigami function of <span class="citation" data-cites="Ishigami-importance90">(Ishigami and Homma, 1989)</span>.</p>
<h3 id="ishigami-function">Ishigami Function</h3>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/ishigami-function.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/ishigami-function.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The Ishigami function <span class="citation" data-cites="Ishigami-importance90">(Ishigami and Homma, 1989)</span> is a well-known test function for uncertainty and sensitivity analysis methods because of its strong nonlinearity and peculiar dependence on <span class="math inline">\(x_3\)</span>. More details of this function can be found in <span class="citation" data-cites="Sobol-variance99">(Sobol and Levitan, 1999)</span>.</p>
<p>Mathematically, the form of the Ishigami function is <span class="math display">\[
g(\textbf{x}) = \sin(x_1) + a \sin^2(x_2) + b x_3^4 \sin(x_1). 
\]</span> We will set the parameters to be <span class="math inline">\(a = 5\)</span> and <span class="math inline">\(b=0.1\)</span> . The input variables are sampled randomly <span class="math inline">\(x_i \sim \mathcal{U}\left(-\pi,\pi\right)\)</span>.</p>
<p>Next, we create the function object and visualize its shape marginally for each one of its three inputs.</p>
<p>Load the Ishigami function</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.test_functions.sensitivity <span class="im">import</span> Ishigami</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>ishigami <span class="op">=</span> Ishigami(a<span class="op">=</span><span class="dv">5</span>, b<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>target_function <span class="op">=</span> ishigami.fidelity1</span></code></pre></div>
<p>That gives us the target function, next we define the input space for the simulator.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core <span class="im">import</span> ContinuousParameter, ParameterSpace</span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>variable_domain <span class="op">=</span> (<span class="op">-</span>np.pi,np.pi)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>           </span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>space <span class="op">=</span> ParameterSpace(</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>          [ContinuousParameter(<span class="st">&#39;x1&#39;</span>, <span class="op">*</span>variable_domain), </span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;x2&#39;</span>, <span class="op">*</span>variable_domain),</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;x3&#39;</span>, <span class="op">*</span>variable_domain)])</span></code></pre></div>
<p>Before moving to any further analysis, we first plot the non-zero components <span class="math inline">\(g(\mathbf{ x})\)</span>. These components are <span class="math display">\[
\begin{align*}
g_1(x_1) &amp; = \sin(x_1) \\
g_2(x_2) &amp; = a \sin^2 (x_2) \\
g_{13}(x_1,x_3) &amp; = b x_3^4 \sin(x_1) 
\end{align*}
\]</span></p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>x_grid <span class="op">=</span> np.linspace(<span class="op">*</span>variable_domain,<span class="dv">100</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>target_simulator <span class="op">=</span> ishigami.fidelity1</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>f1 <span class="op">=</span> ishigami.f1(x_grid)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>f2 <span class="op">=</span> ishigami.f2(x_grid)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>F13 <span class="op">=</span> ishigami.f13(np.array([x_grid,x_grid]).T)[:,np.newaxis]</span></code></pre></div>
<div class="figure">
<div id="non-zero-sobol-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/non-zero-sobol-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="non-zero-sobol-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;non-zero-sobol-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="non-zero-sobol-ishigami-caption" class="caption-frame">
<p>Figure: The non-zero components of the Ishigami function.</p>
</div>
</div>
<h2 id="total-variance">Total Variance</h2>
<p>The total variance <span class="math inline">\(\text{var}(y)\)</span> in this example is</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ishigami.variance_total)</span></code></pre></div>
<p>which is the sum of the variance of <span class="math inline">\(\text{var}\left(g_1(x_1)\right)\)</span>, <span class="math inline">\(\text{var}\left(g_2(x_2)\right)\)</span> and <span class="math inline">\(\text{var}\left(g_{1,3}(x_{1,3})\right)\)</span></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ishigami.variance_x1, ishigami.variance_x2, ishigami.variance_x13)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ishigami.variance_x1 <span class="op">+</span> ishigami.variance_x2 <span class="op">+</span> ishigami.variance_x13)</span></code></pre></div>
<h2 id="first-order-sobol-indices-using-monte-carlo">First Order Sobol Indices using Monte Carlo</h2>
<p>The first order Sobol indices are a measure of “first order sensitivity” of each input variable. They account for the proportion of variance of <span class="math inline">\(y\)</span> explained by changing each variable alone while marginalizing over the rest. Recall that the Sobol index of the <span class="math inline">\(i\)</span>th variable is computed as <span class="math display">\[
S_i = \frac{\text{var}\left(g_i(x_i)\right)}{\text{var}\left(g(\mathbf{ x})\right)}.
\]</span> This value is standardized using the total variance, so it is possible to account for a fractional contribution of each variable to the total variance of the output.</p>
<p>The Sobol indices for higher order interactions <span class="math inline">\(S_{i,j}\)</span> are computed similarly. Due to the normalization by the total variance, the the sum of all Sobol indices equals to one.</p>
<p>In most cases we are interested in the first order indices. The Ishigami function has the benefit that these can be computed analytically. In <code>EmuKit</code> you can extract these values with the code.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>ishigami.main_effects</span></code></pre></div>
<p>But in general, these indices need to be sampled using Monte Carlo or one of the quasi-Monte Carlo methods we’ve seen in the model-free experimental design. Details are given in <span class="citation" data-cites="Sobol-global01">(Sobol, 2001)</span>.</p>
<p>With Emukit, the first-order Sobol indices can be easily computed. We first need to define the space where the target simulator is analyzed.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.sensitivity.monte_carlo <span class="im">import</span> ModelFreeMonteCarloSensitivity</span></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">10</span>)  <span class="co"># for reproducibility</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>num_monte_carlo_points <span class="op">=</span> <span class="dv">10000</span>  <span class="co"># Number of MC samples</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>senstivity_ishigami <span class="op">=</span> ModelFreeMonteCarloSensitivity(target_simulator, space)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>main_effects, total_effects, _ <span class="op">=</span> senstivity_ishigami.compute_effects(num_monte_carlo_points <span class="op">=</span> num_monte_carlo_points)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(main_effects)</span></code></pre></div>
<p>We compare the true effects with the Monte Carlo effects in a bar-plot. The total effects are discussed later.</p>
<div class="figure">
<div id="first-order-sobol-indices-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/first-order-sobol-indices-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="first-order-sobol-indices-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;first-order-sobol-indices-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="first-order-sobol-indices-ishigami-caption" class="caption-frame">
<p>Figure: The non-zero components of the Ishigami function.</p>
</div>
</div>
<h2 id="total-effects-using-monte-carlo">Total Effects Using Monte Carlo</h2>
<p>Computing high order sensitivity indices can be computationally very demanding in high dimensional scenarios and measuring the total influence of each variable on the variance of the output is infeasible. To solve this issue the <em>total</em> indices are used which account for the contribution to the output variance of <span class="math inline">\(x_i\)</span> including all variance caused by the variable alone and all its interactions of any order.</p>
<p>The total effect for <span class="math inline">\(x_i\)</span> is given by: <span class="math display">\[ 
S_{Ti} = \frac{\left\langle \text{var}_{x_i} (y\mid \mathbf{ x}_{\sim i}) \right\rangle _{p(\mathbf{ x}_{\sim i})}}{\text{var}\left(g(\mathbf{ x})\right)} = 1 - \frac{\text{var}_{\mathbf{ x}_{\sim i}} \left\langle y\mid \mathbf{ x}_{\sim i} \right\rangle _{p(\mathbf{ x}_{\sim i})}}{\text{var}\left(g(\mathbf{ x})\right)}
\]</span></p>
<p>Note that the sum of <span class="math inline">\(S_{Ti}\)</span> is not necessarily one in this case unless the model is additive. In the Ishigami example the value of the total effects is</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>ishigami.total_effects</span></code></pre></div>
<p>As in the previous example, the total effects can be computed with Monte Carlo. In the next plot we show the comparison with the true total effects.</p>
<div class="figure">
<div id="total-effects-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/total-effects-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="total-effects-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;total-effects-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="total-effects-ishigami-caption" class="caption-frame">
<p>Figure: The total effects from the Ishigami function as computed via Monte Carlo estimate alongside the true total effects for the Ishigami function.</p>
</div>
</div>
<h2 id="computing-the-sensitivity-indices-using-the-output-of-a-model">Computing the Sensitivity Indices Using the Output of a Model</h2>
<p>In the example used above the Ishigami function is very cheap to evaluate. However, in most real scenarios the functions of interest are expensive, and we need to limit ourselves to a few number of evaluations. Using Monte Carlo methods is infeasible in these scenarios as a large number of samples are typically required to provide good estimates of the Sobol indices.</p>
<p>An alternative in these cases is to use Gaussaian process emulator of the function of interest trained on a few inputs and outputs <span class="citation" data-cites="Marrel-sobol09">(Marrel et al., 2009)</span>. If the model is properly trained, its mean prediction which is cheap to evaluate, can be used to compute the Monte Carlo estimates of the Sobol indices, the variance from the GP emulator can also be used to assess our uncertainty about the Sobol indices. Let’s see how we can do this in Emukit.</p>
<p>We start by generating 100 samples in the input domain. Note that this a just 1% of the number of samples that we used to compute the Sobol coefficients using Monte Carlo.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core.initial_designs <span class="im">import</span> RandomDesign</span></code></pre></div>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>design <span class="op">=</span> RandomDesign(space)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> design.get_samples(<span class="dv">500</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> ishigami.fidelity1(x)[:,np.newaxis]</span></code></pre></div>
<p>Now, we fit a standard Gaussian process to the samples, and we wrap it as an Emukit model.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> GPy.models <span class="im">import</span> GPRegression</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.model_wrappers <span class="im">import</span> GPyModelWrapper</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.sensitivity.monte_carlo <span class="im">import</span> MonteCarloSensitivity</span></code></pre></div>
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>model_gpy <span class="op">=</span> GPRegression(x,y)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>model_emukit <span class="op">=</span> GPyModelWrapper(model_gpy)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>model_emukit.optimize()</span></code></pre></div>
<p>The final step is to compute the coefficients using the class <code>ModelBasedMonteCarloSensitivity</code> which directly calls the model and uses its predictive mean to compute the Monte Carlo estimates of the Sobol indices. We plot the true estimates, those computed using 10000 direct evaluations of the object using Monte Carlo and those computed using a Gaussian process model trained on 100 evaluations.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>num_mc <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>senstivity_ishigami_gpbased <span class="op">=</span> MonteCarloSensitivity(model <span class="op">=</span> model_emukit, input_domain <span class="op">=</span> space)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>main_effects_gp, total_effects_gp, _ <span class="op">=</span> senstivity_ishigami_gpbased.compute_effects(num_monte_carlo_points <span class="op">=</span> num_mc)</span></code></pre></div>
<div class="figure">
<div id="first-order-sobol-indices-gp-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/first-order-sobol-indices-gp-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="first-order-sobol-indices-gp-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;first-order-sobol-indices-gp-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="first-order-sobol-indices-gp-ishigami-caption" class="caption-frame">
<p>Figure: First order Sobol indices as estimated by Monte Carlo and GP-emulator based Monte Carlo.</p>
</div>
</div>
<div class="figure">
<div id="total-effects-sobol-indices-gp-ishigami-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/total-effects-sobol-indices-gp-ishigami.svg" width="80%" style=" ">
</object>
</div>
<div id="total-effects-sobol-indices-gp-ishigami-magnify" class="magnify" onclick="magnifyFigure(&#39;total-effects-sobol-indices-gp-ishigami&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="total-effects-sobol-indices-gp-ishigami-caption" class="caption-frame">
<p>Figure: Total effects as estimated by Monte Carlo and GP based Monte Carlo.</p>
</div>
</div>
<p>We observe some discrepancies with respect to the real value of the Sobol index when using the Gaussian process, but we get a fairly good approximation with a very reduced number of evaluations of the original target function.</p>
<h2 id="conclusions">Conclusions</h2>
<p>The Sobol indices are a tool for explaining the variance of the output of a function as components of the input variables. Monte Carlo is an approach for computing these indices if the function is cheap to evaluate. Other approaches are needed when <span class="math inline">\(g(\cdot)\)</span> is expensive to compute.</p>
<h2 id="catapult-simulation">Catapult Simulation</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/catapult-simulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/catapult-simulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip0">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Nicolas Durrande
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/nicolas-durrande2.jpg" clip-path="url(#clip0)"/>
</svg>
<p>As a worked example we’re going to introduce a catapult simulation written by Nicolas Durrande, <a href="https://durrande.shinyapps.io/catapult/" class="uri">https://durrande.shinyapps.io/catapult/</a>.</p>
<div class="figure">
<div id="catapult-simulation-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/catapult-simulation.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="catapult-simulation-magnify" class="magnify" onclick="magnifyFigure(&#39;catapult-simulation&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="catapult-simulation-caption" class="caption-frame">
<p>Figure: A catapult simulation for experimenting with surrogate models, kindly provided by Nicolas Durrande</p>
</div>
</div>
<p>The simulator allows you to set various parameters of the catapult including the axis of rotation, <code>roation_axis</code>, the position of the arm stop, <code>arm_stop</code>, and the location of the two bindings of the catapult’s spring, <code>spring_binding_1</code> and <code>spring_binding_2</code>.</p>
<p>These parameters are then collated in a vector, <span class="math display">\[
\mathbf{ x}_i = \begin{bmatrix}
\texttt{rotation_axis} \\
\texttt{arm_stop} \\
\texttt{spring_binding_1} \\
\texttt{spring_binding_2}
\end{bmatrix}
\]</span></p>
<p>Having set those parameters, you can run an experiment, by firing the catapult. This will show you how far it goes.</p>
<p>Because you will need to operate the catapult yourself, we’ll create a function to query you about the result of an individual firing.</p>
<p>We can also set the parameter space for the model. Each of these variables is scaled to operate <span class="math inline">\(\in [0, 1]\)</span>.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core <span class="im">import</span> ContinuousParameter, ParameterSpace</span></code></pre></div>
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>variable_domain <span class="op">=</span> [<span class="dv">0</span>,<span class="dv">1</span>]</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>           </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>space <span class="op">=</span> ParameterSpace(</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>          [ContinuousParameter(<span class="st">&#39;rotation_axis&#39;</span>, <span class="op">*</span>variable_domain), </span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;arm_stop&#39;</span>, <span class="op">*</span>variable_domain),</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;spring_binding_1&#39;</span>, <span class="op">*</span>variable_domain),</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>           ContinuousParameter(<span class="st">&#39;spring_binding_2&#39;</span>, <span class="op">*</span>variable_domain)])</span></code></pre></div>
<p>Before we perform sensitivity analysis, we need to build an emulator of the catapulter, which we do using our experimental design process.</p>
<h2 id="experimental-design-for-the-catapult">Experimental Design for the Catapult</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span class="editsection" style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/catapult-experimental-design.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/catapult-experimental-design.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Now we will build an emulator for the catapult using the experimental design loop.</p>
<p>We’ll start with a small model-free design, we’ll use a random design for initializing our model.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.core.initial_designs <span class="im">import</span> RandomDesign</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>design <span class="op">=</span> RandomDesign(space)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> design.get_samples(<span class="dv">5</span>)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> catapult_distance(x)</span></code></pre></div>
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> GPy.models <span class="im">import</span> GPRegression</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.model_wrappers <span class="im">import</span> GPyModelWrapper</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.sensitivity.monte_carlo <span class="im">import</span> MonteCarloSensitivity</span></code></pre></div>
<p>Set up the GPy model. The variance of the RBF kernel is set to <span class="math inline">\(150^2\)</span> because that’s roughly the square of the range of the catapult. We set the noise variance to a small value.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>model_gpy <span class="op">=</span> GPRegression(x,y)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>model_gpy.kern.variance <span class="op">=</span> <span class="dv">150</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>model_gpy.likelihood.variance.fix(<span class="fl">1e-5</span>)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>display(model_gpy)</span></code></pre></div>
<p>Wrap the model for EmuKit.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>model_emukit <span class="op">=</span> GPyModelWrapper(model_gpy)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>model_emukit.optimize()</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>display(model_gpy)</span></code></pre></div>
<p>Now we set up the model loop. We’ll use integrated variance reduction as the acquisition function for our model-based design loop.</p>
<p><em>Warning</em>: This loop runs much slower on Google <code>colab</code> than on a local machine.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.experimental_design.experimental_design_loop <span class="im">import</span> ExperimentalDesignLoop</span></code></pre></div>
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> emukit.experimental_design.acquisitions <span class="im">import</span> IntegratedVarianceReduction, ModelVariance</span></code></pre></div>
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>integrated_variance <span class="op">=</span> IntegratedVarianceReduction(space<span class="op">=</span>space,</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>                                                  model<span class="op">=</span>model_emukit)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>ed <span class="op">=</span> ExperimentalDesignLoop(space<span class="op">=</span>space, </span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>                            model<span class="op">=</span>model_emukit, </span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>                            acquisition <span class="op">=</span> integrated_variance)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>ed.run_loop(catapult_distance, <span class="dv">10</span>)</span></code></pre></div>
<h2 id="sensitivity-analysis-of-a-catapult-simulation">Sensitivity Analysis of a Catapult Simulation</h2>
<p>The final step is to compute the coefficients using the class <code>ModelBasedMonteCarloSensitivity</code> which directly calls the model and uses its predictive mean to compute the Monte Carlo estimates of the Sobol indices. We plot the estimates of the Sobol indices computed using a Gaussian process model trained on the observations we’ve acquired.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>num_mc <span class="op">=</span> <span class="dv">10000</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>senstivity <span class="op">=</span> MonteCarloSensitivity(model <span class="op">=</span> model_emukit, input_domain <span class="op">=</span> space)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>main_effects_gp, total_effects_gp, _ <span class="op">=</span> senstivity.compute_effects(num_monte_carlo_points <span class="op">=</span> num_mc)</span></code></pre></div>
<div class="figure">
<div id="first-order-sobol-indices-gp-catapult-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/first-order-sobol-indices-gp-catapult.svg" width="80%" style=" ">
</object>
</div>
<div id="first-order-sobol-indices-gp-catapult-magnify" class="magnify" onclick="magnifyFigure(&#39;first-order-sobol-indices-gp-catapult&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="first-order-sobol-indices-gp-catapult-caption" class="caption-frame">
<p>Figure: First Order sobol indices as estimated by GP-emulator based Monte Carlo on the catapult.</p>
</div>
</div>
<div class="figure">
<div id="total-effects-sobol-indices-gp-catapult-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/total-effects-sobol-indices-gp-catapult.svg" width="80%" style=" ">
</object>
</div>
<div id="total-effects-sobol-indices-gp-catapult-magnify" class="magnify" onclick="magnifyFigure(&#39;total-effects-sobol-indices-gp-catapult&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="total-effects-sobol-indices-gp-catapult-caption" class="caption-frame">
<p>Figure: Total effects as estimated by GP based Monte Carlo on the catapult.</p>
</div>
</div>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></li>
<li>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></li>
<li>blog: <a href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Durrande-anova13" class="csl-entry" role="doc-biblioentry">
Durrande, N., Ginsbourger, D., Olivier, Carraro, L., 2013. <span>ANOVA</span> kernels and <span>RKHS</span> of zero mean functions for model-based sensitivity analysis. Journal of Multivariate Analysis 115, 57–67. https://doi.org/<a href="https://doi.org/10.1016/j.jmva.2012.08.016">https://doi.org/10.1016/j.jmva.2012.08.016</a>
</div>
<div id="ref-Ishigami-importance90" class="csl-entry" role="doc-biblioentry">
Ishigami, T., Homma, T., 1989. An importance quantification technique in uncertainty analysis for computer models. [1990] Proceedings. First International Symposium on Uncertainty Modeling and Analysis 398–403.
</div>
<div id="ref-Kennedy-predicting00" class="csl-entry" role="doc-biblioentry">
Kennedy, M.C., O’Hagan, A., 2000. Predicting the output from a complex computer code when fast approximations are available. Biometrika 87, 1–13.
</div>
<div id="ref-Marrel-sobol09" class="csl-entry" role="doc-biblioentry">
Marrel, A., Iooss, B., Laurent, B., Roustant, O., 2009. Calculations of <span>S</span>obol indices for the <span>G</span>aussian process metamodel. Reliability Engineering &amp; System Safety 94, 742–751. https://doi.org/<a href="https://doi.org/10.1016/j.ress.2008.07.008">https://doi.org/10.1016/j.ress.2008.07.008</a>
</div>
<div id="ref-Saltelli-variance10" class="csl-entry" role="doc-biblioentry">
Saltelli, A., Annoni, P., Azzini, I., Campolongo, F., Ratto, M., Tarantola, S., 2010. Variance based sensitivity analysis of model output. Design and estimator for the total sensitivity index. Computer Physics Communications 181, 259–270. <a href="https://doi.org/10.1016/j.cpc.2009.09.018">https://doi.org/10.1016/j.cpc.2009.09.018</a>
</div>
<div id="ref-Saltelli-global08" class="csl-entry" role="doc-biblioentry">
Saltelli, A., Ratto, M., Andres, T., Campolongo, F., Cariboni, J., Gatelli, D., Saisana, M., Tarantola, S., 2008. Global sensitivity analysis: The primer. wiley.
</div>
<div id="ref-Saltelli-sensitivity04" class="csl-entry" role="doc-biblioentry">
Saltelli, A., Tarantola, S., Campolongo, F., Ratto, M., 2004. Sensitivity analysis in practice: A guide to assessing scientific methods. wiley.
</div>
<div id="ref-Sobol-global01" class="csl-entry" role="doc-biblioentry">
Sobol, I.M., 2001. Global sensitivity indices for nonlinear mathematical models and their <span>M</span>onte <span>C</span>arlo estimates. Mathematics and Computers in Simulation 55, 271–280. <a href="https://doi.org/10.1016/S0378-4754(00)00270-6">https://doi.org/10.1016/S0378-4754(00)00270-6</a>
</div>
<div id="ref-Sobol-sensitivity90" class="csl-entry" role="doc-biblioentry">
Sobol, I.M., 1990. On sensitivity estimation for nonlinear mathematical models. Matematicheskoe Modelirovanie 2, 112–118.
</div>
<div id="ref-Sobol-variance99" class="csl-entry" role="doc-biblioentry">
Sobol, I.M., Levitan, Y.L., 1999. On the use of variance reducing multipliers in <span>M</span>onte <span>C</span>arlo computations of a global sensitivity index. Computer Physics Communications 117, 52–61. <a href="https://doi.org/10.1016/S0010-4655(98)00156-8">https://doi.org/10.1016/S0010-4655(98)00156-8</a>
</div>
</div>

