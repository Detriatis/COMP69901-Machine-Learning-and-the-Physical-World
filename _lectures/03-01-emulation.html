---
title: "Emulation"
abstract: "<p>In this lecture we motivate the use of emulation and
introduce the GPy software as a framework for building Gaussian process
emulators.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: http://inverseprobability.com
  institute: University of Cambridge
  twitter: lawrennd
  gscholar: r3SJcvoAAAAJ
  orcid: 
edit_url: https://github.com/lawrennd/talks/edit/gh-pages/_mlphysical/emulation.md
date: 2023-10-24
published: 2023-10-24
time: "12:00"
week: 3
session: 1
featured_image: slides/diagrams/uq/emukit-playground-bayes-opt.png
reveal: 03-01-emulation.slides.html
transition: None
ipynb: 03-01-emulation.ipynb
youtube: "Zw2es1Khu_c"
layout: lecture
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<!--setupplotcode{import seaborn as sns
sns.set_style('darkgrid')
sns.set_context('paper')
sns.set_palette('colorblind')}-->
<h2 id="notutils">notutils</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/notutils-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/notutils-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>This small package is a helper package for various notebook utilities
used below.</p>
<p>The software can be installed using</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install notutils</span></code></pre></div>
<p>from the command prompt where you can access your python
installation.</p>
<p>The code is also available on GitHub: <a
href="https://github.com/lawrennd/notutils"
class="uri">https://github.com/lawrennd/notutils</a></p>
<p>Once <code>notutils</code> is installed, it can be imported in the
usual manner.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> notutils</span></code></pre></div>
<h2 id="mlai">mlai</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/mlai-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/mlai-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The <code>mlai</code> software is a suite of helper functions for
teaching and demonstrating machine learning algorithms. It was first
used in the Machine Learning and Adaptive Intelligence course in
Sheffield in 2013.</p>
<p>The software can be installed using</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install mlai</span></code></pre></div>
<p>from the command prompt where you can access your python
installation.</p>
<p>The code is also available on GitHub: <a
href="https://github.com/lawrennd/mlai"
class="uri">https://github.com/lawrennd/mlai</a></p>
<p>Once <code>mlai</code> is installed, it can be imported in the usual
manner.</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<h1 id="emulation">Emulation</h1>
<p>There are a number of ways we can use machine learning to accelerate
scientific discovery. But one way is to have the machine learning model
learn the effect of the rules. Rather than worrying about the detail of
the rules through computing each step, we can have the machine learning
model look to abstract the rules and capture emergent phenomena, just as
the Maxwell-Boltzmann distribution captures the essence of the behavior
of the ideal gas.</p>
<p>The challenges of Laplace’s gremlin present us with issues that we
solve in a particular way, this is the focus of Chapter 6 in <em>The
Atomic Human</em>.</p>
<h1 id="the-atomic-human">The Atomic Human</h1>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_books/includes/the-atomic-human.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_books/includes/the-atomic-human.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="the-atomic-human-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//books/the-atomic-human.jpg" width="40%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="the-atomic-human-magnify" class="magnify"
onclick="magnifyFigure(&#39;the-atomic-human&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="the-atomic-human-caption" class="caption-frame">
<p>Figure: <a href="https://www.amazon.co.uk/dp/B0CGZHBSLL">The Atomic
Human</a> <span class="citation"
data-cites="Lawrence-atomic24">(Lawrence, 2024)</span> due for release
in June 2024.</p>
</div>
</div>
<p>What follows is a quote form Chapter 6, which introduces Laplace’s
gremlin and its consequences.</p>
<p>In Douglas Adams’s <em>Hitchhiker’s Guide to the Galaxy</em> the
computer Deep Thought is asked to provide the answer to the ‘great
question’ of ‘life, the universe and everything’. After seven and a half
million years of computation, Deep Thought has completed its program but
is reluctant to give its creators the answer.</p>
<blockquote>
<p>‘You’re really not going to like it,’ observed Deep Thought.<br />
‘Tell us!’<br />
‘All right,’ said Deep Thought. ‘The Answer to the Great Question . .
.’<br />
‘Yes . . . !’<br />
‘Of Life, the Universe and Everything …’ said Deep Thought.<br />
‘Yes … !’<br />
‘Is …’ said Deep Thought, and paused.<br />
‘Yes … !’<br />
‘Is …’<br />
‘Yes … !!! … ?’<br />
‘Forty-two,’ said Deep Thought, with infinite majesty and calm.</p>
<p>Douglas Adams <em>The Hitchhiker’s Guide to the Galaxy</em>, 1979,
Chapter 27</p>
</blockquote>
<p>After a period of shock from the questioners, the machine goes on to
explain.</p>
<blockquote>
<p>‘I checked it very thoroughly,’ said the computer, ‘and that quite
definitely is the answer. I think the problem, to be quite honest with
you, is that you’ve never actually known what the question is.’</p>
<p>Douglas Adams <em>The Hitchhiker’s Guide to the Galaxy</em>, 1979,
Chapter 28</p>
</blockquote>
<p>To understand the question, Deep Thought goes on to agree to design a
computer which will work out what the question is. In the book that
machine is the planet Earth, and its operators are mice. Deep Thought’s
idea is that the mice will observe the Earth and their observations will
allow them to know what the Great Question is.</p>
<p>To understand the consequences of Hawking’s Theory of Everything, we
would have to carry out a scheme similar to Deep Thought’s. The Theory
wouldn’t directly tell us that hurricanes exist or that when the sun
sets on Earth the sky will have a red hue. It wouldn’t directly tell us
that water will boil at 100 degrees centigrade. These consequences of
the Theory would only play out once it was combined with the data to
give us the emergent qualities of the Universe. The Deep Thought problem
hints at the intractability of doing this. The computation required to
make predictions from Laplace’s demon can be enormous, Deep Thought
intends to create a planet to run it. As a result, this isn’t how our
intelligence works in practice. The computations required are just too
gargantuan. Relative to the scale of the Universe our brains are
extremely limited. Fortunately though, to make these predictions, we
don’t have to build our own Universe, because we’ve already got one.</p>
<div class="figure">
<div id="pooh-rabbit-hoosh-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//ml/E.-H.-Shepard_Two-ink-drawings-from-The-House-at-Pooh-Corner-I_.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="pooh-rabbit-hoosh-magnify" class="magnify"
onclick="magnifyFigure(&#39;pooh-rabbit-hoosh&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="pooh-rabbit-hoosh-caption" class="caption-frame">
<p>Figure: Rabbit and Pooh watch the result of Pooh’s hooshing idea to
move Eeyore towards the shore.</p>
</div>
</div>
<blockquote>
<p>When you are a Bear of Very Little Brain, and you Think of Things,
you find sometimes that a Thing which seemed very Thingish inside you is
quite different when it gets out into the open and has other people
looking at it.</p>
<p>A.A. Milne as Winnie-the-Pooh in <em>The House at Pooh Corner</em>,
1928</p>
</blockquote>
<p>This comment from Pooh bear comes just as he’s tried to rescue his
donkey friend, Eeyore, from a river by dropping a large stone on him
from a bridge. Pooh’s idea had been to create a wave to push the donkey
to the shore, a process that Pooh’s rabbit friend calls “hooshing”.</p>
<p>Hooshing is a technique many children will have tried to retrieve a
ball from a river. It can work, so Pooh’s idea wasn’t a bad one, but the
challenge he faced was in its execution. Pooh aimed to the side of
Eeyore, unfortunately the stone fell directly on the stuffed donkey. But
where is Laplace’s demon in hooshing? Just as we can talk about Gliders
and Loafers in Conway’s Game of Life, we talk about stones and donkeys
in our Universe. Pooh’s prediction that he can hoosh the donkey with the
stone is not based on the Theory, it comes from observing the way
objects interact in the actual Universe. Pooh is like the mice in
Douglas Adams’s Earth. He is observing his environment. He looks for
patterns in that environment. Pooh then borrows the computation that the
Universe has already done for us. He has seen similar situations before,
perhaps he once used a stone to hoosh a ball. He is then generalising
from these previous circumstances to suggest that he can also hoosh the
donkey. Despite being a bear of little brain, like the mice on Adams’s
Earth, Pooh can answer questions about his universe by observing the
results of the Theory of Everything playing out around him.</p>
<h1 id="surrogate-modelling-in-practice">Surrogate Modelling in
Practice</h1>
<p>In the papers we reviewed last lecture, neural networks are being
used to speed up computations. In this course we’ve introduced Gaussian
processes that will be used to speed up these computations. In both
cases the ideas are similar. Rather than rerunning the simulation, we
use data from the simulation to <em>fit</em> the neural network or the
Gaussian process to the data.</p>
<p>We’ll see an example of how this is done in a moment, taken from a
simple ride hailing simulator, but before we look at that, we’ll first
consider why this might be a useful approach.</p>
<p>As we’ve seen from the very simple rules in the Game of Life,
emergent phenomena we might be interested in take computation power to
discover, just as Laplace’s and Dirac’s quotes suggest. The objective in
surrogate modelling is to harness machine learning models to learn those
physical characteristics.</p>
<h2 id="types-of-simulations">Types of Simulations</h2>
<p>We’ve introduced simulations from the perspective of laws of physics.
In practice, many simulations may not directly encode for the laws of
physics, but they might encode expert intuitions about a problem (like
Pooh’s intuition about hooshing).</p>
<p>For example, in Formula 1 races, the cars have tyres that wear at
different rates. Softer tyres allow the cars to drive faster but wear
quicker. Harder tyres man the car drives slower but they last longer.
Changing between tyres is part of the race, and it has a time penalty.
Before each race the teams decide what their strategy will be with tyre
changes. It’s not only how many tyre changes that are important, but
when they happen. If you change your tyre early, you might get a speed
advantage and be able to pass your rival when they change their tyre
later. This is a trick known as ‘undercutting’, but if your early change
puts you back onto the track behind other slower cars, you will lose
this advantage.</p>
<p>Formula 1 teams determine their strategy through simulating the race.
Each team knows how fast other teams are around the track, and what
their top speeds are. So, the teams simulate many thousands or millions
of races with different strategies for their rivals, and they choose the
strategy for which they maximize their number of expected points.</p>
<p>When many simulations are done, the results take time to come. During
the actual race, the simulations are too slow to provide the real time
information teams would need. In this case F1 teams can use emulators,
models that have learnt the effect of the simulations, to give real time
updates.</p>
<p>Formula 1 race simulations contain assumptions that derive from
physics but don’t directly encode the physical laws. For example, if one
car is stuck behind another, in any given lap, it might overtake. A
typical race simulation will look at the lap speed of each car and the
top speed of each car (as measured in ‘speed traps’ that are placed on
the straight). It will assume a probability of overtake for each lap
that is a function of these values. Of course, underlying that function
is the physics of how cars overtake each other, but that can be
abstracted away into a simpler function that the Race Strategy Engineer
defines from their knowledge and previous experience.</p>
<p>Many simulations have this characteristic: major parts of the
simulation are the result of encoding expert knowledge in the code. But
this can lead to challenges. I once asked a strategy engineer, who had
completed a new simulation, how it was going. He replied that things had
started out well, but over time its performance was degrading. We
discussed this for a while and over time a challenge of mis-specified
granularity emerged.</p>
<h2 id="fidelity-of-the-simulation">Fidelity of the Simulation</h2>
<p>The engineer explained how there’d been a race where the simulation
had suggested that their main driver <em>shouldn’t</em> pit because he
would have emerged behind a car with a slower lap speed, but a high
top-speed. This would have made that car difficult to overtake. However,
the driver of that slower car was also in the team’s ‘development
program’, so everyone in the team knew that the slower car would have
moved aside to let their driver through. Unfortunately, the simulation
didn’t know this. So, the team felt the wrong stategy decision was made.
After the race, the simulation was updated to include a special case for
this situation. The new code checked whether the slower car was a
development driver, making it ‘more realistic’.</p>
<p>Over time there were a number of similar changes, each of which
should have improved the simulation, but the reality was the code was
now ‘mixing granularities’. The formula for computing the probability of
overtake as a function of speeds is one that is relatively easy to
verify. It ignores the relationships between drivers, whether a given
driver is a development driver, whether one bears a grudge or not,
whether one is fighting for their place in the team. That’s all
assimilated into the equation. The original equation is easy to
calibrate, but as soon as you move to a finer granularity and consider
more details about individual drivers, the model seems more realistic,
but it becomes difficult to specify, and therefore performance
degrades.</p>
<p>Simulations work at different fidelities, but as the Formula 1
example shows you must be very careful about mixing fidelities within
the same simulation. The appropriate fidelity of a simulation is
strongly dependent on the question being asked of it. On the context.
For example, in Formula 1 races you can also simulate the performance of
the car in the wind tunnel and using computational fluid dynamics
representations of the Navier-Stokes equations. That level of fidelity
<em>is</em> appropriate when designing the aerodynamic components of the
car, but inappropriate when building a strategy simulation.</p>
<h1 id="epidemiology">Epidemiology</h1>
<p>The same concept of modelling at a particular fidelity comes up in
epidemiology. Disease is transmitted by direct person to person
interactions between individuals and objects. But in theoretical
epidemiology, this is approximated by differential equations. The
resulting models look very similar to reaction rate models used in
Chemistry for well mixed beakers. Let’s have a look at a simple example
used for modelling the policy of ‘herd immunity’ for Covid19.</p>
<h2 id="modelling-herd-immunity">Modelling Herd Immunity</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/herd-immunity.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/herd-immunity.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>This example is taken from <a
href="https://personalpages.manchester.ac.uk/staff/thomas.house/blog/modelling-herd-immunity.html">Thomas
House’s blog post</a> on Herd Immunity. This model was shared at the
beginning of the Covid19 pandemic when the first UK lockdown hadn’t yet
occurred.</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> integrate</span></code></pre></div>
<p>The next piece of code sets up the dynamics of the compartmental
model. He doesn’t give the specific details in the blog post, but my
understanding is that the four states are as follows. <code>x[0]</code>
is the susceptible population, those that haven’t had the disease yet.
The susceptible population decreases by encounters with infections
people. In Thomas’s model, both <code>x[3]</code> and <code>x[4]</code>
are infections. So, the dynamics of the reduction of the susceptible is
given by <span class="math display">\[
\frac{\text{d}{S}}{\text{d}t} = - \beta S (I_1 + I_2).
\]</span> Here, we’ve used <span class="math inline">\(I_1\)</span> and
<span class="math inline">\(I_2\)</span> to represent what appears to be
two separate infectious compartments in Thomas’s model. We’ll speculate
about why there are two in a moment.</p>
<p>The model appears to be an SEIR model, so rather than becoming
infectious directly you next move to an ‘exposed’, where you have the
disease, but you are not yet infectious. There are again <em>two</em>
exposed states, we’ll return to that in a moment. We denote the first,
<code>x[1]</code> by <span class="math inline">\(E_1\)</span>. We have
<span class="math display">\[
\frac{\text{d}{E_1}}{\text{d}t} = \beta S (I_1 + I_2) - \sigma E_1.
\]</span> Note that the first term matches the term from the Susceptible
equation. This is because it is the incoming exposed population.</p>
<p>The exposed population move to a second compartment of exposure,
<span class="math inline">\(E_2\)</span>. I believe the reason for this
is that if you use only one exposure compartment, then the statistics of
the duration of exposure are incorrect (implicitly they are
exponentially distributed in the underlying stochastic version of the
model). By using two exposure departments, Thomas is making a slight
correction to this which would impose a first order gamma distribution
on those statistics. A similar trick is being deployed for the
‘infectious group’. So, we gain an additional equation to help with
these statistics, <span class="math display">\[
\frac{\text{d}{E_2}}{\text{d}t} = \sigma E_1 - \sigma E_2.
\]</span> giving us the exposed group as the sum of the two compartments
<span class="math inline">\(E_1\)</span> and <span
class="math inline">\(E_2\)</span>. The exposed group from the second
compartment then become ‘infected’, which we represent with <span
class="math inline">\(I_1\)</span>, in the code this is
<code>x[3]</code>, <span class="math display">\[
\frac{\text{d}{I_1}}{\text{d}t} = \sigma E_2 - \gamma I_1,
\]</span> and similarly, Thomas is using a two-compartment infectious
group to fix up the duration model. So we have, <span
class="math display">\[
\frac{\text{d}{I_2}}{\text{d}t} = \gamma I_1 - \gamma I_2.
\]</span> And finally, we have those that have recovered emerging from
the second infections compartment. In this model there is no separate
model for ‘deaths’, so the recovered compartment, <span
class="math inline">\(R\)</span>, would also include those that die,
<span class="math display">\[
\frac{\text{d}R}{\text{d}t} = \gamma I_2.
\]</span> All these equations are then represented in code as
follows.</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> odefun(t,x,beta0,betat,t0,t1,sigma,gamma):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    dx <span class="op">=</span> np.zeros(<span class="dv">6</span>)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ((t<span class="op">&gt;=</span>t0) <span class="kw">and</span> (t<span class="op">&lt;=</span>t1)):</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        beta <span class="op">=</span> betat</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        beta <span class="op">=</span> beta0</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    dx[<span class="dv">0</span>] <span class="op">=</span> <span class="op">-</span>beta<span class="op">*</span>x[<span class="dv">0</span>]<span class="op">*</span>(x[<span class="dv">3</span>] <span class="op">+</span> x[<span class="dv">4</span>])</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    dx[<span class="dv">1</span>] <span class="op">=</span> beta<span class="op">*</span>x[<span class="dv">0</span>]<span class="op">*</span>(x[<span class="dv">3</span>] <span class="op">+</span> x[<span class="dv">4</span>]) <span class="op">-</span> sigma<span class="op">*</span>x[<span class="dv">1</span>]</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    dx[<span class="dv">2</span>] <span class="op">=</span> sigma<span class="op">*</span>x[<span class="dv">1</span>] <span class="op">-</span> sigma<span class="op">*</span>x[<span class="dv">2</span>]</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    dx[<span class="dv">3</span>] <span class="op">=</span> sigma<span class="op">*</span>x[<span class="dv">2</span>] <span class="op">-</span> gamma<span class="op">*</span>x[<span class="dv">3</span>]</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    dx[<span class="dv">4</span>] <span class="op">=</span> gamma<span class="op">*</span>x[<span class="dv">3</span>] <span class="op">-</span> gamma<span class="op">*</span>x[<span class="dv">4</span>]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    dx[<span class="dv">5</span>] <span class="op">=</span> gamma<span class="op">*</span>x[<span class="dv">4</span>]</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> dx</span></code></pre></div>
<p>Where the code takes in the states of the compartments (the values of
<code>x</code>) and returns the gradients of those states for the
provided parameters (<code>sigma</code>, <code>gamma</code> and
<code>beta</code>). Those parameters are set according to the known
characteristics of the disease.</p>
<p>The next block of code sets up the parameters of the SEIR model. A
particularly important parameter is the reproduction number (<span
class="math inline">\(R_0\)</span>), here Thomas has assumed a
reproduction number of 2.5, implying that each infected member of the
population transmits the infection up to 2.5 other people. The effective
<span class="math inline">\(R\)</span> decreases over time though,
because some of those people they meet will no longer be in the
susceptible group.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters of the model</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>N <span class="op">=</span> <span class="fl">6.7e7</span> <span class="co"># Total population</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>i0 <span class="op">=</span> <span class="fl">1e-4</span> <span class="co"># 0.5*Proportion of the population infected on day 0</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>tlast <span class="op">=</span> <span class="fl">365.0</span> <span class="co"># Consider a year</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>latent_period <span class="op">=</span> <span class="fl">5.0</span> <span class="co"># Days between being infected and becoming infectious</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>infectious_period <span class="op">=</span> <span class="fl">7.0</span> <span class="co"># Days infectious</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>R0 <span class="op">=</span> <span class="fl">2.5</span> <span class="co"># Basic reproduction number in the absence of interventions</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>Rt <span class="op">=</span> <span class="fl">0.75</span> <span class="co"># Reproduction number in the presence of interventions</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>tend <span class="op">=</span> <span class="fl">21.0</span> <span class="co"># Number of days of interventions</span></span></code></pre></div>
<p>The parameters are correct for the ‘discrete system’, where the
infectious period is a discrete time, and the numbers are discrete
values. To translate into our continuous differential equation system’s
parameters, we need to do a couple of manipulations. Note the factor of
2 associated with <code>gamma</code> and <code>sigma</code>. This is a
doubling of the rate to account for the fact that there are two
compartments for each of these states (to fix-up the statistics of the
duration models).</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>beta0 <span class="op">=</span> R0 <span class="op">/</span> infectious_period</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>betat <span class="op">=</span> Rt <span class="op">/</span> infectious_period</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>sigma <span class="op">=</span> <span class="fl">2.0</span> <span class="op">/</span> latent_period</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>gamma <span class="op">=</span> <span class="fl">2.0</span> <span class="op">/</span> infectious_period</span></code></pre></div>
<p>Next, we solve the system using <code>scipy</code>’s initial value
problem solver. The solution method is Runge-Kutta-Fehlberg method, as
indicated by the <code>'RK45'</code> solver. This is a numerical method
for solving differential equations. The 45 is the order of the method
and the error estimator.</p>
<p>We can view the solver itself as somehow a piece of simulation code,
but here it’s being called as sub routine in the system. It returns a
solution for each time step, stored in a list <code>sol</code>.</p>
<p>This is typical of this type of non-linear differential equation
problem. Whether it’s partial differential equations, ordinary
differential equations, there’s a step where a numerical solver needs to
be called. These are often expensive to run. For climate and weather
models, this would be where we solved the Navier-Stokes equations. For
this simple model, the solution is relatively quick.</p>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>t0ran <span class="op">=</span> np.array([<span class="op">-</span><span class="dv">100</span>, <span class="dv">40</span>, <span class="fl">52.5</span>, <span class="dv">65</span>])</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>sol<span class="op">=</span>[]</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tt <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="bu">len</span>(t0ran)):</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    sol.append(integrate.solve_ivp(<span class="kw">lambda</span> t,x: odefun(t,x,beta0,betat,t0ran[tt],t0ran[tt]<span class="op">+</span>tend,sigma,gamma),</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>                              (<span class="fl">0.0</span>,tlast),</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>                              np.array([<span class="fl">1.0</span><span class="op">-</span><span class="fl">2.0</span><span class="op">*</span>i0, <span class="fl">0.0</span>, <span class="fl">0.0</span>, i0, i0, <span class="fl">0.0</span>]),</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>                              <span class="st">&#39;RK45&#39;</span>,</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>                              atol<span class="op">=</span><span class="fl">1e-8</span>,</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>                              rtol<span class="op">=</span><span class="fl">1e-9</span>))</span></code></pre></div>
<div class="figure">
<div id="house-model-zoom-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/house-model-zoom.svg" width="80%" style=" ">
</object>
</div>
<div id="house-model-zoom-magnify" class="magnify"
onclick="magnifyFigure(&#39;house-model-zoom&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="house-model-zoom-caption" class="caption-frame">
<p>Figure: A zoomed in version of Thomas House’s variation on the SEIR
model for evaluating the effect of early interventions.</p>
</div>
</div>
<div class="figure">
<div id="house-model-full-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/house-model-full.svg" width="80%" style=" ">
</object>
</div>
<div id="house-model-full-magnify" class="magnify"
onclick="magnifyFigure(&#39;house-model-full&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="house-model-full-caption" class="caption-frame">
<p>Figure: The full progress of the disease in Thomas House’s variation
on the SEIR model for evaluating the effect of early interventions.</p>
</div>
</div>
<p>In practice, immunity for Covid19 may only last around 6 months. As
an exercise, try to extend Thomas’s model for the case where immunity is
temporary. You’ll need to account for deaths as well in your new
model.</p>
<p>Thinking about our Formula 1 example, and the differing levels of
fidelity that might be included in a model, you can now imagine the
challenges of doing large scale theoretical epidemiology. The
compartment model is operating at a particular level of fidelity.
Imagine trying to modify this model for a specific circumstance, like
the way that the University of Cambridge chooses to do lectures. It’s
not appropriate for this level of fidelity. You need to use different
types of models for that decision making. <a
href="https://mlatcl.github.io/mlphysical/casestudies/tti-explorer.html">One
of our case studies</a> looks at a simulation that was used to advise
the government on the Test Trace Isolate program that took a different
approach <span class="citation" data-cites="Delve-tti20">(The DELVE
Initiative, 2020a)</span>.</p>
<h1 id="strategies-for-simulation">Strategies for Simulation</h1>
<p>Within any simulation, we can roughly split the variables of interest
into the state variables and the parameters. In the Herd immunity
example, the state variables were the different susceptible, exposed,
infectious and recovered groups. The parameters were the reproduction
number and the expected lengths of infection and the timing of lockdown.
Often parameters are viewed as the inputs to the simulation, the things
we can control. We might want to know how to time lock down to minimize
the number of deaths. This behavior of the simulator is what we may want
to emulate with our Gaussian process model.</p>
<p>So far, we’ve introduced simulation motivated by the physical laws of
the universe. Those laws are sometimes encoded in differential
equations, in which case we can try to solve those systems (like with
Herd Immunity or Navier Stokes). An alternative approach is taken in the
Game of Life. There a turn-based simulation is used, at each turn, we
iterate through the simulation updating the state of the simulation.
This is known as a <em>discrete event simulation</em>. In race
simulation for Formula 1 a discrete event simulation is also used. There
is another form of discrete event simulation, often used in chemical
models, where the events don’t take place at regular intervals. Instead,
the timing to the next event is computed, and the simulator advances
that amount of time. For an example of this see <a
href="https://en.wikipedia.org/wiki/Gillespie_algorithm">the Gillespie
algorithm</a>.</p>
<p>There is a third type of simulation that we’d also like to introduce.
That is simulation within computer software. In particular, the need to
backtest software with ‘what if’ ideas – known as counter factual
simulation – or to trace errors that may have occurred in production.
This can involve loading up entire code bases and rerunning them with
simulated inputs. This is a third form of simulation where emulation can
also come in useful.</p>
<h2 id="backtesting-production-code">Backtesting Production Code</h2>
<p>In Amazon the team I led looked at examples of simulations and
emulation as varied as Prime Air drones across to the Amazon Supply
Chain. In a purchasing system, the idea is to store stock to balance
supply and demand. The aim is to keep product in stock for quick
dispatch while keeping prices (and therefore costs) low. This idea is at
the heart of Amazon’s focus on customer experience.</p>
<h2 id="alexa">Alexa</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/alexa-system.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/alexa-system.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip0">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Tom Taylor
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/tom-taylor.png" clip-path="url(#clip0)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip1">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Joe Walowski
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/joe-walowski.png" clip-path="url(#clip1)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip2">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Rohit Prasad
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/rohit-prasad.png" clip-path="url(#clip2)"/>
</svg>
</div>
<div class="figure">
<div id="alexa-architecture-overview-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/VQVZ2hvNVfo?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="alexa-architecture-overview-magnify" class="magnify"
onclick="magnifyFigure(&#39;alexa-architecture-overview&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="alexa-architecture-overview-caption" class="caption-frame">
<p>Figure: Alexa Architecture overview taken from the Alexa Skills
programme.</p>
</div>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip3">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Rohit Prasad
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/rohit-prasad.png" clip-path="url(#clip3)"/>
</svg>
</div>
<div class="figure">
<div id="rohit-prasad-alexa-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/wa8DU-Sui8Q?start=2520" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="rohit-prasad-alexa-magnify" class="magnify"
onclick="magnifyFigure(&#39;rohit-prasad-alexa&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="rohit-prasad-alexa-caption" class="caption-frame">
<p>Figure: Rohit Prasad talking about Alexa at the Amazon 2019 re:MARS
event.</p>
</div>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip4">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Tom Taylor
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/tom-taylor.png" clip-path="url(#clip4)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip5">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Joe Walowski
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/joe-walowski.png" clip-path="url(#clip5)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip6">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Rohit Prasad
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/rohit-prasad.png" clip-path="url(#clip6)"/>
</svg>
</div>
<div class="figure">
<div id="alexa-schematic-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//software/alexa-schematic.svg" width="40%" style=" ">
</object>
</div>
<div id="alexa-schematic-magnify" class="magnify"
onclick="magnifyFigure(&#39;alexa-schematic&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="alexa-schematic-caption" class="caption-frame">
<p>Figure: Simple schmeatic of an intelligent agent’s components.</p>
</div>
</div>
<h2 id="speech-to-text">Speech to Text</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip7">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Catherine Breslin
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/catherine-breslin.png" clip-path="url(#clip7)"/>
</svg>
</div>
<h2 id="cloud-service-knowledge-base">Cloud Service: Knowledge Base</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip8">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
David Hardcastle
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/david-hardcastle.png" clip-path="url(#clip8)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip9">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Arpit Mittal
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/arpit-mittal.png" clip-path="url(#clip9)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip10">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Christos Christodoulopoulos
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/christos-christodoulopoulos.png" clip-path="url(#clip10)"/>
</svg>
</div>
<h2 id="text-to-speech">Text to Speech</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip11">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Andrew Breen
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/andrew-breen.png" clip-path="url(#clip11)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip12">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Roberto Barra Chicote
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/roberto-barra-chicote.png" clip-path="url(#clip12)"/>
</svg>
</div>
<h2 id="prime-air">Prime Air</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/prime-air-system.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/prime-air-system.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>One project where the components of machine learning and the physical
world come together is Amazon’s Prime Air drone delivery system.</p>
<p>Automating the process of moving physical goods through autonomous
vehicles completes the loop between the ‘bits’ and the ‘atoms’. In other
words, the information and the ‘stuff’. The idea of the drone is to
complete a component of package delivery, the notion of last mile
movement of goods, but in a fully autonomous way.</p>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip13">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Gur Kimchi
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/gur-kimchi.png" clip-path="url(#clip13)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip14">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Paul Viola
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/paul-viola.png" clip-path="url(#clip14)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip15">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
David Moro
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/david-moro.png" clip-path="url(#clip15)"/>
</svg>
</div>
<div class="figure">
<div id="amazon-drone-flight-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/3HJtmx5f1Fc?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="amazon-drone-flight-magnify" class="magnify"
onclick="magnifyFigure(&#39;amazon-drone-flight&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="amazon-drone-flight-caption" class="caption-frame">
<p>Figure: An actual ‘Santa’s sleigh’. Amazon’s prototype delivery
drone. Machine learning algorithms are used across various systems
including sensing (computer vision for detection of wires, people, dogs
etc) and piloting. The technology is necessarily a combination of old
and new ideas. The transition from vertical to horizontal flight is
vital for efficiency and uses sophisticated machine learning to
achieve.</p>
</div>
</div>
<p>As Jeff Wilke (who was CEO of Amazon Retail at the time) <a
href="https://blog.aboutamazon.com/transportation/a-drone-program-taking-flight">announced
in June 2019</a> the technology is ready, but still needs
operationalization including e.g. regulatory approval.</p>
<div class="figure">
<div id="jeff-wilke-remars-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/wa8DU-Sui8Q?start=3767" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="jeff-wilke-remars-magnify" class="magnify"
onclick="magnifyFigure(&#39;jeff-wilke-remars&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="jeff-wilke-remars-caption" class="caption-frame">
<p>Figure: Jeff Wilke (CEO Amazon Consumer) announcing the new drone at
the Amazon 2019 re:MARS event alongside the scale of the Amazon supply
chain.</p>
</div>
</div>
<blockquote>
<p>When we announced earlier this year that we were evolving our Prime
two-day shipping offer in the U.S. to a one-day program, the response
was terrific. But we know customers are always looking for something
better, more convenient, and there may be times when one-day delivery
may not be the right choice. Can we deliver packages to customers even
faster? We think the answer is yes, and one way we’re pursuing that goal
is by pioneering autonomous drone technology.</p>
</blockquote>
<blockquote>
<p>Today at Amazon’s re:MARS Conference (Machine Learning, Automation,
Robotics and Space) in Las Vegas, we unveiled our latest Prime Air drone
design. We’ve been hard at work building fully electric drones that can
fly up to 15 miles and deliver packages under five pounds to customers
in less than 30 minutes. And, with the help of our world-class
fulfillment and delivery network, we expect to scale Prime Air both
quickly and efficiently, delivering packages via drone to customers
within months.</p>
</blockquote>
<p>The 15 miles in less than 30 minutes implies air speed velocities of
around 50 kilometers per hour.</p>
<blockquote>
<p>Our newest drone design includes advances in efficiency, stability
and, most importantly, in safety. It is also unique, and it advances the
state of the art. How so? First, it’s a hybrid design. It can do
vertical takeoffs and landings – like a helicopter. And it’s efficient
and aerodynamic—like an airplane. It also easily transitions between
these two modes—from vertical-mode to airplane mode, and back to
vertical mode.</p>
</blockquote>
<blockquote>
<p>It’s fully shrouded for safety. The shrouds are also the wings, which
makes it efficient in flight.</p>
</blockquote>
<div class="figure">
<div id="amazon-prime-air-remars-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//ai/amazon-prime-air-remars-june-2019.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="amazon-prime-air-remars-magnify" class="magnify"
onclick="magnifyFigure(&#39;amazon-prime-air-remars&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="amazon-prime-air-remars-caption" class="caption-frame">
<p>Figure: Picture of the drone from Amazon Re-MARS event in 2019.</p>
</div>
</div>
<blockquote>
<p>Our drones need to be able to identify static and moving objects
coming from any direction. We employ diverse sensors and advanced
algorithms, such as multi-view stereo vision, to detect static objects
like a chimney. To detect moving objects, like a paraglider or
helicopter, we use proprietary computer-vision and machine learning
algorithms.</p>
</blockquote>
<blockquote>
<p>A customer’s yard may have clotheslines, telephone wires, or
electrical wires. Wire detection is one of the hardest challenges for
low-altitude flights. Through the use of computer-vision techniques
we’ve invented, our drones can recognize and avoid wires as they descend
into, and ascend out of, a customer’s yard.</p>
</blockquote>
<h2 id="supply-chain-optimization">Supply Chain Optimization</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/supply-chain-system.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/supply-chain-system.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip16">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Llew Mason
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/llew-mason.png" clip-path="url(#clip16)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip17">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Devesh Mishra
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/devesh-mishra.png" clip-path="url(#clip17)"/>
</svg>
</div>
<p>Supply chain is the process of matching between the supply of the
product and demand for the product. This matching process is done
through the deployment of resources: places to store the products, ways
and means of transporting the product and even the ability to transform
products from one form to another (e.g. transforming paper into books
through printing).</p>
<div class="figure">
<div id="scot-promo-video-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/ncwsr1Of6Cw?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="scot-promo-video-magnify" class="magnify"
onclick="magnifyFigure(&#39;scot-promo-video&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="scot-promo-video-caption" class="caption-frame">
<p>Figure: Promotional video for the Amazon supply chain optimization
team.</p>
</div>
</div>
<p>Arugably the Amazon supply chain is (or was) the largest automated
decision-making system in the world in terms of the amount of money
spent and the quantity of product moved through automated decision
making.</p>
<h2 id="supply-chain-optimization-1">Supply Chain Optimization</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip18">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Llew Mason
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/llew-mason.png" clip-path="url(#clip18)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip19">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Devesh Mishra
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/devesh-mishra.png" clip-path="url(#clip19)"/>
</svg>
</div>
<p>At the heart of an automated supply chain is the buying system, which
determines the optimal stock level for products and makes purchases
based on the difference between that stock level and the current stock
level.</p>
<div class="figure">
<div id="buying-schematic-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//software/buying-schematic.svg" width="40%" style=" ">
</object>
</div>
<div id="buying-schematic-magnify" class="magnify"
onclick="magnifyFigure(&#39;buying-schematic&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="buying-schematic-caption" class="caption-frame">
<p>Figure: A schematic of a typical buying system for supply chain.</p>
</div>
</div>
<p>To make these decisions predictive models (often machine learning or
statistical models) have to be moved. For example, the demand for a
particular product needs to be forecast.</p>
<h2 id="forecasting">Forecasting</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip20">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Jenny Freshwater
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/jenny-freshwater.png" clip-path="url(#clip20)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip21">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Ping Xu
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/ping-xu.png" clip-path="url(#clip21)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip22">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Dean Foster
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/dean-foster.png" clip-path="url(#clip22)"/>
</svg>
</div>
<div class="figure">
<div id="jenny-freshwater-remars-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/wa8DU-Sui8Q?start=1358" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="jenny-freshwater-remars-magnify" class="magnify"
onclick="magnifyFigure(&#39;jenny-freshwater-remars&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="jenny-freshwater-remars-caption" class="caption-frame">
<p>Figure: Jenny Freshwater speaking at the Amazon re:MARS event in June
2019.</p>
</div>
</div>
<p>The process of forecasting is described by Jenny Freshwater (at the
time Director for Forecasting within Amazon’s Supply Chain Optimization
team in the video in Figure <span
class="math inline">\(\ref{jenny-freshwater-remars}\)</span>.</p>
<p>For each product in the Amazon catalogue, the demand is forecast
across the a given future period.</p>
<h2 id="inventory-and-buying">Inventory and Buying</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip23">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Deepak Bhatia
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/deepak-bhatia.png" clip-path="url(#clip23)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip24">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Piyush Saraogi
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/piyush-saraogi.png" clip-path="url(#clip24)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip25">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Raman Iyer
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/raman-iyer.jpg" clip-path="url(#clip25)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip26">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Salal Humair
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/salal-humair.png" clip-path="url(#clip26)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip27">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Narayan Venkatasubramanyan
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/narayan-venkatasubramanyan.png" clip-path="url(#clip27)"/>
</svg>
</div>
<p>Forecast information is combined with predictions around lead times
from suppliers, understanding of the network’s capacity (in terms of how
much space is available in which fulfillment centers), the cost of
storing and transporting products and the “value” for the consumer in
finding the product is in stock. These models are typically operational
research models (such as the “newsvendor problem” combined with machine
learning and/or statistical forecasts.</p>
<h2 id="buying-system">Buying System</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/buying-system.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/buying-system.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>An example of a complex decision-making system might be an automated
buying system. In such a system, the idea is to match demand for
products to supply of products.</p>
<p>The matching of demand and supply is a repetitive theme for decision
making systems. Not only does it occur in automated buying, but also in
the allocation of drivers to riders in a ride sharing system. Or in the
allocation of compute resource to users in a cloud system.</p>
<p>The components of any of these systems include predictions of the
demand for the product, the drivers, or the compute. Predictions of the
supply. Decisions are then made for how much material to keep in stock,
or how many drivers to have on the road, or how much computer capacity
to have in your data centers. These decisions have cost implications.
The optimal amount of product will depend on the cost of making it
available. For a buying system this is the storage costs.</p>
<p>Decisions are made based on the supply and demand to make new orders,
to encourage more drivers to come into the system or to build new data
centers or rent more computational power.</p>
<div class="figure">
<div id="buying-system-components-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//software/buying-schematic.svg" width="40%" style=" ">
</object>
</div>
<div id="buying-system-components-magnify" class="magnify"
onclick="magnifyFigure(&#39;buying-system-components&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="buying-system-components-caption" class="caption-frame">
<p>Figure: The components of a putative automated buying system</p>
</div>
</div>
<h2 id="monolithic-system">Monolithic System</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/aws-soa.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_ai/includes/aws-soa.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The classical approach to building these systems was a ‘monolithic
system’. Built in a similar way to the successful applications software
such as Excel or Word, or large operating systems, a single code base
was constructed. The complexity of such code bases run to many
lines.</p>
<p>In practice, shared dynamically linked libraries may be used for
aspects such as user interface, or networking, but the software often
has many millions of lines of code. For example, the Microsoft Office
suite is said to contain over 30 million lines of code.</p>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip28">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Charlie Bell
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/charlie-bell.png" clip-path="url(#clip28)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip29">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Peter Vosshall
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/peter-vosshall.png" clip-path="url(#clip29)"/>
</svg>
</div>
<div class="figure">
<div id="ml-system-monolith-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//ai/ml-system-monolith-purchasing.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-monolith-magnify" class="magnify"
onclick="magnifyFigure(&#39;ml-system-monolith&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ml-system-monolith-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<p>Such software is not only difficult to develop, but also to scale
when computation demands increase. Amazon’s original website software
(called Obidos) was a <a
href="https://en.wikipedia.org/wiki/Obidos_(software)">monolithic
design</a> but by the early noughties it was becoming difficult to
sustain and maintain. The software was phased out in 2006 to be replaced
by a modularized software known as a ‘service-oriented
architecture’.</p>
<h2 id="service-oriented-architecture">Service Oriented
Architecture</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip30">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Charlie Bell
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/charlie-bell.png" clip-path="url(#clip30)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip31">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Peter Vosshall
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/peter-vosshall.png" clip-path="url(#clip31)"/>
</svg>
</div>
<p>In Service Oriented Architecture, or “Software as a Service” the idea
is that code bases are modularized and communicate with one another
using network requests. A standard approach is to use a <a
href="https://en.wikipedia.org/wiki/Representational_state_transfer">REST
API</a>. So, rather than a single monolithic code base, the code is
developed with individual services that handle the different
requests.</p>
<div class="figure">
<div id="ml-system-downstream-purchasing-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//ai/ml-system-downstream-purchasing000.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-downstream-purchasing-magnify" class="magnify"
onclick="magnifyFigure(&#39;ml-system-downstream-purchasing&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ml-system-downstream-purchasing-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<p>Modern software development uses an approach known as
<em>service-oriented architecture</em> to build highly complex systems.
Such systems have similar emergent properties to Conway’s “Game of
Life”. Understanding these emergent properties is vitally important when
diagnosing problems in the system.</p>
<p>In the context of machine learning and complex systems, Jonathan
Zittrain has coined the term <a
href="https://medium.com/berkman-klein-center/from-technical-debt-to-intellectual-debt-in-ai-e05ac56a502c">“Intellectual
Debt”</a> to describe the challenge of understanding what you’ve
created. In <a
href="https://mlatcl.github.io/projects/data-oriented-architectures-for-ai-based-systems.html">the
ML@CL group we’ve been foucssing on developing the notion of a
<em>data-oriented architecture</em></a> to deal with intellectual debt
<span class="citation" data-cites="Cabrera-realworld23">(Cabrera et al.,
2023)</span>.</p>
<p>This is the landscape we now find ourselves in with regard to
software development. In practice, each of these services is often
‘owned’ and maintained by an individual team. The team is judged by the
quality of their service provision. They work to detailed specifications
on what their service should output, what its availability should be and
other objectives like speed of response. This allows for conditional
independence between teams and for faster development.</p>
<p>Clearly Conway’s Game of Life exhibits an enormous amount of
intellectual debt, indeed that was the idea. Build something simple that
exhibits great complexity. That’s what makes it so popular. But in
deployed system software, intellectual debt is a major headache and
emulation presents one way of dealing with it.</p>
<p>Unfortunately, it also makes sophisticated software systems a
breeding ground for intellectual debt. Particularly when they contain
components which are themselves ML components. Dealing with this
challenge is a major objective of my Senior AI Fellowship at the Alan
Turing Institute. You can see me talking about the problems <a
href="http://inverseprobability.com/talks/notes/deploying-machine-learning-systems-intellectual-debt-and-auto-ai.html">at
this recent seminar given virtually in Manchester</a>.</p>
<h2 id="examples-in-python">Examples in Python</h2>
<p>There are a number of different simulations available in python, and
tools specifically design for simulation. For example <code>simpy</code>
has a <a href="https://simpy.readthedocs.io/en/latest/examples/">list of
example simulations</a> around machine shops, gas stations, car
washes.</p>
<p>Operations research ideas like the newsvendor problem, can also be
solved, Andrea Fabry provides an example of the newsvendor problem in
python for order of <a
href="https://github.com/fabryandrea/newsvendor">NFL replica jerseys
here</a>.</p>
<p>The news vendor problem is also a component in the Amazon supply
chain. The Amazon supply chain makes predictions about supply and
demand, combines them with a cost basis and computes optimal stock.
Inventory orders are based on the difference between this optimal stock
and current stock. The <a
href="https://github.com/amzn/supply-chain-simulation-environment">MiniSCOT
simulation</a> provides code that illustrates this.</p>
<p>Control problems are also systems that aim to achieve objectives
given a set of parameters. A classic control problem is the inverted
pendulum. This <a
href="https://www.moorepants.info/blog/npendulum.html">python code</a>
generalises the standard inverted pendulum using one with <span
class="math inline">\(n\)</span>-links using symbolic python code.</p>
<p>In reinforcement learning similar control problems are studied, a
classic reinforcement learning problem is known as the <a
href="https://github.com/openai/gym/blob/master/gym/envs/classic_control/mountain_car.py">Mountain
Car</a>. You can work with this problem using an environment known as <a
href="https://github.com/openai/gym">OpenAI gym</a> that includes many
different reinforcement learning scenarios.</p>
<p>In neuroscience Hodgkin and Huxley studied the giant axon in squid to
work out a set of differential equations that are still used today to
model spiking neurons. Mark Kramer explains how to <a
href="https://mark-kramer.github.io/Case-Studies-Python/HH.html">simulate
them in python here</a>.</p>
<p>All Formula One race teams simulate the race to determine their
strategy (tyres, pit stops etc). While those simulations are
proprietary, there is sufficient interest in the wider community that
race simulations have been developed in python. Here is <a
href="https://github.com/rothnic/formulapy">one that Nick Roth has made
available</a>.</p>
<p>Formula one teams also make use of simulation to design car parts.
There are at least two components to this, simulations that allow the
modelling of fluid flow across the car, and simulations that analyze the
capabilities of materials under stress. You can find computational <a
href="https://github.com/barbagroup/CFDPython">fluild dynamics
simulations in python here</a> and <a
href="https://solidspy.readthedocs.io/en/latest/readme.html">finite
element analysis methods for computing stress in materials here</a>.</p>
<p>Alongside continuous system simulation through partial differential
equations, another form of simulation that arises is known as
<em>discrete event simulation</em>. This comes up in c<a
href="https://github.com/mkalewski/sim2net">omputer networks</a> and
also in chemical systems where the approach to simulating is kown as the
<a
href="https://github.com/karinsasaki/gillespie-algorithm-python/">Gillespie
algorithm</a>.</p>
<h2 id="simulation-system">Simulation System</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/simulation-system.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/simulation-system.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>An example of a complex decision-making system might be a climate
model, in such a system there are separate models for the atmosphere,
the ocean and the land.</p>
<p>The components of these systems include flowing of currents, chemical
interactions in the upper atmosphere, evaporation of water etc..</p>
<div class="figure">
<div id="carbon-cycle-noaa-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/carbon_cycle.jpg" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="carbon-cycle-noaa-magnify" class="magnify"
onclick="magnifyFigure(&#39;carbon-cycle-noaa&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="carbon-cycle-noaa-caption" class="caption-frame">
<p>Figure: Representation of the Carbon Cycle from the US National
Oceanic and Atmospheric Administration. While everything is
interconnected in the system, we can decompose into separate models for
atmosphere, ocean, land.</p>
</div>
</div>
<p>The influence of human activity also needs to be incorporated and
modelled so we can make judgments about how to mitigate the effects of
global warming.</p>
<div class="figure">
<div id="simulation-system-components-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/simulation-schematic.svg" width="40%" style=" ">
</object>
</div>
<div id="simulation-system-components-magnify" class="magnify"
onclick="magnifyFigure(&#39;simulation-system-components&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="simulation-system-components-caption" class="caption-frame">
<p>Figure: The components of a simulation system for climate
modelling.</p>
</div>
</div>
<h2 id="monolithic-system-1">Monolithic System</h2>
<p>The classical approach to building these systems was a ‘monolithic
system’. Built in a similar way to the successful applications software
such as Excel or Word, or large operating systems, a single code base
was constructed. The complexity of such code bases run to many
lines.</p>
<p>In practice, shared dynamically linked libraries may be used for
aspects such as user interface, or networking, but the software often
has many millions of lines of code. For example, the Microsoft Office
suite is said to contain over 30 million lines of code.</p>
<div class="figure">
<div id="ml-system-monolith-simulation-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/ml-system-monolith-simulation.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-monolith-simulation-magnify" class="magnify"
onclick="magnifyFigure(&#39;ml-system-monolith-simulation&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ml-system-monolith-simulation-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<h2 id="service-oriented-architecture-1">Service Oriented
Architecture</h2>
<p>Such software is not only difficult to develop, but also to scale
when computation demands increase. For example, Amazon’s original
website software (called Obidos) was a <a
href="https://en.wikipedia.org/wiki/Obidos_(software)">monolithic
design</a> but by the early noughties it was becoming difficult to
sustain and maintain. The software was phased out in 2006 to be replaced
by a modularized software known as a ‘service-oriented
architecture’.</p>
<p>In Service Oriented Architecture, or “Software as a Service” the idea
is that code bases are modularized and communicate with one another
using network requests. A standard approach is to use a <a
href="https://en.wikipedia.org/wiki/Representational_state_transfer">REST
API</a>. So, rather than a single monolithic code base, the code is
developed with individual services that handle the different
requests.</p>
<p>The simulation software is turned inside out to expose the individual
components to the operator.</p>
<div class="figure">
<div id="ml-system-downstream-simulation-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/ml-system-downstream-simulation000.svg" width="60%" style=" ">
</object>
</div>
<div id="ml-system-downstream-simulation-magnify" class="magnify"
onclick="magnifyFigure(&#39;ml-system-downstream-simulation&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ml-system-downstream-simulation-caption" class="caption-frame">
<p>Figure: A potential path of models in a machine learning system.</p>
</div>
</div>
<p>This is the landscape we now find ourselves in for software
development. In practice, each of these services is often ‘owned’ and
maintained by an individual team. The team is judged by the quality of
their service provision. They work to detailed specifications on what
their service should output, what its availability should be and other
objectives like speed of response. This allows for conditional
independence between teams and for faster development.</p>
<p>One question is to what extent is the same approach
possible/desirable for scientific models? The components we listed above
are already separated and often run independently. But those components
themselves are made up of other sub-components that could also be
exposed in a similar manner to software-as-a-service, giving us the
notion of “simulation as a service”.</p>
<p>One thing about working in an industrial environment, is the way that
short-term thinking actions become important. For example, in Formula
One, the teams are working on a two-week cycle to digest information
from the previous week’s race and incorporate updates to the car or
their strategy.</p>
<p>However, businesses must also think about more medium-term horizons.
For example, in Formula 1 you need to worry about next year’s car. So,
while you’re working on updating this year’s car, you also need to think
about what will happen for next year and prioritize these conflicting
needs appropriately.</p>
<p>In the Amazon supply chain, there are equivalent demands. If we
accept that an artificial intelligence is just an automated
decision-making system. And if we measure in terms of money
automatically spent, or goods automatically moved, then Amazon’s buying
system is perhaps the world’s largest AI.</p>
<p>Those decisions are being made on short time schedules; purchases are
made by the system on weekly cycles. But just as in Formula 1, there is
also a need to think about what needs to be done next month, next
quarter and next year. Planning meetings are held not only on a weekly
basis (known as weekly business reviews), but monthly, quarterly, and
then yearly meetings for planning spends and investments.</p>
<p>Amazon is known for being longer term thinking than many companies,
and a lot of this is coming from the CEO. One quote from Jeff Bezos that
stuck with me was the following.</p>
<blockquote>
<p>“I very frequently get the question: ‘What’s going to change in the
next 10 years?’ And that is a very interesting question; it’s a very
common one. I almost never get the question: ‘What’s not going to change
in the next 10 years?’ And I submit to you that that second question is
actually the more important of the two – because you can build a
business strategy around the things that are stable in time. … [I]n our
retail business, we know that customers want low prices, and I know
that’s going to be true 10 years from now. They want fast delivery; they
want vast selection. It’s impossible to imagine a future 10 years from
now where a customer comes up and says, ‘Jeff I love Amazon; I just wish
the prices were a little higher,’ [or] ‘I love Amazon; I just wish you’d
deliver a little more slowly.’ Impossible. And so the effort we put into
those things, spinning those things up, we know the energy we put into
it today will still be paying off dividends for our customers 10 years
from now. When you have something that you know is true, even over the
long term, you can afford to put a lot of energy into it.”</p>
</blockquote>
<p>This quote is incredibly important for long term thinking. Indeed,
it’s a failure of many of our simulations that they focus on what is
going to happen, not what will not happen. In Amazon, this meant that
there was constant focus on these three areas, keeping costs low, making
delivery fast and improving selection. For example, shortly before I
left Amazon moved its entire US network from two-day delivery to one-day
delivery. This involves changing the way the entire buying system
operates. Or, more recently, the company has had to radically change the
portfolio of products it buys in the face of Covid19.</p>
<!--These challenges are not just there for Amazon and Formula 1. In Sheffield, we worked closely with a Chesterfield based company called Fusion Group. They make joints that fuse PTFE pipes together. These pipes are used for transporting both water and gas. Their founder, Eric Bridgstock, was an engineer who introduced PTFE piping to the UK when working for DuPont. Eric set up Fusion group to manufacture the fusion fittings. Because PTFE pipes carry water or gas at high pressure, when these fittings fail significant damage can occur. When these fittings were originally installed in the early 1980s, the job was done by a specialist, but nowadays the pipe weld is compelted by the same team that digs the hole. While costs have come down, the number of PTFE weld failures went up. Eric's company focussed on new systems for auto-->
<div class="figure">
<div id="experiment-analyze-design-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//ml/experiment-analyze-design.svg" width="50%" style=" ">
</object>
</div>
<div id="experiment-analyze-design-magnify" class="magnify"
onclick="magnifyFigure(&#39;experiment-analyze-design&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="experiment-analyze-design-caption" class="caption-frame">
<p>Figure: Experiment, analyze and design is a flywheel of knowledge
that is the dual of the model, data and compute. By running through this
spiral, we refine our hypothesis/model and develop new experiments which
can be analyzed to further refine our hypothesis.</p>
</div>
</div>
<p>From the perspective of the team that we had in the supply chain, we
looked at what we most needed to focus on. Amazon moves very quickly,
but we could also take a leaf out of Jeff’s book, and instead of
worrying about what was going to change, remember what wasn’t going to
change.</p>
<blockquote>
<p>We don’t know what science we’ll want to do in five years’ time, but
we won’t want slower experiments, we won’t want more expensive
experiments and we won’t want a narrower selection of experiments.</p>
</blockquote>
<p>As a result, our focus was on how to speed up the process of
experiments, increase the diversity of experiments that we can do, and
keep the experiments price as low as possible.</p>
<p>The faster the innovation flywheel can be iterated, then the quicker
we can ask about different parts of the supply chain, and the better we
can tailor systems to answering those questions.</p>
<p>We need faster, cheaper and more diverse experiments which implies we
need better ecosystems for experimentation. This has led us to focus on
the software frameworks we’re using to develop machine learning systems
including data oriented architectures (<span class="citation"
data-cites="Borchert-dataoriented20">Borchert (2020)</span>;<span
class="citation" data-cites="Lawrence-dop19">Lawrence
(2019)</span>;<span class="citation"
data-cites="Vorhemus-doa17">Vorhemus and Schikuta (2017)</span>;<span
class="citation" data-cites="Joshi-doa07">Joshi (2007)</span>), data
maturity assessments (<span class="citation"
data-cites="Lawrence-maturity20">Lawrence et al. (2020)</span>) and data
readiness levels (See this blog post on <a
href="http://inverseprobability.com/2017/01/12/data-readiness-levels">Data
Readiness Levels</a>. and <span class="citation"
data-cites="Lawrence-drl17">Lawrence (2017)</span>;<span
class="citation" data-cites="Delve-data20">The DELVE Initiative
(2020b)</span>)</p>
<h2 id="packing-problems">Packing Problems</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/packing-problems.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_simulation/includes/packing-problems.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="friedman-s9-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/friedman/s9.gif" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="friedman-s9-magnify" class="magnify"
onclick="magnifyFigure(&#39;friedman-s9&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="friedman-s9-caption" class="caption-frame">
<p>Figure: Packing 9 squares into a single square. This example is
trivially solved. Credit <a
href="https://erich-friedman.github.io/packing/"
class="uri">https://erich-friedman.github.io/packing/</a></p>
</div>
</div>
<div class="figure">
<div id="friedman-s17-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/friedman/s17.gif" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="friedman-s17-magnify" class="magnify"
onclick="magnifyFigure(&#39;friedman-s17&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="friedman-s17-caption" class="caption-frame">
<p>Figure: Packing 17 squares into a single square. The optimal solution
is sometimes hard to find. Here the side length of the smallest square
that holds 17 similarly shaped squares is at least 4.675 times the
smaller square. This solution found by John Bidwell in 1997. Credit <a
href="https://erich-friedman.github.io/packing/"
class="uri">https://erich-friedman.github.io/packing/</a></p>
</div>
</div>
<p>Another example of a problem where the “physics” is understood
because it’s really mathematics, is packing problems. Here the
mathematics is just geometry, but still we need some form of compute to
solve these problems. <a
href="https://erich-friedman.github.io/packing/">Erich Friedman’s
website</a> contains a host of these problems, only some of which are
analytically tractable.</p>
<div class="figure">
<div id="friedman-s10-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/friedman/s10.gif" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="friedman-s10-magnify" class="magnify"
onclick="magnifyFigure(&#39;friedman-s10&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="friedman-s10-caption" class="caption-frame">
<p>Figure: Packing 10 squares into a single square. This example is
proven by Walter Stromquist <span class="citation"
data-cites="Stromquist-packingIII84">(Stromquist, 1984)</span>. Here
<span class="math inline">\(s=3+\frac{1}{\sqrt{2}}\)</span>. Credit <a
href="https://erich-friedman.github.io/packing/"
class="uri">https://erich-friedman.github.io/packing/</a></p>
</div>
</div>
<h2 id="modelling-with-a-function">Modelling with a Function</h2>
<p>What if the question of interest was quite simple, for example in the
packing problem, we just wanted to know the minimum side length.
Sometimes, regardless of the complexity of the problem, there can be a
pattern to the answer that is emergent due to regularities in the
underlying problem.</p>
<h2 id="erich-friedman-packing-data">Erich Friedman Packing Data</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_datasets/includes/erich-friedman-packing-data.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_datasets/includes/erich-friedman-packing-data.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pods</span></code></pre></div>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pods</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pods.datasets.erich_friedman_packing_data()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[<span class="st">&#39;X&#39;</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">&#39;Y&#39;</span>]</span></code></pre></div>
<div class="figure">
<div id="squares-in-squares-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//datasets/squares-in-squares.svg" width="80%" style=" ">
</object>
</div>
<div id="squares-in-squares-magnify" class="magnify"
onclick="magnifyFigure(&#39;squares-in-squares&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="squares-in-squares-caption" class="caption-frame">
<p>Figure: Plot of minimum side length known as a function of number of
squares inside.</p>
</div>
</div>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install gpy</span></code></pre></div>
<h2 id="gaussian-process-fit">Gaussian Process Fit</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/erich-friedman-packing-gp.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/erich-friedman-packing-gp.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Our first objective will be to perform a Gaussian process fit to the
data, we’ll do this using the <a
href="https://github.com/SheffieldML/GPy">GPy software</a>.</p>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>m_full <span class="op">=</span> GPy.models.GPRegression(x,y)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> m_full.optimize() <span class="co"># Optimize parameters of covariance function</span></span></code></pre></div>
<p>The first command sets up the model, then
<code>m_full.optimize()</code> optimizes the parameters of the
covariance function and the noise level of the model. Once the fit is
complete, we’ll try creating some test points, and computing the output
of the GP model in terms of the mean and standard deviation of the
posterior functions between 1870 and 2030. We plot the mean function and
the standard deviation at 200 locations. We can obtain the predictions
using <code>y_mean, y_var = m_full.predict(xt)</code></p>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">100</span>,<span class="dv">400</span>)[:,np.newaxis]</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>yt_mean, yt_var <span class="op">=</span> m_full.predict(xt)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>yt_sd<span class="op">=</span>np.sqrt(yt_var)</span></code></pre></div>
<p>Now we plot the results using the helper function in
<code>mlai.plot</code>.</p>
<div class="figure">
<div id="erich-friedman-packing-gp-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//gp/erich-friedman-packing-gp.svg" width="80%" style=" ">
</object>
</div>
<div id="erich-friedman-packing-gp-magnify" class="magnify"
onclick="magnifyFigure(&#39;erich-friedman-packing-gp&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="erich-friedman-packing-gp-caption" class="caption-frame">
<p>Figure: Gaussian process fit to the Erich Friedman Packing data.</p>
</div>
</div>
<h2 id="statistical-emulation">Statistical Emulation</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="met-office-unified-model-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/unified-model-systems.svg" width="80%" style=" ">
</object>
</div>
<div id="met-office-unified-model-magnify" class="magnify"
onclick="magnifyFigure(&#39;met-office-unified-model&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="met-office-unified-model-caption" class="caption-frame">
<p>Figure: The UK Met office runs a shared code base for its simulations
of climate and the weather. This plot shows the different spatial and
temporal scales used.</p>
</div>
</div>
<p>In many real-world systems, decisions are made through simulating the
environment. Simulations may operate at different granularities. For
example, simulations are used in weather forecasts and climate
forecasts. Interestingly, the UK Met office uses the same code for both,
it has a <a
href="https://www.metoffice.gov.uk/research/approach/modelling-systems/unified-model/index">“Unified
Model” approach</a>, but they operate climate simulations at greater
spatial and temporal resolutions.</p>
<div class="figure">
<div id="statistical-emulation-1-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/statistical-emulation000.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-1-magnify" class="magnify"
onclick="magnifyFigure(&#39;statistical-emulation-1&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="statistical-emulation-1-caption" class="caption-frame">
<p>Figure: Real world systems consist of simulators that capture our
domain knowledge about how our systems operate. Different simulators run
at different speeds and granularities.</p>
</div>
</div>
<div class="figure">
<div id="statistical-emulation-2-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/statistical-emulation001.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-2-magnify" class="magnify"
onclick="magnifyFigure(&#39;statistical-emulation-2&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="statistical-emulation-2-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the
simulation with a statistical model.</p>
</div>
</div>
<p>A statistical emulator is a data-driven model that learns about the
underlying simulation. Importantly, learns with uncertainty, so it
‘knows what it doesn’t know’. In practice, we can call the emulator in
place of the simulator. If the emulator ‘doesn’t know’, it can call the
simulator for the answer.</p>
<div class="figure">
<div id="statistical-emulation-5-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
<div id="statistical-emulation-5-magnify" class="magnify"
onclick="magnifyFigure(&#39;statistical-emulation-5&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="statistical-emulation-5-caption" class="caption-frame">
<p>Figure: A statistical emulator is a system that reconstructs the
simulation with a statistical model. As well as reconstructing the
simulation, a statistical emulator can be used to correlate with the
real world.</p>
</div>
</div>
<p>As well as reconstructing an individual simulator, the emulator can
calibrate the simulation to the real world, by monitoring differences
between the simulator and real data. This allows the emulator to
characterize where the simulation can be relied on, i.e., we can
validate the simulator.</p>
<p>Similarly, the emulator can adjudicate between simulations. This is
known as <em>multi-fidelity emulation</em>. The emulator characterizes
which emulations perform well where.</p>
<p>If all this modelling is done with judicious handling of the
uncertainty, the <em>computational doubt</em>, then the emulator can
assist in deciding what experiment should be run next to aid a decision:
should we run a simulator, in which case which one, or should we attempt
to acquire data from a real-world intervention.</p>
<h2 id="gpy-a-gaussian-process-framework-in-python">GPy: A Gaussian
Process Framework in Python</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/gpy-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/gpy-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Gaussian processes are a flexible tool for non-parametric analysis
with uncertainty. The GPy software was started in Sheffield to provide a
easy to use interface to GPs. One which allowed the user to focus on the
modelling rather than the mathematics.</p>
<div class="figure">
<div id="gpy-software-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//gp/gpy.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="gpy-software-magnify" class="magnify"
onclick="magnifyFigure(&#39;gpy-software&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gpy-software-caption" class="caption-frame">
<p>Figure: GPy is a BSD licensed software code base for implementing
Gaussian process models in Python. It is designed for teaching and
modelling. We welcome contributions which can be made through the GitHub
repository <a href="https://github.com/SheffieldML/GPy"
class="uri">https://github.com/SheffieldML/GPy</a></p>
</div>
</div>
<p>GPy is a BSD licensed software code base for implementing Gaussian
process models in python. This allows GPs to be combined with a wide
variety of software libraries.</p>
<p>The software itself is available on <a
href="https://github.com/SheffieldML/GPy">GitHub</a> and the team
welcomes contributions.</p>
<p>The aim for GPy is to be a probabilistic-style programming language,
i.e., you specify the model rather than the algorithm. As well as a
large range of covariance functions the software allows for non-Gaussian
likelihoods, multivariate outputs, dimensionality reduction and
approximations for larger data sets.</p>
<p>The documentation for GPy can be found <a
href="https://gpy.readthedocs.io/en/latest/">here</a>.</p>
<h2 id="gpy-tutorial">GPy Tutorial</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gpy-tutorial.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gpy-tutorial.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip32">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
James Hensman
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/james-hensman.png" clip-path="url(#clip32)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip33">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Nicolas Durrande
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/nicolas-durrande2.jpg" clip-path="url(#clip33)"/>
</svg>
</div>
<p>This GPy tutorial is based on material we share in the Gaussian
process summer school for teaching these models <a
href="https://gpss.cc" class="uri">https://gpss.cc</a>. It contains
material from various members and former members of the Sheffield
machine learning group, but particular mention should be made of <a
href="https://sites.google.com/site/nicolasdurrandehomepage/">Nicolas
Durrande</a> and <a href="https://jameshensman.github.io/">James
Hensman</a>, see <a
href="http://gpss.cc/gpss17/labs/GPSS_Lab1_2017.ipynb"
class="uri">http://gpss.cc/gpss17/labs/GPSS_Lab1_2017.ipynb</a>.</p>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<p>To give a feel for the software we’ll start by creating an
exponentiated quadratic covariance function, <span
class="math display">\[
k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha \exp\left(-\frac{\left\Vert
\mathbf{ x}- \mathbf{ x}^\prime \right\Vert_2^2}{2\ell^2}\right),
\]</span> where the length scale is <span
class="math inline">\(\ell\)</span> and the variance is <span
class="math inline">\(\alpha\)</span>.</p>
<p>To set this up in GPy we create a kernel in the following manner.</p>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>input_dim<span class="op">=</span><span class="dv">1</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>alpha <span class="op">=</span> <span class="fl">1.0</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>lengthscale <span class="op">=</span> <span class="fl">2.0</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>kern <span class="op">=</span> GPy.kern.RBF(input_dim<span class="op">=</span>input_dim, variance<span class="op">=</span>alpha, lengthscale<span class="op">=</span>lengthscale)</span></code></pre></div>
<p>That builds a kernel object for us. The kernel can be displayed.</p>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>display(kern)</span></code></pre></div>
<p>Or because it’s one dimensional, you can also plot the kernel as a
function of its inputs (while the other is fixed).</p>
<div class="figure">
<div id="gpy-eq-covariance-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//kern/gpy-eq-covariance.svg" width="80%" style=" ">
</object>
</div>
<div id="gpy-eq-covariance-magnify" class="magnify"
onclick="magnifyFigure(&#39;gpy-eq-covariance&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gpy-eq-covariance-caption" class="caption-frame">
<p>Figure: The exponentiated quadratic covariance function as plotted by
the <code>GPy.kern.plot</code> command.</p>
</div>
</div>
<p>You can set the length scale of the covariance to different values
and plot the result.</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>kern <span class="op">=</span> GPy.kern.RBF(input_dim<span class="op">=</span>input_dim)     <span class="co"># By default, the parameters are set to 1.</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>lengthscales <span class="op">=</span> np.asarray([<span class="fl">0.2</span>,<span class="fl">0.5</span>,<span class="fl">1.</span>,<span class="fl">2.</span>,<span class="fl">4.</span>])</span></code></pre></div>
<div class="figure">
<div id="gpy-eq-covariance-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//kern/gpy-eq-covariance-lengthscales.svg" width="80%" style=" ">
</object>
</div>
<div id="gpy-eq-covariance-magnify" class="magnify"
onclick="magnifyFigure(&#39;gpy-eq-covariance&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gpy-eq-covariance-caption" class="caption-frame">
<p>Figure: The exponentiated quadratic covariance function plotted for
different length scales by <code>GPy.kern.plot</code> command.</p>
</div>
</div>
<h2 id="covariance-functions-in-gpy">Covariance Functions in GPy</h2>
<p>Many covariance functions are already implemented in GPy. Instead of
rbf, try constructing and plotting the following covariance functions:
<code>exponential</code>, <code>Matern32</code>, <code>Matern52</code>,
<code>Brownian</code>, <code>linear</code>, <code>bias</code>,
<code>rbfcos</code>, <code>periodic_Matern32</code>, etc. Some of these
covariance functions, such as <code>rbfcos</code>, are not parametrized
by a variance and a length scale. Further, not all kernels are
stationary (i.e., they can’t all be written as <span
class="math inline">\(k(\mathbf{ x}, \mathbf{ x}^\prime) = f(\mathbf{
x}-\mathbf{ x}^\prime)\)</span>, see for example the Brownian covariance
function). So for plotting it may be interesting to change the value of
the fixed input.</p>
<h2 id="combining-covariance-functions-in-gpy">Combining Covariance
Functions in GPy</h2>
<p>In GPy you can easily combine covariance functions you have created
using the sum and product operators, <code>+</code> and <code>*</code>.
So, for example, if we wish to combine an exponentiated quadratic
covariance with a Matern 5/2 then we can write</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>kern1 <span class="op">=</span> GPy.kern.RBF(<span class="dv">1</span>, variance<span class="op">=</span><span class="fl">1.</span>, lengthscale<span class="op">=</span><span class="fl">2.</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>kern2 <span class="op">=</span> GPy.kern.Matern52(<span class="dv">1</span>, variance<span class="op">=</span><span class="fl">2.</span>, lengthscale<span class="op">=</span><span class="fl">4.</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>kern <span class="op">=</span> kern1 <span class="op">+</span> kern2</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>display(kern)</span></code></pre></div>
<div class="figure">
<div id="gpy-eq-plus-matern52-covariance-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//kern/gpy-eq-plus-matern52-covariance.svg" width="80%" style=" ">
</object>
</div>
<div id="gpy-eq-plus-matern52-covariance-magnify" class="magnify"
onclick="magnifyFigure(&#39;gpy-eq-plus-matern52-covariance&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gpy-eq-plus-matern52-covariance-caption" class="caption-frame">
<p>Figure: A combination of the exponentiated quadratic covariance plus
the Matern <span class="math inline">\(5/2\)</span> covariance.</p>
</div>
</div>
<p>Or if we wanted to multiply them, we can write</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>kern1 <span class="op">=</span> GPy.kern.RBF(<span class="dv">1</span>, variance<span class="op">=</span><span class="fl">1.</span>, lengthscale<span class="op">=</span><span class="fl">2.</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>kern2 <span class="op">=</span> GPy.kern.Matern52(<span class="dv">1</span>, variance<span class="op">=</span><span class="fl">2.</span>, lengthscale<span class="op">=</span><span class="fl">4.</span>)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>kern <span class="op">=</span> kern1 <span class="op">*</span> kern2</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>display(kern)</span></code></pre></div>
<div class="figure">
<div id="gpy-eq-times-matern52-covariance-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//kern/gpy-eq-times-matern52-covariance.svg" width="80%" style=" ">
</object>
</div>
<div id="gpy-eq-times-matern52-covariance-magnify" class="magnify"
onclick="magnifyFigure(&#39;gpy-eq-times-matern52-covariance&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gpy-eq-times-matern52-covariance-caption"
class="caption-frame">
<p>Figure: A combination of the exponentiated quadratic covariance
multiplied by the Matern <span class="math inline">\(5/2\)</span>
covariance.</p>
</div>
</div>
<p>You can learn about how to implement <a
href="https://gpy.readthedocs.io/en/latest/tuto_creating_new_kernels.html">new
kernel objects in GPy here</a>.</p>
<div class="figure">
<div id="nicolas-durrande-on-kernel-design-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/-sY8zW3Om1Y?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="nicolas-durrande-on-kernel-design-magnify" class="magnify"
onclick="magnifyFigure(&#39;nicolas-durrande-on-kernel-design&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="nicolas-durrande-on-kernel-design-caption"
class="caption-frame">
<p>Figure: Designing the covariance function for your Gaussian process
is a key place in which you introduce your understanding of the data
problem. To learn more about the design of covariance functions, see
this talk from Nicolas Durrande at GPSS in 2016.</p>
</div>
</div>
<h2 id="a-gaussian-process-regression-model">A Gaussian Process
Regression Model</h2>
<p>We will now combine the Gaussian process prior with some data to form
a GP regression model with GPy. We will generate data from the function
<span class="math display">\[
f( x) = − \cos(\pi x) + \sin(4\pi x)
\]</span> over the domain <span class="math inline">\([0, 1]\)</span>,
adding some noise to gives <span class="math display">\[
y(x) = f(x) + \epsilon,
\]</span> with the noise being Gaussian distributed, <span
class="math inline">\(\epsilon\sim
\mathcal{N}\left(0,0.01\right)\)</span>.</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.linspace(<span class="fl">0.05</span>,<span class="fl">0.95</span>,<span class="dv">10</span>)[:,np.newaxis]</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> <span class="op">-</span>np.cos(np.pi<span class="op">*</span>X) <span class="op">+</span> np.sin(<span class="dv">4</span><span class="op">*</span>np.pi<span class="op">*</span>X) <span class="op">+</span> np.random.normal(loc<span class="op">=</span><span class="fl">0.0</span>, scale<span class="op">=</span><span class="fl">0.1</span>, size<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">1</span>))</span></code></pre></div>
<div class="figure">
<div id="noisy-sine-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//gp/noisy-sine.svg" width="80%" style=" ">
</object>
</div>
<div id="noisy-sine-magnify" class="magnify"
onclick="magnifyFigure(&#39;noisy-sine&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="noisy-sine-caption" class="caption-frame">
<p>Figure: Data from the noisy sine wave for fitting with a GPy
model.</p>
</div>
</div>
<p>A GP regression model based on an exponentiated quadratic covariance
function can be defined by first defining a covariance function.</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>kern <span class="op">=</span> GPy.kern.RBF(input_dim<span class="op">=</span><span class="dv">1</span>, variance<span class="op">=</span><span class="fl">1.</span>, lengthscale<span class="op">=</span><span class="fl">1.</span>)</span></code></pre></div>
<p>And then combining it with the data to form a Gaussian process
model.</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPy.models.GPRegression(X,Y,kern)</span></code></pre></div>
<p>Just as for the covariance function object, we can find out about the
model using the command <code>display(model)</code>.</p>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>display(model)</span></code></pre></div>
<p>Note that by default the model includes some observation noise with
variance 1. We can see the posterior mean prediction and visualize the
marginal posterior variances using <code>model.plot()</code>.</p>
<div class="figure">
<div id="noisy-sine-gp-fit-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//gp/noisy-sine-gp-fit.svg" width="80%" style=" ">
</object>
</div>
<div id="noisy-sine-gp-fit-magnify" class="magnify"
onclick="magnifyFigure(&#39;noisy-sine-gp-fit&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="noisy-sine-gp-fit-caption" class="caption-frame">
<p>Figure: A Gaussian process fit to the noisy sine data. Here the
parameters of the process and the covariance function haven’t yet been
optimized.</p>
</div>
</div>
<p>You can also look directly at the predictions for the model
using.</p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>Xstar <span class="op">=</span> np.linspace(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>)[:, np.newaxis]</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>Ystar, Vstar <span class="op">=</span> model.predict(Xstar)</span></code></pre></div>
<p>Which gives you the mean (<code>Ystar</code>), the variance
(<code>Vstar</code>) at the locations given by <code>Xstar</code>.</p>
<h2 id="covariance-function-parameter-estimation">Covariance Function
Parameter Estimation</h2>
<p>As we have seen during the lectures, the parameters values can be
estimated by maximizing the likelihood of the observations. Since we
don’t want any of the variances to become negative during the
optimization, we can constrain all parameters to be positive before
running the optimization.</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>model.constrain_positive()</span></code></pre></div>
<p>The warnings are because the parameters are already constrained by
default, the software is warning us that they are being
reconstrained.</p>
<p>Now we can optimize the model using the <code>model.optimize()</code>
method. Here we switch messages on, which allows us to see the
progression of the optimization.</p>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>model.optimize(messages<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<p>By default, the optimization is using a limited memory BFGS optimizer
<span class="citation" data-cites="Byrd:lbfgsb95">(Byrd et al.,
1995)</span>.</p>
<p>Once again, we can display the model, now to see how the parameters
have changed.</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>display(model)</span></code></pre></div>
<p>The length scale is much smaller, as well as the noise level. The
variance of the exponentiated quadratic has also reduced.</p>
<div class="figure">
<div id="noisy-sine-gp-optimized-fit-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//gp/noisy-sine-gp-optimized-fit.svg" width="80%" style=" ">
</object>
</div>
<div id="noisy-sine-gp-optimized-fit-magnify" class="magnify"
onclick="magnifyFigure(&#39;noisy-sine-gp-optimized-fit&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="noisy-sine-gp-optimized-fit-caption" class="caption-frame">
<p>Figure: A Gaussian process fit to the noisy sine data with parameters
optimized.</p>
</div>
</div>
<h2 id="gpy-and-emulation">GPy and Emulation</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gpy-emulation.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gpy-emulation.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Let <span class="math inline">\(\mathbf{ x}\)</span> be a random
variable defined over the real numbers, <span
class="math inline">\(\Re\)</span>, and <span
class="math inline">\(f(\cdot)\)</span> be a function mapping between
the real numbers <span class="math inline">\(\Re \rightarrow
\Re\)</span>.</p>
<p>The problem of <em>uncertainty propagation</em> is the study of the
distribution of the random variable <span
class="math inline">\(f(\mathbf{ x})\)</span>.</p>
<p>We’re going to address this problem using emulation and GPy. We will
see in this section the advantage of using a model when only a few
observations of <span class="math inline">\(f\)</span> are
available.</p>
<p>Firstly, we’ll make use of a test function known as the Branin test
function. <span class="math display">\[
f(\mathbf{ x}) = a(x_2 - bx_1^2 + cx_1 - r)^2 + s(1-t \cos(x_1)) + s
\]</span> where we are setting <span class="math inline">\(a=1\)</span>,
<span class="math inline">\(b=5.1/(4\pi^2)\)</span>, <span
class="math inline">\(c=5/\pi\)</span>, <span
class="math inline">\(r=6\)</span>, <span
class="math inline">\(s=10\)</span> and <span
class="math inline">\(t=1/(8\pi)\)</span>.</p>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> branin(X):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> ((X[:,<span class="dv">1</span>]<span class="op">-</span><span class="fl">5.1</span><span class="op">/</span>(<span class="dv">4</span><span class="op">*</span>np.pi<span class="op">**</span><span class="dv">2</span>)<span class="op">*</span>X[:,<span class="dv">0</span>]<span class="op">**</span><span class="dv">2</span><span class="op">+</span><span class="dv">5</span><span class="op">*</span>X[:,<span class="dv">0</span>]<span class="op">/</span>np.pi<span class="op">-</span><span class="dv">6</span>)<span class="op">**</span><span class="dv">2</span> </span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>        <span class="op">+</span> <span class="dv">10</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">8</span><span class="op">*</span>np.pi))<span class="op">*</span>np.cos(X[:,<span class="dv">0</span>])<span class="op">+</span><span class="dv">10</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span>(y)</span></code></pre></div>
<p>We’ll define a grid of twenty-five observations over [−5, 10] × [0,
15] and a set of 25 observations.</p>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training set defined as a 5*5 grid:</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>xg1 <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">5</span>,<span class="dv">10</span>,<span class="dv">5</span>)</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>xg2 <span class="op">=</span> np.linspace(<span class="dv">0</span>,<span class="dv">15</span>,<span class="dv">5</span>)</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> np.zeros((xg1.size <span class="op">*</span> xg2.size,<span class="dv">2</span>))</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i,x1 <span class="kw">in</span> <span class="bu">enumerate</span>(xg1):</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> j,x2 <span class="kw">in</span> <span class="bu">enumerate</span>(xg2):</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>        X[i<span class="op">+</span>xg1.size<span class="op">*</span>j,:] <span class="op">=</span> [x1,x2]</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> branin(X)[:,np.newaxis]</span></code></pre></div>
<p>The task here will be to consider the distribution of <span
class="math inline">\(f(U)\)</span>, where <span
class="math inline">\(U\)</span> is a random variable with uniform
distribution over the input space of <span
class="math inline">\(f\)</span>. We focus on the computaiton of two
quantities, the expectation of <span
class="math inline">\(f(U)\)</span>, <span
class="math inline">\(\left\langle f(U)\right\rangle\)</span>, and the
probability that the value is greater than 200.</p>
<h2 id="computation-of-leftlangle-furightrangle">Computation of <span
class="math inline">\(\left\langle f(U)\right\rangle\)</span></h2>
<p>The expectation of <span class="math inline">\(f(U )\)</span> is
given by <span class="math inline">\(\int_\mathbf{ x}f( \mathbf{
x})\text{d}\mathbf{ x}\)</span>. A basic approach to approximate this
integral is to compute the mean of the 25 observations:
<code>np.mean(Y)</code>. Since the points are distributed on a grid,
this can be seen as the approximation of the integral by a rough Riemann
sum.</p>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Estimate of the expectation is given by: </span><span class="sc">{mean}</span><span class="st">&#39;</span>.<span class="bu">format</span>(mean<span class="op">=</span>Y.mean()))</span></code></pre></div>
<p>The result can be compared with the actual mean of the Branin
function which is 54.31.</p>
<p>Alternatively, we can fit a GP model and compute the integral of the
best predictor by Monte Carlo sampling.</p>
<p>Firstly, we create the covariance function. Here we’re going to use
an exponentiated quadratic, but we’ll augment it with the ‘bias’
covariance function. This covariance function represents a single fixed
bias that is added to the overall covariance. It allows us to deal with
non-zero-mean emulations.</p>
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an exponentiated quadratic plus bias covariance function</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>kern_eq <span class="op">=</span> GPy.kern.RBF(input_dim<span class="op">=</span><span class="dv">2</span>, ARD <span class="op">=</span> <span class="va">True</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>kern_bias <span class="op">=</span> GPy.kern.Bias(input_dim<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>kern <span class="op">=</span> kern_eq <span class="op">+</span> kern_bias</span></code></pre></div>
<p>Now we construct the Gaussian process regression model in GPy.</p>
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Build a GP model</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPy.models.GPRegression(X,Y,kern)</span></code></pre></div>
<p>In the sinusoid example above, we learnt the variance of the process.
But in this example, we are fitting an emulator to a function we know is
noise-free. However, we don’t fix the noise value to precisely zero, as
this can lead to some numerical errors. Instead, we fix the variance of
the Gaussian noise to a very small value.</p>
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fix the noise variance</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>model.likelihood.variance.fix(<span class="fl">1e-5</span>)</span></code></pre></div>
<p>Now we fit the model. Note, that the initial values for the length
scale are not appropriate. So first set the length scale of the model
needs to be reset.</p>
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>kern.rbf.lengthscale <span class="op">=</span> np.asarray([<span class="dv">3</span>, <span class="dv">3</span>])</span></code></pre></div>
<p>It’s a common error in Gaussian process fitting to initialize the
length scale too small or too big. The challenge is that the error
surface is normally multimodal, and the final solution can be very
sensitive to this initialization. If the length scale is initialized too
small, the solution can converge on an place where the signal isn’t
extracted by the covariance function. If the length scale is initialized
too large, then the variations of the function are often missing. Here
the length scale is set for each dimension of inputs as 3. Now that’s
done, we can optimize the model.</p>
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomize the model and optimize</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>model.optimize(messages<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="figure">
<div id="branin-gp-optimized-fit-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//gp/branin-gp-optimized-fit.svg" width="80%" style=" ">
</object>
</div>
<div id="branin-gp-optimized-fit-magnify" class="magnify"
onclick="magnifyFigure(&#39;branin-gp-optimized-fit&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="branin-gp-optimized-fit-caption" class="caption-frame">
<p>Figure: A Gaussian process fit to the Branin test function, used to
assess the mean of the function by emulation.</p>
</div>
</div>
<p>Finally, we can compute the mean of the model predictions using very
many Monte Carlo samples.</p>
<p>Note, that in this example, because we’re using a test function, we
could simply have done the Monte Carlo estimation directly on the Branin
function. However, imagine instead that we were trying to understand the
results of a complex computational fluid dynamics simulation, where each
run of the simulation (which is equivalent to our test function) took
many hours. In that case the advantage of the emulator is clear.</p>
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the mean of model prediction on 1e5 Monte Carlo samples</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>Xp <span class="op">=</span> np.random.uniform(size<span class="op">=</span>(<span class="bu">int</span>(<span class="fl">1e5</span>),<span class="dv">2</span>))</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>Xp[:,<span class="dv">0</span>] <span class="op">=</span> Xp[:,<span class="dv">0</span>]<span class="op">*</span><span class="dv">15</span><span class="op">-</span><span class="dv">5</span></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>Xp[:,<span class="dv">1</span>] <span class="op">=</span> Xp[:,<span class="dv">1</span>]<span class="op">*</span><span class="dv">15</span></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>mu, var <span class="op">=</span> model.predict(Xp)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;The estimate of the mean of the Branin function is </span><span class="sc">{mean}</span><span class="st">&#39;</span>.<span class="bu">format</span>(mean<span class="op">=</span>np.mean(mu)))</span></code></pre></div>
<h3 id="exercise-1">Exercise 1</h3>
<p>Now think about how to make use of the variance estimation from the
Gaussian process to obtain error bars around your estimate.</p>
<h3 id="exercise-2">Exercise 2</h3>
<p>You’ve seen how the Monte Carlo estimates work with the Gaussian
process. Now make your estimate of the probability that the Branin
function is greater than 200 with the uniform random inputs.</p>
<h2
id="uncertainty-quantification-and-design-of-experiments">Uncertainty
Quantification and Design of Experiments</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/uq-sampling-history-doe.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/uq-sampling-history-doe.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>We’re introducing you to the optimization and analysis of real-world
models through emulation, this domain is part of a broader field known
as surrogate modelling.</p>
<p>Although we’re approaching this from the machine learning
perspective, with a computer-scientist’s approach, you won’t be
surprised to find out that this field is not new and there are a range
of research groups interested in this domain.</p>
<p>We’ve been focussing on <em>active</em> experimental design. In
particular, the case where we are sequentially selecting points to run
our simulation based on previous results.</p>
<p>Here, we pause for a moment and cover approaches to <em>passive</em>
experimental design. Almost all the emulation examples we’ve looked at
so far need some initial points to ‘seed’ the emulator. Selecting these
is also a task of experimental design, but one we perform without
running our simulator.</p>
<p>This type of challenge, of where to run the simulation to get the
answer you require is an old challenge. One classic paper, <span
class="citation" data-cites="McKay-selecting79">McKay et al.
(1979)</span>, reviews three different methods for designing these
inputs. They are <em>random sampling</em>, <em>stratified sampling</em>
and <em>Latin hypercube sampling</em>.</p>
<blockquote>
<p>Let the input values <span class="math inline">\(\mathbf{ x}_1,
\dots, \mathbf{ x}_n\)</span> be a random sample from <span
class="math inline">\(f(\mathbf{ x})\)</span>. This method of sampling
is perhaps the most obvious, and an entire body of statistical
literature may be used in making inferences regarding the distribution
of <span class="math inline">\(Y(t)\)</span>.</p>
</blockquote>
<blockquote>
<p>Using stratified sampling, all areas of the sample space of <span
class="math inline">\(\mathbf{ x}\)</span> are represented by input
values. Let the sample space <span class="math inline">\(S\)</span> of
<span class="math inline">\(\mathbf{ x}\)</span> be partitioned into
<span class="math inline">\(I\)</span> disjoint strata <span
class="math inline">\(S_t\)</span>. Let <span class="math inline">\(\pi
= P(\mathbf{ x}\in S_i)\)</span> represent the size of <span
class="math inline">\(S_i\)</span>. Obtain a random sample <span
class="math inline">\(\mathbf{ x}_{ij}\)</span>, <span
class="math inline">\(j = 1, \dots, n\)</span> from <span
class="math inline">\(S_i\)</span>. Then of course the <span
class="math inline">\(n_i\)</span> sum to <span
class="math inline">\(n\)</span>. If <span class="math inline">\(I =
1\)</span>, we have random sampling over the entire sample space.</p>
</blockquote>
<blockquote>
<p>The same reasoning that led to stratified sampling, ensuring that all
portions of <span class="math inline">\(S\)</span> were sampled, could
lead further. If we wish to ensure also that each of the input variables
<span class="math inline">\(\mathbf{ x}_k\)</span> has all portions of
its distribution represented by input values, we can divide the range of
each <span class="math inline">\(\mathbf{ x}_k\)</span> into <span
class="math inline">\(n\)</span> strata of equal marginal probability
<span class="math inline">\(1/n\)</span>, and sample once from each
stratum. Let this sample be <span class="math inline">\(\mathbf{
x}_{kj}\)</span>, <span class="math inline">\(j = 1, \dots, n\)</span>.
These form the <span class="math inline">\(\mathbf{ x}_k\)</span>
component, <span class="math inline">\(k = 1, \dots , K\)</span>, in
<span class="math inline">\(\mathbf{ x}_i\)</span>, <span
class="math inline">\(i = 1, \dots, n\)</span>. The components of the
various <span class="math inline">\(\mathbf{ x}_k\)</span>’s are matched
at random. This method of selecting input values is an extension of
quota sampling (Steinberg 1963), and can be viewed as a <span
class="math inline">\(K\)</span>-dimensional extension of Latin square
sampling (Raj 1968).</p>
</blockquote>
<p>The paper’s rather dated reference to “Output from a Computer Code”
does carry forward through this literature, which has continued to be a
focus of interest for statisticians. <a
href="http://www.tonyohagan.co.uk/academic/">Tony O’Hagan</a>, who was a
colleague in Sheffield but is also one of the pioneers of Gaussian
process models was developing these methods when I first arrived there
<span class="citation" data-cites="Kennedy-bayesian01">(Kennedy and
O’Hagan, 2001)</span>, and continued with a large EPSRC funded project
for managing uncertainty in computational models, <a
href="http://www.mucm.ac.uk/" class="uri">http://www.mucm.ac.uk/</a>.
You can see a list of <a
href="http://www.mucm.ac.uk/Pages/Dissemination/TechnicalReports.html">their
technical reports here</a>.</p>
<p>Another important group based in France is the “MASCOT-NUM Research
Group”, <a href="https://www.gdr-mascotnum.fr/"
class="uri">https://www.gdr-mascotnum.fr/</a>. These researchers bring
together statisticians, applied mathematicians and engineers in solving
these problems.</p>
<h2 id="emukit-playground">Emukit Playground</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-playground.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_uq/includes/emukit-playground.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip34">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Leah Hirst
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/person-placeholder.jpg" clip-path="url(#clip34)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip35">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Cliff McCollum
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/cliff-mccollum.jpg" clip-path="url(#clip35)"/>
</svg>
</div>
<p>Emukit playground is a software toolkit for exploring the use of
statistical emulation as a tool. It was built by <a
href="https://www.linkedin.com/in/leahhirst/">Leah Hirst</a>, during her
software engineering internship at Amazon and supervised by <a
href="https://www.linkedin.com/in/cliffmccollum/">Cliff
McCollum</a>.</p>
<div class="figure">
<div id="emukit-playground-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/emukit-playground.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-playground-magnify" class="magnify"
onclick="magnifyFigure(&#39;emukit-playground&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="emukit-playground-caption" class="caption-frame">
<p>Figure: Emukit playground is a tutorial for understanding the
simulation/emulation relationship. <a
href="https://amzn.github.io/emukit-playground/"
class="uri">https://amzn.github.io/emukit-playground/</a></p>
</div>
</div>
<div class="figure">
<div id="emukit-playground-bayes-opt-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/emukit-playground-bayes-opt.png" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="emukit-playground-bayes-opt-magnify" class="magnify"
onclick="magnifyFigure(&#39;emukit-playground-bayes-opt&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="emukit-playground-bayes-opt-caption" class="caption-frame">
<p>Figure: Tutorial on Bayesian optimization of the number of taxis
deployed from Emukit playground. <a
href="https://amzn.github.io/emukit-playground/#!/learn/bayesian_optimization"
class="uri">https://amzn.github.io/emukit-playground/#!/learn/bayesian_optimization</a></p>
</div>
</div>
<p>You can explore Bayesian optimization of a taxi simulation.</p>
<h3 id="exercise-3">Exercise 3</h3>
<p>You now know enough to build a simple emulation. To test your
knowledge have a go at cobmining GPy with Thomas House’s herd immunity
simulation. Can you build a Gaussian process emulator of the simulation?
Don’t spent do long on this exercise. The idea is just to consolidate
things like what the inputs and outputs should be.</p>
<h2 id="conclusions">Conclusions</h2>
<p>We summarized the different types of simulation into roughly three
groups. Firstly, those based on physical laws in the form of
differential equations. Examples include certain compartmental
epidemiological models, climate models and weather models. Secondly,
discrete event simulations. These simulations often run to a ‘clock’,
where updates to the state are taken in turns. The Game of Life is an
example of this type of simulation, and Formula 1 models of race
strategy also use this approach. There is another type of discrete event
simulation that doesn’t use a turn-based approach but waits for the next
event. The <a
href="https://en.wikipedia.org/wiki/Gillespie_algorithm">Gillespie
algorithm</a> is an example of such an approach but we didn’t cover it
here. Finally, we realized that general computer code bases are also
simulations. If a company has a large body of code, and particularly if
it’s hosted within a streaming environment (such as Apache Kafka), it’s
possible to back test the code with different inputs. Such backtests can
be viewed as simulations, and in the case of large bodies of code (such
as the code that manages Amazon’s automated buying systems) the back
tests can be slow and could also benefit from emulation.</p>
<p>We’ve introduced emulation as a way of dealing with different
fidelities of simulations and removing the computational demands that
come with them. We’ve highlighted how emulation can be deployed and
introduced the <code>GPy</code> software for Gaussian process
modelling.</p>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to
check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking
Machines</a></li>
<li>newspaper: <a
href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile
Page</a></li>
<li>blog: <a
href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="list">
<div id="ref-Borchert-dataoriented20" class="csl-entry" role="listitem">
Borchert, T., 2020. <a
href="https://tborchertblog.wordpress.com/2020/02/13/28/">Milan: An
evolution of data-oriented programming</a>.
</div>
<div id="ref-Byrd:lbfgsb95" class="csl-entry" role="listitem">
Byrd, R.H., Lu, P., Nocedal, J., 1995. A limited memory algorithm for
bound constrained optimization. SIAM Journal on Scientific and
Statistical Computing 16, 1190–1208.
</div>
<div id="ref-Cabrera-realworld23" class="csl-entry" role="listitem">
Cabrera, C., Paleyes, A., Thodoroff, P., Lawrence, N.D., 2023. <a
href="https://arxiv.org/abs/2302.04810">Real-world machine learning
systems: A survey from a data-oriented architecture perspective</a>.
</div>
<div id="ref-Joshi-doa07" class="csl-entry" role="listitem">
Joshi, R., 2007. <a
href="http://community.rti.com/sites/default/files/archive/Data-Oriented_Architecture.pdf">A
loosely-coupled real-time SOA</a>. Real-Time Innovations Inc.
</div>
<div id="ref-Kennedy-bayesian01" class="csl-entry" role="listitem">
Kennedy, M.C., O’Hagan, A., 2001. Bayesian calibration of computer
models. Journal of the Royal Statistical Society: Series B (Statistical
Methodology) 63, 425–464. <a
href="https://doi.org/10.1111/1467-9868.00294">https://doi.org/10.1111/1467-9868.00294</a>
</div>
<div id="ref-Lawrence-atomic24" class="csl-entry" role="listitem">
Lawrence, N.D., 2024. The atomic human: Understanding ourselves in the
age of AI. Allen Lane.
</div>
<div id="ref-Lawrence-dop19" class="csl-entry" role="listitem">
Lawrence, N.D., 2019. <a
href="http://inverseprobability.com/talks/notes/modern-data-oriented-programming.html">Modern
data oriented programming</a>.
</div>
<div id="ref-Lawrence-drl17" class="csl-entry" role="listitem">
Lawrence, N.D., 2017. Data readiness levels. ArXiv.
</div>
<div id="ref-Lawrence-maturity20" class="csl-entry" role="listitem">
Lawrence, N.D., Montgomery, J., Paquet, U., 2020. <a
href="https://rs-delve.github.io/addenda/2020/11/24/organizational-data-maturity.html">Organisational
data maturity</a>. The Royal Society.
</div>
<div id="ref-McKay-selecting79" class="csl-entry" role="listitem">
McKay, M.D., Beckman, R.J., Conover, W.J., 1979. <a
href="http://www.jstor.org/stable/1268522">A comparison of three methods
for selecting values of input variables in the analysis of output from a
computer code</a>. Technometrics 21, 239–245.
</div>
<div id="ref-Stromquist-packingIII84" class="csl-entry" role="listitem">
Stromquist, W.R., 1984. Packing unit squares inside squares, III. Daniel
H. Wagner Associates.
</div>
<div id="ref-Delve-data20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020b. <a
href="http://rs-delve.github.io/reports/2020/11/24/data-readiness-lessons-from-an-emergency.html">Data
readiness: Lessons from an emergency</a>. The Royal Society.
</div>
<div id="ref-Delve-tti20" class="csl-entry" role="listitem">
The DELVE Initiative, 2020a. <a
href="https://rs-delve.github.io/reports/2020/05/27/test-trace-isolate.html">Test,
trace, isolate</a>. The Royal Society.
</div>
<div id="ref-Vorhemus-doa17" class="csl-entry" role="listitem">
Vorhemus, C., Schikuta, E., 2017. A data-oriented architecture for
loosely coupled real-time information systems, in: Proceedings of the
19th International Conference on Information Integration and Web-Based
Applications &amp; Services, iiWAS ’17. Association for Computing
Machinery, New York, NY, USA, pp. 472–481. <a
href="https://doi.org/10.1145/3151759.3151770">https://doi.org/10.1145/3151759.3151770</a>
</div>
</div>

