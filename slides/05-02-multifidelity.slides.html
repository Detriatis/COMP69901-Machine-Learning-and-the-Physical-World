<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2022-11-10">
  <title>Multifidelity Modelling</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@3.9.2/css/reveal.css">
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="https://unpkg.com/reveal.js@3.9.2/css/theme/black.css" id="theme">
  <link rel="stylesheet" href="https://inverseprobability.com/assets/css/talks.css"/>
  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement( 'link' );
    link.rel = 'stylesheet';
    link.type = 'text/css';
    link.href = window.location.search.match( /print-pdf/gi ) ? 'https://unpkg.com/reveal.js@3.9.2/css/print/pdf.css' : 'https://unpkg.com/reveal.js@3.9.2/css/print/paper.css';
    document.getElementsByTagName( 'head' )[0].appendChild( link );
  </script>
  <!--[if lt IE 9]>
  <script src="https://unpkg.com/reveal.js@3.9.2/lib/js/html5shiv.js"></script>
  <![endif]-->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_SVG" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    TeX: {
         extensions: ["color.js"]
      }
    });
  </script>
  <script src="../assets/js/figure-animate.js"></script>
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section id="title-slide">
  <h1 class="title">Multifidelity Modelling</h1>
  <p class="author" style="text-align:center"><a href="http://inverseprobability.com">Neil D. Lawrence</a></p>
  <p class="date" style="text-align:center"><time>2022-11-10</time></p>
</section>

<section class="slide level2">

<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--setupplotcode{import seaborn as sns
sns.set_style('darkgrid')
sns.set_context('paper')
sns.set_palette('colorblind')}-->
<!-- SECTION An Introduction to Multi-fidelity Modeling in Emukit -->
</section>
<section id="an-introduction-to-multi-fidelity-modeling-in-emukit" class="slide level2">
<h2>An Introduction to Multi-fidelity Modeling in Emukit</h2>
<div class="figure">
<div id="statistical-emulation-6-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/statistical-emulation004.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A statistical emulator is a system that reconstructs the simulation with a statistical model. As well as reconstructing the simulation, a statistical emulator can be used to correlate with the real world.
</aside>
</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
</section>
<section id="linear-multi-fidelity-model" class="slide level2">
<h2>Linear multi-fidelity model</h2>
<p><span class="math display">\[
f_{\text{high}}(x) = f_{\text{err}}(x) + \rho \,f_{\text{low}}(x)
\]</span></p>
<p><span class="math display">\[
f_{t}(x) = f_{t}(x) + \rho_{t-1} \,f_{t-1}(x), \quad t=1,\dots, T
\]</span></p>
</section>
<section id="section" class="slide level2">
<h2></h2>
<p><span class="math display">\[
\begin{pmatrix}
\mathbf{X}_{\text{low}} \\
\mathbf{X}_{\text{high}}
\end{pmatrix}
\]</span></p>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<p><span class="math display">\[
\begin{bmatrix}
f_{\text{low}}\left(h\right)\\
f_{\text{high}}\left(h\right)
\end{bmatrix}
\sim
GP
\begin{pmatrix}
\begin{bmatrix}
0 \\ 0
\end{bmatrix},
\begin{bmatrix}
k_{\text{low}} &amp; \rho k_{\text{low}} \\
\rho k_{\text{low}} &amp; \rho^2 k_{\text{low}} + k_{\text{err}}
\end{bmatrix}
\end{pmatrix}
\]</span></p>
</section>
<section id="linear-multi-fidelity-modeling-in-emukit" class="slide level2">
<h2>Linear multi-fidelity modeling in Emukit</h2>
<p><span class="math display">\[
\mathbf{X}= \begin{pmatrix}
x_{\text{low};0}^0 &amp; x_{\text{low};0}^1 &amp; x_{\text{low};0}^2 &amp; 0\\
x_{\text{low};1}^0 &amp; x_{\text{low};1}^1 &amp; x_{\text{low};1}^2 &amp; 0\\
x_{\text{low};2}^0 &amp; x_{\text{low};2}^1 &amp; x_{\text{low};2}^2 &amp; 0\\
x_{\text{high};0}^0 &amp; x_{\text{high};0}^1 &amp; x_{\text{high};0}^2 &amp; 1\\
x_{\text{high};1}^0 &amp; x_{\text{high};1}^1 &amp; x_{\text{high};1}^2 &amp; 1
\end{pmatrix}\quad
\mathbf{Y}= \begin{pmatrix}
y_{\text{low};0}\\
y_{\text{low};1}\\
y_{\text{low};2}\\
y_{\text{high};0}\\
y_{\text{high};1}
\end{pmatrix}
\]</span></p>
</section>
<section id="section-2" class="slide level2">
<h2></h2>
<div class="figure">
<div id="high-and-low-fidelity-forrester-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/high-and-low-fidelity-forrester.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
High and low fidelity Forrester functions.
</aside>
</section>
<section id="multifidelity-fit" class="slide level2">
<h2>Multifidelity Fit</h2>
<div class="figure">
<div id="linear-multi-fidelity-model-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/linear-multi-fidelity-model.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Linear multi-fidelity model fit to low and high-fidelity Forrester function
</aside>
</section>
<section id="comparison-to-standard-gp" class="slide level2">
<h2>Comparison to standard GP</h2>
<div class="figure">
<div id="linear-multi-fidelity-high-fidelity-gp-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/linear-multi-fidelity-high-fidelity-gp.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Comparison of linear multi-fidelity model and high fidelity GP
</aside>
</section>
<section id="nonlinear-multi-fidelity-model" class="slide level2">
<h2>Nonlinear multi-fidelity model</h2>
<p><span class="math display">\[
f_{\text{low}}(x) = \sin(8\pi x)
\]</span></p>
<p><span class="math display">\[
f_{\text{high}}(x) = \left(x- \sqrt{2}\right) \, f_{\text{low}}^2
\]</span></p>
</section>
<section id="section-3" class="slide level2">
<h2></h2>
<div class="figure">
<div id="high-and-low-fidelity-functions-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/high-and-low-fidelity-functions.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
High and low-fidelity functions
</aside>
</section>
<section id="section-4" class="slide level2">
<h2></h2>
<div class="figure">
<div id="mapping-low-to-high-fidelity-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/mapping-low-to-high-fidelity.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Mapping from low-fidelity to high-fidelity.
</aside>
</section>
<section id="failure-of-linear-multi-fidelity-model" class="slide level2">
<h2>Failure of linear multi-fidelity model</h2>
<div class="figure">
<div id="linear-multi-fidelity-model-fit-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/linear-multi-fidelity-model-fit.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Linear multi-fidelity model fit to high-fidelity function
</aside>
</section>
<section id="nonlinear-multi-fidelity-model-1" class="slide level2">
<h2>Nonlinear Multi-fidelity model</h2>
<p><span class="math display">\[ 
f_{\text{high}}(x) = \rho( \, f_{\text{low}}(x)) + \delta(x) 
\]</span></p>
</section>
<section id="section-5" class="slide level2">
<h2></h2>
<div class="figure">
<div id="-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/nonlinear-multi-fidelity-model-fit.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Nonlinear multi-fidelity model fit to low and high-fidelity functions.
</aside>
</section>
<section id="section-6" class="slide level2">
<h2></h2>
<div class="figure">
<div id="mapping-low-fidelity-to-high-fidelity-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/mapping-low-fidelity-to-high-fidelity.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Mapping from low fidelity to high fidelity
</aside>
</section>
<section id="deep-gaussian-processes" class="slide level2">
<h2>Deep Gaussian Processes</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip0">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Andreas Damianou
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/andreas-damianou.png" clip-path="url(#clip0)"/>
</svg>
</div>
</section>
<section id="stochastic-process-composition" class="slide level2">
<h2>Stochastic Process Composition</h2>
<p><span class="math display">\[\mathbf{ y}= \mathbf{ f}_4\left(\mathbf{ f}_3\left(\mathbf{ f}_2\left(\mathbf{ f}_1\left(\mathbf{ x}\right)\right)\right)\right)\]</span></p>
</section>
<section id="mathematically" class="slide level2">
<h2>Mathematically</h2>
<ul>
<li><p>Composite <em>multivariate</em> function</p>
<p><span class="math display">\[
\mathbf{g}(\mathbf{ x})=\mathbf{ f}_5(\mathbf{ f}_4(\mathbf{ f}_3(\mathbf{ f}_2(\mathbf{ f}_1(\mathbf{ x}))))).
\]</span></p></li>
</ul>
</section>
<section id="equivalent-to-markov-chain" class="slide level2">
<h2>Equivalent to Markov Chain</h2>
<ul>
<li>Composite <em>multivariate</em> function <span class="math display">\[
p(\mathbf{ y}|\mathbf{ x})= p(\mathbf{ y}|\mathbf{ f}_5)p(\mathbf{ f}_5|\mathbf{ f}_4)p(\mathbf{ f}_4|\mathbf{ f}_3)p(\mathbf{ f}_3|\mathbf{ f}_2)p(\mathbf{ f}_2|\mathbf{ f}_1)p(\mathbf{ f}_1|\mathbf{ x})
\]</span></li>
</ul>
<div class="figure">
<div id="deep-markov-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/deep-markov.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Probabilistically the deep Gaussian process can be represented as a Markov chain. Indeed they can even be analyzed in this way <span class="citation" data-cites="Dunlop:deep2017">(Dunlop et al., n.d.)</span>.
</aside>
</section>
<section id="section-7" class="slide level2">
<h2></h2>
<div class="figure">
<div id="deep-markov-vertical-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/deep-markov-vertical.svg" width="7%" style=" ">
</object>
</div>
</div>
<aside class="notes">
More usually deep probabilistic models are written vertically rather than horizontally as in the Markov chain.
</aside>
</section>
<section id="why-composition" class="slide level2">
<h2>Why Composition?</h2>
<ul>
<li><p>Gaussian processes give priors over functions.</p></li>
<li><p>Elegant properties:</p>
<ul>
<li>e.g. <em>Derivatives</em> of process are also Gaussian distributed (if they exist).</li>
</ul></li>
<li><p>For particular covariance functions they are ‘universal approximators,’ i.e. all functions can have support under the prior.</p></li>
<li><p>Gaussian derivatives might ring alarm bells.</p></li>
<li><p>E.g. a priori they don’t believe in function ‘jumps.’</p></li>
</ul>
</section>
<section id="stochastic-process-composition-1" class="slide level2">
<h2>Stochastic Process Composition</h2>
<ul>
<li><p>From a process perspective: <em>process composition</em>.</p></li>
<li><p>A (new?) way of constructing more complex <em>processes</em> based on simpler components.</p></li>
</ul>
</section>
<section id="section-8" class="slide level2">
<h2></h2>
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/deep-markov-vertical.svg" width style=" ">
</object>
</section>
<section id="section-9" class="slide level2">
<h2></h2>
<div class="figure">
<div id="deep-markov-vertical-side-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/deep-markov-vertical-side.svg" width="15%" style=" ">
</object>
</div>
</div>
<aside class="notes">
More generally we aren’t constrained by the Markov chain. We can design structures that respect our belief about the underlying conditional dependencies. Here we are adding a side note from the chain.
</aside>
</section>
<section id="gpy-a-gaussian-process-framework-in-python" class="slide level2">
<h2>GPy: A Gaussian Process Framework in Python</h2>
<div class="figure">
<div id="gpy-software-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//gp/gpy.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
GPy is a BSD licensed software code base for implementing Gaussian process models in Python. It is designed for teaching and modelling. We welcome contributions which can be made through the GitHub repository <a href="https://github.com/SheffieldML/GPy" class="uri">https://github.com/SheffieldML/GPy</a>
</aside>
<center>
<a href="https://github.com/SheffieldML/GPy" class="uri">https://github.com/SheffieldML/GPy</a>
</center>
</section>
<section id="gpy-a-gaussian-process-framework-in-python-1" class="slide level2">
<h2>GPy: A Gaussian Process Framework in Python</h2>
<ul>
<li>BSD Licensed software base.</li>
<li>Wide availability of libraries, ‘modern’ scripting language.</li>
<li>Allows us to set projects to undergraduates in Comp Sci that use GPs.</li>
<li>Available through GitHub <a href="https://github.com/SheffieldML/GPy" class="uri">https://github.com/SheffieldML/GPy</a></li>
<li>Reproducible Research with Jupyter Notebook.</li>
</ul>
</section>
<section id="features" class="slide level2">
<h2>Features</h2>
<ul>
<li>Probabilistic-style programming (specify the model, not the algorithm).</li>
<li>Non-Gaussian likelihoods.</li>
<li>Multivariate outputs.</li>
<li>Dimensionality reduction.</li>
<li>Approximations for large data sets.</li>
</ul>
</section>
<section id="olympic-marathon-data" class="slide level2">
<h2>Olympic Marathon Data</h2>
<table>
<tr>
<td width="70%">
<ul>
<li>Gold medal times for Olympic Marathon since 1896.</li>
<li>Marathons before 1924 didn’t have a standardized distance.</li>
<li>Present results using pace per km.</li>
<li>In 1904 Marathon was badly organized leading to very slow times.</li>
</ul>
</td>
<td width="30%">
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//Stephen_Kiprotich.jpg" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
<small>Image from Wikimedia Commons <a href="http://bit.ly/16kMKHQ" class="uri">http://bit.ly/16kMKHQ</a></small>
</td>
</tr>
</table>
</section>
<section id="olympic-marathon-data-1" class="slide level2">
<h2>Olympic Marathon Data</h2>
<div class="figure">
<div id="olympic-marathon-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//datasets/olympic-marathon.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Olympic marathon pace times since 1896.
</aside>
</section>
<section id="alan-turing" class="slide level2">
<h2>Alan Turing</h2>
<div class="figure">
<div id="turing-run-times-figure" class="figure-frame">
<table>
<tr>
<td width="50%">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//turing-times.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="50%">
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//turing-run.jpg" width="50%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
</div>
<aside class="notes">
Alan Turing, in 1946 he was only 11 minutes slower than the winner of the 1948 games. Would he have won a hypothetical games held in 1946? Source: <a href="http://www.turing.org.uk/scrapbook/run.html" target="_blank">Alan Turing Internet Scrapbook</a>.
</aside>
</section>
<section id="probability-winning-olympics" class="slide level2">
<h2>Probability Winning Olympics?</h2>
<ul>
<li>He was a formidable Marathon runner.</li>
<li>In 1946 he ran a time 2 hours 46 minutes.
<ul>
<li>That’s a pace of 3.95 min/km.</li>
</ul></li>
<li>What is the probability he would have won an Olympics if one had been held in 1946?</li>
</ul>
</section>
<section id="gaussian-process-fit" class="slide level2">
<h2>Gaussian Process Fit</h2>
</section>
<section id="olympic-marathon-data-gp" class="slide level2">
<h2>Olympic Marathon Data GP</h2>
<div class="figure">
<div id="olympic-marathon-gp-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//gp/olympic-marathon-gp.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Gaussian process fit to the Olympic Marathon data. The error bars are too large, perhaps due to the outlier from 1904.
</aside>
</section>
<section id="deep-gp-fit" class="slide level2">
<h2>Deep GP Fit</h2>
<ul>
<li><p>Can a Deep Gaussian process help?</p></li>
<li><p>Deep GP is one GP feeding into another.</p></li>
</ul>
</section>
<section id="olympic-marathon-data-deep-gp" class="slide level2">
<h2>Olympic Marathon Data Deep GP</h2>
<div class="figure">
<div id="olympic-marathon-deep-gp-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/olympic-marathon-deep-gp.svg" width="100%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Deep GP fit to the Olympic marathon data. Error bars now change as the prediction evolves.
</aside>
</section>
<section id="olympic-marathon-data-deep-gp-1" class="slide level2">
<h2>Olympic Marathon Data Deep GP</h2>
<div class="figure">
<div id="olympic-marathon-deep-gp-samples-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/olympic-marathon-deep-gp-samples.svg" width style=" ">
</object>
</div>
</div>
<aside class="notes">
Point samples run through the deep Gaussian process show the distribution of output locations.
</aside>
</section>
<section id="olympic-marathon-data-latent-1" class="slide level2">
<h2>Olympic Marathon Data Latent 1</h2>
<div class="figure">
<div id="olympic-marathon-deep-gp-layer-0-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/olympic-marathon-deep-gp-layer-0.svg" width style=" ">
</object>
</div>
</div>
<aside class="notes">
The mapping from input to the latent layer is broadly, with some flattening as time goes on. Variance is high across the input range.
</aside>
</section>
<section id="olympic-marathon-data-latent-2" class="slide level2">
<h2>Olympic Marathon Data Latent 2</h2>
<div class="figure">
<div id="olympic-marathon-deep-gp-layer-1-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/olympic-marathon-deep-gp-layer-1.svg" width style=" ">
</object>
</div>
</div>
<aside class="notes">
The mapping from the latent layer to the output layer.
</aside>
</section>
<section id="olympic-marathon-pinball-plot" class="slide level2">
<h2>Olympic Marathon Pinball Plot</h2>
<div class="figure">
<div id="olympic-marathon-deep-gp-pinball-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//deepgp/olympic-marathon-deep-gp-pinball.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A pinball plot shows the movement of the ‘ball’ as it passes through each layer of the Gaussian processes. Mean directions of movement are shown by lines. Shading gives one standard deviation of movement position. At each layer, the uncertainty is reset. The overal uncertainty is the cumulative uncertainty from all the layers. There is some grouping of later points towards the right in the first layer, which also injects a large amount of uncertainty. Due to flattening of the curve in the second layer towards the right the uncertainty is reduced in final output.
</aside>
</section>
<section id="deep-emulation" class="slide level2">
<h2>Deep Emulation</h2>
<div class="figure">
<div id="ml-system-downstream-simulation0-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/ml-system-downstream-simulation000.svg" width="75%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in the emulation of a simulation system.
</aside>
</section>
<section id="deep-emulation-1" class="slide level2">
<h2>Deep Emulation</h2>
<div class="figure">
<div id="ml-system-downstream-simulation1-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/ml-system-downstream-simulation001.svg" width="75%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in a machine learning system.
</aside>
</section>
<section id="deep-emulation-2" class="slide level2">
<h2>Deep Emulation</h2>
<div class="figure">
<div id="ml-system-downstream-simulation2-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/ml-system-downstream-simulation002.svg" width="75%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in the emulation of a simulation system.
</aside>
</section>
<section id="deep-emulation-3" class="slide level2">
<h2>Deep Emulation</h2>
<div class="figure">
<div id="ml-system-downstream-simulation3-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//simulation/ml-system-downstream-simulation003.svg" width="75%" style=" ">
</object>
</div>
</div>
<aside class="notes">
A potential path of models in the emulation of a simulation system.
</aside>
</section>
<section id="brief-reflection" class="slide level2">
<h2>Brief Reflection</h2>
<ul>
<li>Given you a toolkit of Surrogate Modelling.</li>
<li>Project work is opportunity to use your imagination.</li>
<li>Can combine different parts together.</li>
</ul>
</section>
<section id="section-10" class="slide level2">
<h2></h2>
<div class="figure">
<div id="mountain-car-emulation-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/mountain-car-emulation.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
The mountain car example contains a simulation of a car’s dynamics within the wider simulation of the mountain. The simulation of the car is called as a subroutine many times by the wider simulation of the mountain. We can choose to build a surrogate model of the car, and work with a modified mountain simulation where the emulator is called instead of the car’s simulation directly.
</aside>
</section>
<section id="mountain-car-simulator" class="slide level2">
<h2>Mountain Car Simulator</h2>
<div class="figure">
<div id="mountain-car-figure" class="figure-frame">
<div class="centered" style="">
<img class="negate" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/mountaincar.png" width="60%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
The mountain car simulation from the Open AI gym.
</aside>
</section>
<section id="car-dynamics" class="slide level2">
<h2>Car Dynamics</h2>
<p><span class="math display">\[
\mathbf{ x}_{t+1} = f(\mathbf{ x}_{t},\textbf{u}_{t})
\]</span> where <span class="math inline">\(\textbf{u}_t\)</span> is the action force, <span class="math inline">\(\mathbf{ x}_t = (p_t, v_t)\)</span> is the vehicle state</p>
</section>
<section id="policy" class="slide level2">
<h2>Policy</h2>
<ul>
<li>Assume policy is linear with parameters <span class="math inline">\(\boldsymbol{\theta}\)</span> <span class="math display">\[
\pi(\mathbf{ x},\theta)= \theta_0 + \theta_p p + \theta_vv.
\]</span></li>
</ul>
</section>
<section id="emulate-the-mountain-car" class="slide level2">
<h2>Emulate the Mountain Car</h2>
<ul>
<li>Goal is find <span class="math inline">\(\theta\)</span> such that <span class="math display">\[
\theta^* = arg \max_{\theta} R_T(\theta).
\]</span></li>
<li>Reward is computed as 100 for target, minus squared sum of actions</li>
</ul>
</section>
<section id="random-linear-controller" class="slide level2">
<h2>Random Linear Controller</h2>
<div class="figure">
<div id="mountain-car-random-figure" class="figure-frame">
<iframe src="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/mountain-car-random.html" width="600" height="450" allowtransparency="true" frameborder="0">
</iframe>
</div>
</div>
<aside class="notes">
Random linear controller for the Mountain car. It fails to move the car to the top of the mountain.
</aside>
</section>
<section id="best-controller-after-50-iterations-of-bayesian-optimization" class="slide level2">
<h2>Best Controller after 50 Iterations of Bayesian Optimization</h2>
<div class="figure">
<div id="mountain-car-similated-bayes-opt-figure" class="figure-frame">
<iframe src="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/mountain-car-simulated.html" width="600" height="450" allowtransparency="true" frameborder="0">
</iframe>
</div>
</div>
<aside class="notes">
Mountain car simulator trained using Bayesian optimization and the simulator of the dynamics. Fifty iterations of Bayesian optimization are used to optimize the controler.
</aside>
</section>
<section id="data-efficient-emulation" class="slide level2">
<h2>Data Efficient Emulation</h2>
<ul>
<li>For standard Bayesian Optimization ignored <em>dynamics</em> of the car.</li>
<li>For more data efficiency, first <em>emulate</em> the dynamics.</li>
<li>Then do Bayesian optimization of the <em>emulator</em>.</li>
</ul>
<p><span class="math display">\[
\mathbf{ x}_{t+1} =g(\mathbf{ x}_{t},\textbf{u}_{t})
\]</span></p>
</section>
<section id="section-11" class="slide level2">
<h2></h2>
<ul>
<li>Use a Gaussian process to model <span class="math display">\[
\Delta v_{t+1} = v_{t+1} - v_{t}
\]</span> and <span class="math display">\[
\Delta x_{t+1} = p_{t+1} - p_{t}
\]</span></li>
<li>Two processes, one with mean <span class="math inline">\(v_{t}\)</span> one with mean <span class="math inline">\(p_{t}\)</span></li>
</ul>
</section>
<section id="emulator-training" class="slide level2">
<h2>Emulator Training</h2>
<ul>
<li>Used 500 randomly selected points to train emulators.</li>
<li>Can make proces smore efficient through <em>experimental design</em>.</li>
</ul>
</section>
<section id="comparison-of-emulation-and-simulation" class="slide level2">
<h2>Comparison of Emulation and Simulation</h2>
<div class="figure">
<div id="emu-sim-comparison-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/emu-sim-comparison.svg" width="80%" style=" ">
</object>
</div>
</div>
<aside class="notes">
Comparison between the mountain car simulator and the emulator.
</aside>
<!--{space= [{'name':'linear_1', 'type':'continuous', 'domain':(-1/1.2, +1)},
        {'name':'linear_2', 'type':'continuous', 'domain':(-1/0.07, +1/0.07)},
        {'name':'constant', 'type':'continuous', 'domain':(-1, +1)}]-->
</section>
<section id="data-efficiency" class="slide level2">
<h2>Data Efficiency</h2>
<ul>
<li>Our emulator used only 500 calls to the simulator.</li>
<li>Optimizing the simulator directly required 37,500 calls to the simulator.</li>
</ul>
</section>
<section id="best-controller-using-emulator-of-dynamics" class="slide level2">
<h2>Best Controller using Emulator of Dynamics</h2>
<div class="figure">
<div id="mountain-car-emulated-figure" class="figure-frame">
<iframe src="https://mlatcl.github.io/mlphysical/./slides/diagrams//uq/mountain-car-emulated.html" width="600" height="450" allowtransparency="true" frameborder="0">
</iframe>
</div>
</div>
<aside class="notes">
Mountain car controller learnt through emulation. Here 500 calls to the simulator are used to fit the controller rather than 37,500 calls to the simulator required in the standard learning.
</aside>
</section>
<section id="mountain-car-multi-fidelity-emulation" class="slide level2">
<h2>Mountain Car: Multi-Fidelity Emulation</h2>
<p><span class="math display">\[
f_i\left(\mathbf{ x}\right) = \rho f_{i-1}\left(\mathbf{ x}\right) + \delta_i\left(\mathbf{ x}\right),
\]</span></p>
<p><span class="math display">\[
f_i\left(\mathbf{ x}\right) = g_{i}\left(f_{i-1}\left(\mathbf{ x}\right)\right) + \delta_i\left(\mathbf{ x}\right),
\]</span></p>
</section>
<section id="prime-air" class="slide level2">
<h2>Prime Air</h2>
<div class="centered" style="">
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip1">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Gur Kimchi
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/gur-kimchi.png" clip-path="url(#clip1)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip2">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
Paul Viola
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/paul-viola.png" clip-path="url(#clip2)"/>
</svg>
<svg viewBox="0 0 200 200" style="width:15%">
<defs> <clipPath id="clip3">
<style>
circle {
  fill: black;
}
</style>
<circle cx="100" cy="100" r="100"/> </clipPath> </defs>
<title>
David Moro
</title>
<image preserveAspectRatio="xMinYMin slice" width="100%" xlink:href="https://mlatcl.github.io/mlphysical/./slides/diagrams//people/david-moro.png" clip-path="url(#clip3)"/>
</svg>
</div>
<div class="figure">
<div id="amazon-drone-flight-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/3HJtmx5f1Fc?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
</div>
<aside class="notes">
An actual ‘Santa’s sleigh.’ Amazon’s prototype delivery drone. Machine learning algorithms are used across various systems including sensing (computer vision for detection of wires, people, dogs etc) and piloting. The technology is necessarily a combination of old and new ideas. The transition from vertical to horizontal flight is vital for efficiency and uses sophisticated machine learning to achieve.
</aside>
</section>
<section id="section-12" class="slide level2">
<h2></h2>
<div class="figure">
<div id="jeff-wilke-remars-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/wa8DU-Sui8Q?start=3767" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
</div>
<aside class="notes">
Jeff Wilke (CEO Amazon Consumer) announcing the new drone at the Amazon 2019 re:MARS event alongside the scale of the Amazon supply chain.
</aside>
</section>
<section id="section-13" class="slide level2">
<h2></h2>
<div class="figure">
<div id="amazon-prime-air-remars-figure" class="figure-frame">
<div class="centered centered" style="">
<img class="" src="https://mlatcl.github.io/mlphysical/./slides/diagrams//ai/amazon-prime-air-remars-june-2019.jpg" width="80%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
</div>
<aside class="notes">
Picture of the drone from Amazon Re-MARS event in 2019.
</aside>
</section>
<section id="thanks" class="slide level2 scrollable">
<h2 class="scrollable">Thanks!</h2>
<ul>
<li><p>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></p></li>
<li><p>podcast: <a href="http://thetalkingmachines.com">The Talking Machines</a></p></li>
<li><p>newspaper: <a href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile Page</a></p></li>
<li><p>blog posts:</p>
<p><a href="http://inverseprobability.com/2014/07/01/open-data-science">Open Data Science</a></p></li>
</ul>
</section>
<section id="references" class="slide level2 unnumbered scrollable">
<h2 class="unnumbered scrollable">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Dunlop:deep2017" class="csl-entry" role="doc-biblioentry">
Dunlop, M.M., Girolami, M.A., Stuart, A.M., Teckentrup, A.L., n.d. How deep are deep <span>G</span>aussian processes? Journal of Machine Learning Research 19, 1–46.
</div>
</div>
</section>
    </div>
  </div>

  <script src="https://unpkg.com/reveal.js@3.9.2/lib/js/head.min.js"></script>
  <script src="https://unpkg.com/reveal.js@3.9.2/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Push each slide change to the browser history
        history: true,
        // Transition style
        transition: 'None', // none/fade/slide/convex/concave/zoom
        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // Optional reveal.js plugins
        dependencies: [
          { src: 'https://unpkg.com/reveal.js@3.9.2/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'https://unpkg.com/reveal.js@3.9.2/plugin/zoom-js/zoom.js', async: true },
          { src: 'https://unpkg.com/reveal.js@3.9.2/plugin/math/math.js', async: true },
          { src: 'https://unpkg.com/reveal.js@3.9.2/plugin/notes/notes.js', async: true }
        ]
      });
    </script>
    </body>
</html>
